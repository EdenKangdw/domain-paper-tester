import streamlit as st
import pickle
import numpy as np
import torch
import glob

def load_classifier(path):
    with open(path, 'rb') as f:
        return pickle.load(f)

def get_head_feature(prompt, model, tokenizer):
    # evidence ì¶”ì¶œ ë° attention ê³„ì‚° (ì‹¤í—˜ê³¼ ë™ì¼í•˜ê²Œ)
    inputs = tokenizer(prompt, return_tensors="pt")
    inputs = {k: v.to(model.device) for k, v in inputs.items()}
    with torch.no_grad():
        outputs = model(**inputs, output_attentions=True)
        attentions = tuple(attn.cpu().numpy() for attn in outputs.attentions)
    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])
    last_attn = attentions[-1][0]  # (head, from_token, to_token)
    # evidence_indices ì¶”ì¶œ (ì—¬ê¸°ì„  ì˜ˆì‹œë¡œ ë§ˆì§€ë§‰ í† í°)
    evidence_indices = [len(tokens)-1]
    # ê°€ì¥ ê°•í•˜ê²Œ ë°˜ì‘í•œ head ì°¾ê¸°
    head_scores = [last_attn[h, :, evidence_indices].mean() for h in range(last_attn.shape[0])]
    max_head = int(np.argmax(head_scores))
    feature = np.zeros(32)
    feature[max_head] = 1
    return feature

def show():
    st.title("ğŸ§‘â€ğŸ”¬ ë„ë©”ì¸ ë¶„ë¥˜ê¸° ì‹¤í—˜")
    st.markdown("í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ë©´ ë„ë©”ì¸ ë¶„ë¥˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.")
    prompt = st.text_area("í”„ë¡¬í”„íŠ¸ ì…ë ¥", height=100)
    # ì—¬ëŸ¬ ë¶„ë¥˜ê¸° íŒŒì¼ ì¤‘ ì„ íƒ
    clf_files = glob.glob('domain_classifier*.pkl')
    if not clf_files:
        st.error("ë¶„ë¥˜ê¸° íŒŒì¼(domain_classifier*.pkl)ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í•™ìŠµ íƒ­ì—ì„œ ë¶„ë¥˜ê¸°ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.")
        return
    selected_clf = st.selectbox("ë¶„ë¥˜ê¸° íŒŒì¼ ì„ íƒ", clf_files, index=0)
    if st.button("ë„ë©”ì¸ ì˜ˆì¸¡"):
        if 'model' not in st.session_state or 'tokenizer' not in st.session_state:
            st.error("ë¨¼ì € ëª¨ë¸ì„ ë¡œë“œí•˜ì„¸ìš”.")
            return
        model = st.session_state['model']
        tokenizer = st.session_state['tokenizer']
        try:
            clf = load_classifier(selected_clf)
        except Exception as e:
            st.error(f"ë¶„ë¥˜ê¸° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return
        feature = get_head_feature(prompt, model, tokenizer)
        pred = clf.predict([feature])[0]
        proba = clf.predict_proba([feature])[0]
        st.success(f"ì˜ˆì¸¡ ë„ë©”ì¸: **{pred}**")
        st.bar_chart({c: p for c, p in zip(clf.classes_, proba)})
        st.info(f"ì‚¬ìš©í•œ ë¶„ë¥˜ê¸° íŒŒì¼: {selected_clf}") 