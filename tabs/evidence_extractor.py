import streamlit as st
import json
import time
from datetime import datetime
from pathlib import Path
import requests
from transformers import AutoTokenizer
import re
import ast
from typing import List, Tuple, Optional, Dict, Any

# ìƒìˆ˜ ì •ì˜
OLLAMA_API_BASE = "http://localhost:11434"
TIMEOUT = 15  # íƒ€ì„ì•„ì›ƒì„ 15ì´ˆë¡œ ë‹¨ì¶•

# ëª¨ë¸ë³„ í† í¬ë‚˜ì´ì € ë§¤í•‘
MODEL_TOKENIZER_MAP = {
    "gemma:7b": "google/gemma-7b",
    "mistral:7b": "mistralai/Mistral-7B-v0.1",
    "qwen:7b": "Qwen/Qwen-7B",
    "llama2:7b": "meta-llama/Llama-2-7b-hf",
    "llama2:13b": "meta-llama/Llama-2-13b-hf",
    "llama2:70b": "meta-llama/Llama-2-70b-hf",
    "deepseek-r1:7b": "deepseek-ai/deepseek-llm-7b-base",
    "deepseek-r1-distill-llama:8b": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
}

# ë„ë©”ì¸ë³„ evidence ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
DOMAIN_PROMPTS = {
    "economy": "Find tokens related to economy, finance, market, investment, currency, and trade.",
    "legal": "Find tokens related to law, regulations, contracts, rights, and obligations.",
    "medical": "Find tokens related to medicine, health, disease, treatment, and drugs.",
    "technical": "Find tokens related to technology, science, engineering, computers, and systems."
}

@st.cache_data(ttl=300)
def get_available_models() -> List[str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        response = requests.get(f"{OLLAMA_API_BASE}/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get("models", [])
            return [model["name"] for model in models]
        return []
    except Exception as e:
        print(f"Error fetching models: {e}")
        return []

def check_model_status(model_key: str) -> bool:
    """íŠ¹ì • ëª¨ë¸ì˜ ì‹¤í–‰ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    try:
        # ë¨¼ì € ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ëª©ë¡ í™•ì¸
        response = requests.get(f"{OLLAMA_API_BASE}/api/ps", timeout=5)
        if response.status_code == 200:
            running_models = response.json().get("models", [])
            model_names = [model["name"] for model in running_models]
            if model_key in model_names:
                return True
        
        # ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ˆë¼ë©´ ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í…ŒìŠ¤íŠ¸
        response = requests.post(
            f"{OLLAMA_API_BASE}/api/generate",
            json={
                "model": model_key,
                "prompt": "test",
                "stream": False,
                "options": {
                    "num_predict": 1
                }
            },
            timeout=5
        )
        
        if response.status_code == 200:
            # ì‘ë‹µì´ ì„±ê³µí•˜ë©´ ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•¨
            return True
        elif response.status_code == 404:
            # ëª¨ë¸ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ
            return False
        else:
            # ê¸°íƒ€ ì˜¤ë¥˜
            return False
            
    except Exception as e:
        print(f"ëª¨ë¸ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False

def get_running_models() -> List[str]:
    """ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        response = requests.get(f"{OLLAMA_API_BASE}/api/ps", timeout=5)
        if response.status_code == 200:
            running_models = response.json().get("models", [])
            return [model["name"] for model in running_models]
        return []
    except Exception as e:
        print(f"ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return []

def load_file_data(file_path: Path) -> List[Dict[str, Any]]:
    """íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            if file_path.suffix == ".json":
                data = json.load(f)
                return data if isinstance(data, list) else [data]
            elif file_path.suffix == ".jsonl":
                return [json.loads(line) for line in f if line.strip()]
    except Exception as e:
        print(f"Error loading {file_path}: {e}")
    return []

def load_origin_prompts(domain: str, model_key: str = None) -> List[Dict[str, Any]]:
    """ë„ë©”ì¸ë³„ origin í”„ë¡¬í”„íŠ¸ íŒŒì¼ë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    if model_key:
        # ëª¨ë¸ë³„ ë„ë©”ì¸ ë””ë ‰í† ë¦¬ì—ì„œ ë¡œë“œ (ì½œë¡ ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½)
        origin_dir = Path(f"dataset/origin/{model_key.replace(':', '_')}/{domain.lower()}")
        if not origin_dir.exists():
            # ì½œë¡ ì´ ê·¸ëŒ€ë¡œì¸ ê²½ìš°ë„ ì‹œë„
            origin_dir = Path(f"dataset/origin/{model_key}/{domain.lower()}")
    else:
        # ê¸°ì¡´ ë°©ì‹ (ë„ë©”ì¸ ì§ì ‘ ë””ë ‰í† ë¦¬)
        origin_dir = Path(f"dataset/origin/{domain.lower()}")
    
    if not origin_dir.exists():
        return []
    
    all_prompts = []
    
    # ëª¨ë“  JSON ë° JSONL íŒŒì¼ ì²˜ë¦¬
    for file_path in origin_dir.glob("*.json*"):
        file_data = load_file_data(file_path)
        all_prompts.extend(file_data)
    
    return all_prompts

def get_available_files(domain: str, model_key: str = None) -> List[Dict[str, Any]]:
    """ë„ë©”ì¸ë³„ ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if model_key:
        # ëª¨ë¸ë³„ ë„ë©”ì¸ ë””ë ‰í† ë¦¬ì—ì„œ ë¡œë“œ (ì½œë¡ ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½)
        origin_dir = Path(f"dataset/origin/{model_key.replace(':', '_')}/{domain.lower()}")
        if not origin_dir.exists():
            # ì½œë¡ ì´ ê·¸ëŒ€ë¡œì¸ ê²½ìš°ë„ ì‹œë„
            origin_dir = Path(f"dataset/origin/{model_key}/{domain.lower()}")
    else:
        # ê¸°ì¡´ ë°©ì‹ (ë„ë©”ì¸ ì§ì ‘ ë””ë ‰í† ë¦¬)
        origin_dir = Path(f"dataset/origin/{domain.lower()}")
    
    if not origin_dir.exists():
        return []
    
    files = []
    for file_path in origin_dir.glob("*.json*"):
        try:
            file_data = load_file_data(file_path)
            files.append({
                "path": file_path,
                "name": file_path.name,
                "size": file_path.stat().st_size,
                "prompt_count": len(file_data),
                "data": file_data
            })
        except Exception as e:
            print(f"Error loading {file_path}: {e}")
    
    return files

def load_selected_files(domain: str, selected_files: List[str], model_key: str = None) -> List[Dict[str, Any]]:
    """ì„ íƒëœ íŒŒì¼ë“¤ì—ì„œ í”„ë¡¬í”„íŠ¸ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    if model_key:
        # ëª¨ë¸ë³„ ë„ë©”ì¸ ë””ë ‰í† ë¦¬ì—ì„œ ë¡œë“œ (ì½œë¡ ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½)
        origin_dir = Path(f"dataset/origin/{model_key.replace(':', '_')}/{domain.lower()}")
        if not origin_dir.exists():
            # ì½œë¡ ì´ ê·¸ëŒ€ë¡œì¸ ê²½ìš°ë„ ì‹œë„
            origin_dir = Path(f"dataset/origin/{model_key}/{domain.lower()}")
    else:
        # ê¸°ì¡´ ë°©ì‹ (ë„ë©”ì¸ ì§ì ‘ ë””ë ‰í† ë¦¬)
        origin_dir = Path(f"dataset/origin/{domain.lower()}")
    
    if not origin_dir.exists():
        return []
    
    all_prompts = []
    for file_name in selected_files:
        file_path = origin_dir / file_name
        if file_path.exists():
            file_data = load_file_data(file_path)
            all_prompts.extend(file_data)
    
    return all_prompts

# def find_token_positions(prompt: str, tokens: List[str], tokenizer) -> List[int]:
#     """í”„ë¡¬í”„íŠ¸ì—ì„œ í† í°ë“¤ì˜ ìœ„ì¹˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤ (í† í° ë‹¨ìœ„ ì¸ë±ìŠ¤)."""
#     # ì´ í•¨ìˆ˜ëŠ” ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - ì›ë³¸ í”„ë¡¬í”„íŠ¸ì—ì„œ ë‹¨ìˆœ ë¬¸ìì—´ ë§¤ì¹­ìœ¼ë¡œ ëŒ€ì²´
#     pass

def extract_tokens_from_response(response_text: str) -> Optional[List[str]]:
    """ëª¨ë¸ ì‘ë‹µì—ì„œ í† í° ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        print(f"   ğŸ” í† í° ì¶”ì¶œ ì‹œì‘: {len(response_text)} ë¬¸ì ì‘ë‹µ")
        print(f"   ì›ë³¸ ì‘ë‹µ: {response_text}")
        
        import re
        import ast
        import json
        
        # 1. ê°€ì¥ ì •í™•í•œ ë°©ë²•: JSON íŒŒì‹± ì‹œë„
        try:
            # ì „ì²´ ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹± ì‹œë„
            parsed = json.loads(response_text.strip())
            if isinstance(parsed, list):
                result = [str(token).strip() for token in parsed if token]
                print(f"   âœ… JSON íŒŒì‹± ì„±ê³µ: {len(result)}ê°œ í† í°")
                print(f"   ì¶”ì¶œëœ í† í°ë“¤: {result}")
                return result
        except json.JSONDecodeError:
            pass
        
        # 2. JSON ë°°ì—´ íŒ¨í„´ ì°¾ê¸° (ë” ì •í™•í•œ ì •ê·œì‹)
        # ì¤‘ì²©ëœ ë°°ì—´ë„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ê°œì„ 
        json_array_pattern = r'\[(?:[^[\]]*|\[(?:[^[\]]*|\[[^[\]]*\])*\])*\]'
        list_matches = re.findall(json_array_pattern, response_text)
        
        for match in list_matches:
            try:
                evidence_tokens = ast.literal_eval(match)
                if isinstance(evidence_tokens, list) and evidence_tokens:
                    result = [str(token).strip() for token in evidence_tokens if token]
                    print(f"   âœ… JSON ë°°ì—´ íŒ¨í„´ì—ì„œ ì¶”ì¶œ: {len(result)}ê°œ í† í°")
                    print(f"   ë§¤ì¹˜ëœ íŒ¨í„´: {match}")
                    print(f"   ì¶”ì¶œëœ í† í°ë“¤: {result}")
                    return result
            except (ValueError, SyntaxError) as e:
                print(f"   âš ï¸ íŒ¨í„´ íŒŒì‹± ì‹¤íŒ¨: {match} - {str(e)}")
                continue
        
        # 3. ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì¸ í† í°ë“¤ ì¶”ì¶œ (ë” ì •í™•í•œ íŒ¨í„´)
        print(f"   ë”°ì˜´í‘œ íŒ¨í„´ìœ¼ë¡œ ì¶”ì¶œ ì‹œë„...")
        # JSON ë°°ì—´ ë‚´ë¶€ì˜ ë”°ì˜´í‘œë§Œ ì°¾ê¸°
        quoted_tokens = re.findall(r'["\']([^"\']+)["\']', response_text)
        if quoted_tokens:
            # ì¤‘ë³µ ì œê±°í•˜ê³  ì •ë¦¬
            result = list(set([token.strip() for token in quoted_tokens if token.strip()]))
            print(f"   âœ… ë”°ì˜´í‘œ íŒ¨í„´ì—ì„œ ì¶”ì¶œ: {len(result)}ê°œ í† í°")
            print(f"   ì¶”ì¶œëœ í† í°ë“¤: {result}")
            return result
        
        # 4. ëŒ€ê´„í˜¸ ì•ˆì˜ ë‚´ìš©ì„ ì§ì ‘ íŒŒì‹±
        print(f"   ëŒ€ê´„í˜¸ ë‚´ìš© ì§ì ‘ íŒŒì‹± ì‹œë„...")
        bracket_content = re.search(r'\[(.*?)\]', response_text, re.DOTALL)
        if bracket_content:
            content = bracket_content.group(1)
            # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ í•­ëª©ë“¤ ì¶”ì¶œ
            items = [item.strip().strip('"\'') for item in content.split(',') if item.strip()]
            if items:
                result = [item for item in items if item]
                print(f"   âœ… ëŒ€ê´„í˜¸ ë‚´ìš©ì—ì„œ ì¶”ì¶œ: {len(result)}ê°œ í† í°")
                print(f"   ì¶”ì¶œëœ í† í°ë“¤: {result}")
                return result
        
        # 5. Mistral/Gemma ëª¨ë¸ íŠ¹í™” íŒŒì‹± (íƒœê·¸ ì œê±° í›„ íŒŒì‹±)
        print(f"   Mistral/Gemma ëª¨ë¸ íŠ¹í™” íŒŒì‹± ì‹œë„...")
        
        # Mistral ëª¨ë¸: <s>[INST] ... [/INST] íƒœê·¸ ì œê±°
        mistral_cleaned = re.sub(r'<s>\[INST\].*?\[/INST\]', '', response_text, flags=re.DOTALL)
        mistral_cleaned = mistral_cleaned.strip()
        
        # Gemma ëª¨ë¸: <start_of_turn>model ... <end_of_turn> íƒœê·¸ ì œê±°
        gemma_cleaned = re.sub(r'<start_of_turn>model\s*', '', response_text, flags=re.IGNORECASE)
        gemma_cleaned = re.sub(r'<end_of_turn>\s*', '', gemma_cleaned, flags=re.IGNORECASE)
        gemma_cleaned = gemma_cleaned.strip()
        
        # Mistral íƒœê·¸ê°€ ì œê±°ëœ ê²½ìš°
        if mistral_cleaned != response_text:
            print(f"   Mistral íƒœê·¸ ì œê±°ë¨: {len(mistral_cleaned)} ë¬¸ì")
            # ì œê±°ëœ í…ìŠ¤íŠ¸ì—ì„œ ë‹¤ì‹œ JSON íŒŒì‹± ì‹œë„
            try:
                parsed = json.loads(mistral_cleaned)
                if isinstance(parsed, list):
                    result = [str(token).strip() for token in parsed if token]
                    print(f"   âœ… Mistral íƒœê·¸ ì œê±° í›„ JSON íŒŒì‹± ì„±ê³µ: {len(result)}ê°œ í† í°")
                    print(f"   ì¶”ì¶œëœ í† í°ë“¤: {result}")
                    return result
            except json.JSONDecodeError:
                pass
            
            # Mistral íƒœê·¸ ì œê±° í›„ ë°°ì—´ íŒ¨í„´ ì°¾ê¸°
            list_matches = re.findall(json_array_pattern, mistral_cleaned)
            for match in list_matches:
                try:
                    evidence_tokens = ast.literal_eval(match)
                    if isinstance(evidence_tokens, list) and evidence_tokens:
                        result = [str(token).strip() for token in evidence_tokens if token]
                        print(f"   âœ… Mistral íƒœê·¸ ì œê±° í›„ ë°°ì—´ íŒ¨í„´ì—ì„œ ì¶”ì¶œ: {len(result)}ê°œ í† í°")
                        print(f"   ì¶”ì¶œëœ í† í°ë“¤: {result}")
                        return result
                except (ValueError, SyntaxError):
                    continue
        
        # Gemma íƒœê·¸ê°€ ì œê±°ëœ ê²½ìš°
        if gemma_cleaned != response_text:
            print(f"   Gemma íƒœê·¸ ì œê±°ë¨: {len(gemma_cleaned)} ë¬¸ì")
            # ì œê±°ëœ í…ìŠ¤íŠ¸ì—ì„œ ë‹¤ì‹œ JSON íŒŒì‹± ì‹œë„
            try:
                parsed = json.loads(gemma_cleaned)
                if isinstance(parsed, list):
                    result = [str(token).strip() for token in parsed if token]
                    print(f"   âœ… Gemma íƒœê·¸ ì œê±° í›„ JSON íŒŒì‹± ì„±ê³µ: {len(result)}ê°œ í† í°")
                    print(f"   ì¶”ì¶œëœ í† í°ë“¤: {result}")
                    return result
            except json.JSONDecodeError:
                pass
            
            # Gemma íƒœê·¸ ì œê±° í›„ ë°°ì—´ íŒ¨í„´ ì°¾ê¸°
            list_matches = re.findall(json_array_pattern, gemma_cleaned)
            for match in list_matches:
                try:
                    evidence_tokens = ast.literal_eval(match)
                    if isinstance(evidence_tokens, list) and evidence_tokens:
                        result = [str(token).strip() for token in evidence_tokens if token]
                        print(f"   âœ… Gemma íƒœê·¸ ì œê±° í›„ ë°°ì—´ íŒ¨í„´ì—ì„œ ì¶”ì¶œ: {len(result)}ê°œ í† í°")
                        print(f"   ì¶”ì¶œëœ í† í°ë“¤: {result}")
                        return result
                except (ValueError, SyntaxError):
                    continue
        
        # 6. ë§ˆì§€ë§‰ ìˆ˜ë‹¨: ë‹¨ì–´ íŒ¨í„´ (í•˜ì§€ë§Œ ë” ì •êµí•˜ê²Œ)
        print(f"   ë‹¨ì–´ íŒ¨í„´ìœ¼ë¡œ ì¶”ì¶œ ì‹œë„...")
        # JSON ë°°ì—´ ë‚´ë¶€ì˜ ë‹¨ì–´ë“¤ë§Œ ì°¾ê¸°
        words = re.findall(r'\b[a-zA-Z][a-zA-Z0-9_]*\b', response_text)
        if words:
            # ì¤‘ë³µ ì œê±°í•˜ê³  ì •ë¦¬
            result = list(set([word.strip() for word in words if word.strip() and len(word) > 1]))
            print(f"   âœ… ë‹¨ì–´ íŒ¨í„´ì—ì„œ ì¶”ì¶œ: {len(result)}ê°œ í† í°")
            print(f"   ì¶”ì¶œëœ í† í°ë“¤: {result}")
            return result
        
        print(f"   âŒ ëª¨ë“  ì¶”ì¶œ ë°©ë²• ì‹¤íŒ¨")
        print(f"   ì›ë³¸ ì‘ë‹µ: {response_text}")
        return None
        
    except Exception as e:
        print(f"âŒ í† í° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        print(f"   ì‘ë‹µ í…ìŠ¤íŠ¸: {response_text}")
        return None

def call_ollama_api(model_key: str, prompt: str) -> Optional[str]:
    """Ollama APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    try:
        print(f"   ğŸ“¡ Ollama API í˜¸ì¶œ: {model_key}")
        print(f"   í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        
        # ëª¨ë¸ë³„ ìµœì í™”ëœ íŒŒë¼ë¯¸í„°
        if "mistral" in model_key.lower():
            options = {
                "temperature": 0.1,      # Mistralì€ ë” ë‚®ì€ temperatureì—ì„œ ë” ì •í™•í•¨
                "top_p": 0.9,            # ë” ì •í™•í•œ ì‘ë‹µì„ ìœ„í•´
                "num_predict": 150,      # Mistralì€ ë” ê¸´ ì‘ë‹µì´ í•„ìš”í•  ìˆ˜ ìˆìŒ
                "repeat_penalty": 1.1,   # Mistralì€ ë°˜ë³µì— ëœ ë¯¼ê°í•¨
                "top_k": 5               # ë” ì§‘ì¤‘ëœ í† í° ì„ íƒ
            }
        elif "gemma" in model_key.lower():
            options = {
                "temperature": 0.05,     # ë” ë‚®ì€ temperatureë¡œ ë¹ ë¥¸ ì‘ë‹µ
                "top_p": 0.8,            # ë” ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´
                "num_predict": 50,       # ë” ì§§ì€ ì‘ë‹µìœ¼ë¡œ ì†ë„ í–¥ìƒ
                "repeat_penalty": 1.0,   # ë°˜ë³µ ë°©ì§€ ìµœì†Œí™”
                "top_k": 3               # ë” ì§‘ì¤‘ëœ í† í° ì„ íƒ
            }
        else:
            options = {
                "temperature": 0.3,      # ì•½ê°„ì˜ ë‹¤ì–‘ì„±ì„ ìœ„í•´ temperature ì¦ê°€
                "top_p": 0.8,            # ë” ë‹¤ì–‘í•œ ì‘ë‹µì„ ìœ„í•´ top_p ì¦ê°€
                "num_predict": 100,      # ì¶©ë¶„í•œ ì‘ë‹µ ê¸¸ì´
                "repeat_penalty": 1.2,   # ë°˜ë³µ ë°©ì§€ ê°•í™”
                "top_k": 10              # ë” ë‹¤ì–‘í•œ í† í° ì„ íƒ
            }
        
        response = requests.post(
            f"{OLLAMA_API_BASE}/api/generate",
            json={
                "model": model_key,
                "prompt": prompt,
                "stream": False,
                "options": options
            },
            timeout=TIMEOUT
        )
        
        print(f"   API ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            response_text = result.get("response", "").strip()
            
            # ëª¨ë¸ë³„ ì‘ë‹µ í›„ì²˜ë¦¬
            if "deepseek" in model_key.lower():
                import re
                # <think>...</think> íƒœê·¸ì™€ ë‚´ìš© ì œê±°
                response_text = re.sub(r'<think>.*?</think>', '', response_text, flags=re.DOTALL)
                # <think> íƒœê·¸ë§Œ ìˆëŠ” ê²½ìš° ì œê±°
                response_text = re.sub(r'<think>\s*</think>', '', response_text)
                response_text = response_text.strip()
                print(f"   âœ… API í˜¸ì¶œ ì„±ê³µ (deepseek íƒœê·¸ ì œê±°): {len(response_text)} ë¬¸ì ì‘ë‹µ")
                print(f"   ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response_text[:100]}...")
            elif "mistral" in model_key.lower():
                import re
                # Mistral ëª¨ë¸ì˜ íŠ¹ë³„í•œ ì‘ë‹µ í˜•ì‹ ì²˜ë¦¬
                # ë¶ˆí•„ìš”í•œ ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ ì œê±°
                response_text = re.sub(r'Here are the extracted tokens?:?', '', response_text, flags=re.IGNORECASE)
                response_text = re.sub(r'The extracted tokens are:?', '', response_text, flags=re.IGNORECASE)
                response_text = re.sub(r'Based on the prompt, the relevant tokens are:?', '', response_text, flags=re.IGNORECASE)
                response_text = response_text.strip()
                print(f"   âœ… API í˜¸ì¶œ ì„±ê³µ (mistral í›„ì²˜ë¦¬): {len(response_text)} ë¬¸ì ì‘ë‹µ")
                print(f"   ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response_text[:100]}...")
            elif "gemma" in model_key.lower():
                import re
                # Gemma ëª¨ë¸ì˜ íŠ¹ë³„í•œ ì‘ë‹µ í˜•ì‹ ì²˜ë¦¬
                # <start_of_turn>model íƒœê·¸ì™€ ë‚´ìš© ì œê±°
                response_text = re.sub(r'<start_of_turn>model\s*', '', response_text, flags=re.IGNORECASE)
                response_text = re.sub(r'<end_of_turn>\s*', '', response_text, flags=re.IGNORECASE)
                # ë¶ˆí•„ìš”í•œ ì„¤ëª…ì´ë‚˜ ì¶”ê°€ í…ìŠ¤íŠ¸ ì œê±°
                response_text = re.sub(r'Here are the extracted tokens?:?', '', response_text, flags=re.IGNORECASE)
                response_text = re.sub(r'The extracted tokens are:?', '', response_text, flags=re.IGNORECASE)
                response_text = response_text.strip()
                print(f"   âœ… API í˜¸ì¶œ ì„±ê³µ (gemma í›„ì²˜ë¦¬): {len(response_text)} ë¬¸ì ì‘ë‹µ")
                print(f"   ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response_text[:100]}...")
            else:
                print(f"   âœ… API í˜¸ì¶œ ì„±ê³µ: {len(response_text)} ë¬¸ì ì‘ë‹µ")
                print(f"   ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response_text[:100]}...")
            
            return response_text
        else:
            print(f"âŒ Ollama API ì˜¤ë¥˜: {response.status_code}")
            print(f"   ì‘ë‹µ ë‚´ìš©: {response.text[:200]}...")
            return None
    except Exception as e:
        print(f"âŒ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        print(f"   ëª¨ë¸: {model_key}")
        print(f"   í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)}")
        return None

def extract_evidence_tokens(prompt: str, model_key: str, domain: str) -> Tuple[List[int], List[str]]:
    """
    ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì—ì„œ evidence í† í°ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        prompt (str): ì›ë³¸ í”„ë¡¬í”„íŠ¸
        model_key (str): ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
        domain (str): ë„ë©”ì¸ ì´ë¦„
    
    Returns:
        tuple: (evidence_indices, evidence_tokens)
    """
    try:
        print(f"ğŸ” Evidence ì¶”ì¶œ ì‹œì‘: {domain} ë„ë©”ì¸")
        print(f"   í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        print(f"   í”„ë¡¬í”„íŠ¸ ë‚´ìš©: {prompt[:100]}...")
        
        domain_instruction = DOMAIN_PROMPTS.get(domain.lower(), "Find important tokens related to the domain.")
        print(f"   ë„ë©”ì¸ ì§€ì‹œì‚¬í•­: {domain_instruction}")
        
        # í”„ë¡¬í”„íŠ¸ë³„ ê³ ìœ í•œ evidence ì¶”ì¶œì„ ìœ„í•œ ê°œì„ ëœ í”„ë¡¬í”„íŠ¸
        # í”„ë¡¬í”„íŠ¸ì˜ ê³ ìœ ì„±ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ í•´ì‹œ ê¸°ë°˜ ì‹ë³„ì ì¶”ê°€
        import hashlib
        prompt_hash = hashlib.md5(prompt.encode()).hexdigest()[:8]
        
        # ëª¨ë¸ë³„ íŠ¹í™” í”„ë¡¬í”„íŠ¸
        if "llama" in model_key.lower():
            evidence_prompt = f"""<s>[INST] Extract ONLY English words from this prompt that are relevant to the {domain} domain.

INPUT: "{prompt}"

RULES:
- Extract ONLY single words from the input
- NO explanations or text
- NO compound phrases - split "heart attack" into ["heart", "attack"]
- Return ONLY JSON array

EXAMPLES:
- "heart attack symptoms" â†’ ["heart", "attack", "symptoms"]
- "processing power" â†’ ["processing", "power"]

RESPONSE (JSON only):
["word1", "word2", "word3"] [/INST]"""
        elif "mistral" in model_key.lower():
            evidence_prompt = f"""<s>[INST] You are a token extraction system. Extract ONLY English words from the given prompt that are relevant to the {domain} domain.

INPUT: "{prompt}"

CRITICAL RULES:
- Extract ONLY single words that exist in the input prompt
- Return ONLY a JSON array format
- NO explanations, NO additional text
- NO compound phrases - split "heart attack" into ["heart", "attack"]
- Focus on domain-specific terms

EXAMPLES:
- Medical: ["symptoms", "heart", "attack", "diagnosis"]
- Legal: ["contract", "liability", "jurisdiction"]
- Technical: ["algorithm", "implementation", "optimization"]

RESPONSE FORMAT (JSON array only):
["word1", "word2", "word3"] [/INST]"""
        elif "gemma" in model_key.lower():
            evidence_prompt = f"""<start_of_turn>user
Extract key words from: "{prompt}"

Domain: {domain}
Format: JSON array only
Example: ["word1", "word2", "word3"]<end_of_turn>
<start_of_turn>model
["word1", "word2", "word3"]<end_of_turn>"""
        else:
            evidence_prompt = f"""
You are an evidence extraction system. Extract the most important English words from the given prompt that are relevant to the {domain} domain.

PROMPT ID: {prompt_hash}
INPUT PROMPT: "{prompt}"

TASK: Identify 3-8 key words from the prompt that are most important for understanding the {domain} domain question.

RULES:
1. Extract ONLY words that appear in the input prompt
2. Focus on domain-specific terms and key concepts
3. Return ONLY a JSON array of strings
4. Do not add explanations or other text
5. Each word should be meaningful and relevant to the domain
6. Consider the specific content of this prompt (ID: {prompt_hash})
7. Extract SINGLE words only, not phrases or compound terms
8. Avoid multi-word expressions like "processing power" - extract "processing" and "power" separately

EXAMPLES:
- Medical: ["symptoms", "heart", "attack", "diagnosis"]
- Legal: ["contract", "liability", "jurisdiction", "legal"]
- Technical: ["algorithm", "implementation", "optimization", "system"]
- Instead of "processing power", extract: ["processing", "power"]
- Instead of "memory capacity", extract: ["memory", "capacity"]

RESPONSE (JSON array only):
["word1", "word2", "word3", "word4"]
"""
        
        print(f"   Ollama API í˜¸ì¶œ ì‹œì‘...")
        # Ollama API í˜¸ì¶œ (ë§¤ë²ˆ ìƒˆë¡œìš´ ì‘ë‹µì„ ìœ„í•´ ìºì‹œ ì—†ì´)
        response_text = call_ollama_api(model_key, evidence_prompt)
        if not response_text:
            print(f"âŒ No response from Ollama API for model {model_key}")
            return [], []
        
        print(f"   í”„ë¡¬í”„íŠ¸ ID: {prompt_hash}")
        print(f"   ì‘ë‹µ ê¸¸ì´: {len(response_text)} ë¬¸ì")
        
        print(f"   Ollama API ì‘ë‹µ ë°›ìŒ: {len(response_text)} ë¬¸ì")
        print(f"   ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response_text[:200]}...")
        
        # ì‘ë‹µì—ì„œ í† í° ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        print(f"   í† í° ì¶”ì¶œ ì‹œì‘...")
        evidence_tokens = extract_tokens_from_response(response_text)
        if not evidence_tokens:
            print(f"âŒ Failed to extract tokens from response: {response_text[:100]}...")
            return [], []
        
        print(f"ğŸ” Extracted {len(evidence_tokens)} tokens from response: {evidence_tokens}")
        
        # ë³µí•©ì–´ ë¶„ë¦¬ ë° ë”°ì˜´í‘œ ì²˜ë¦¬
        print(f"   ë³µí•©ì–´ ë¶„ë¦¬ ë° ë”°ì˜´í‘œ ì²˜ë¦¬: {len(evidence_tokens)}ê°œ í† í°")
        print(f"   ì›ë³¸ evidence í† í°: {evidence_tokens}")
        
        import re
        def clean_token(token) -> str:
            # ì•ŒíŒŒë²³, ìˆ«ì, í•˜ì´í”ˆë§Œ ë‚¨ê¸°ê³  ëª¨ë‘ ì œê±°
            return ' '.join(re.findall(r'[a-zA-Z0-9-]+', str(token)))

        split_tokens = []
        for token in evidence_tokens:
            token_str = clean_token(token)
            for t in token_str.split():
                cleaned = clean_token(t)
                if cleaned:
                    split_tokens.append(cleaned)
        print(f"   ë³µí•©ì–´+í—ˆìš©ë¬¸ìë§Œ ì²˜ë¦¬ ê²°ê³¼: {split_tokens}")
        
        # ì›ë³¸ í”„ë¡¬í”„íŠ¸ì—ì„œ evidence í† í°ì˜ ìœ„ì¹˜ ì°¾ê¸° (ë‹¨ìˆœ ë¬¸ìì—´ ë§¤ì¹­)
        print(f"   ì›ë³¸ í”„ë¡¬í”„íŠ¸ì—ì„œ evidence í† í° ìœ„ì¹˜ ì°¾ê¸°...")
        evidence_indices = []
        evidence_tokens_final = []
        
        for token in split_tokens:
            try:
                index = prompt.lower().find(token.lower())
                if index != -1:
                    evidence_indices.append(index)
                    evidence_tokens_final.append(token)
                    print(f"   âœ… '{token}' ë°œê²¬: ì¸ë±ìŠ¤ {index}")
                else:
                    print(f"   âš ï¸ '{token}' í”„ë¡¬í”„íŠ¸ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            except Exception as e:
                print(f"   âŒ '{token}' ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        
        print(f"ğŸ” Final result: {len(evidence_indices)} indices, {len(evidence_tokens_final)} tokens")
        print(f"   ìµœì¢… evidence í† í°: {evidence_tokens_final}")
        print(f"   ìµœì¢… evidence ì¸ë±ìŠ¤: {evidence_indices}")
        
        return evidence_indices, evidence_tokens_final
        
    except Exception as e:
        print(f"âŒ Evidence ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        print(f"   í”„ë¡¬í”„íŠ¸: {prompt[:100]}...")
        print(f"   ëª¨ë¸: {model_key}")
        print(f"   ë„ë©”ì¸: {domain}")
        return [], []

@st.cache_resource
def load_tokenizer_cached(tokenizer_name: str):
    """í† í¬ë‚˜ì´ì €ë¥¼ ìºì‹œí•˜ì—¬ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        print(f"   ğŸ”§ í† í¬ë‚˜ì´ì € ë¡œë“œ: {tokenizer_name}")
        return AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)
    except Exception as e:
        print(f"   âŒ í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        # trust_remote_code ì—†ì´ ë‹¤ì‹œ ì‹œë„
        try:
            print(f"   ğŸ”§ trust_remote_code=Falseë¡œ ì¬ì‹œë„")
            return AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=False)
        except Exception as e2:
            print(f"   âŒ í† í¬ë‚˜ì´ì € ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: {str(e2)}")
            raise e2

def process_single_prompt_multi_models(prompt_data: Dict[str, Any], model_keys: List[str], domain: str) -> List[Dict[str, Any]]:
    """ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ë¥¼ ì—¬ëŸ¬ ëª¨ë¸ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    results = []
    
    for model_key in model_keys:
        try:
            print(f"ğŸ” í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ì‹œì‘: {domain} ë„ë©”ì¸, {model_key} ëª¨ë¸")
            print(f"   í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt_data['prompt'])} ë¬¸ì")
            print(f"   í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {prompt_data['prompt'][:100]}...")
            
            # ëª¨ë¸ ìƒíƒœ í™•ì¸ (í† í¬ë‚˜ì´ì € ë¶ˆí•„ìš”)
            print(f"   ëª¨ë¸ {model_key} ì¤€ë¹„ ì™„ë£Œ")
            
            # Evidence ì¶”ì¶œ
            print(f"   Evidence ì¶”ì¶œ ì‹œì‘...")
            evidence_indices, evidence_tokens = extract_evidence_tokens(prompt_data["prompt"], model_key, domain)
            print(f"   Evidence ì¶”ì¶œ ê²°ê³¼: {len(evidence_indices)}ê°œ ì¸ë±ìŠ¤, {len(evidence_tokens)}ê°œ í† í°")
            
            # Evidence ì¶”ì¶œ ê²°ê³¼ í™•ì¸
            if not evidence_tokens:
                print(f"   âš ï¸ No evidence tokens extracted for prompt: {prompt_data['prompt'][:50]}...")
                continue
            
            # response í•„ë“œ ì œê±°í•˜ê³  í•„ìš”í•œ í•„ë“œë§Œ í¬í•¨
            cleaned_data = {
                "prompt": prompt_data["prompt"],
                "domain": prompt_data.get("domain", domain),
                "model": model_key,
                "index": prompt_data.get("index", 0),
                "evidence_indices": evidence_indices,
                "evidence_tokens": evidence_tokens,
                "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S")
            }
            
            results.append(cleaned_data)
            print(f"   âœ… í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ì™„ë£Œ: {domain} ë„ë©”ì¸, {model_key} ëª¨ë¸, {len(evidence_tokens)}ê°œ evidence í† í°")
            
        except Exception as e:
            print(f"   âŒ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({model_key}): {str(e)}")
            print(f"   Prompt: {prompt_data.get('prompt', '')[:50]}...")
            print(f"   Domain: {domain}")
            print(f"   Model: {model_key}")
            continue
    
    return results

def process_single_prompt(prompt_data: Dict[str, Any], model_key: str, domain: str) -> Dict[str, Any]:
    """ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤. (ë‹¨ì¼ ëª¨ë¸ìš© - í˜¸í™˜ì„± ìœ ì§€)"""
    max_retries = 2  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
    
    for attempt in range(max_retries + 1):
        try:
            prompt = prompt_data["prompt"]
            if attempt > 0:
                print(f"   ğŸ”„ ì¬ì‹œë„ {attempt}/{max_retries}: {domain} ë„ë©”ì¸")
            else:
                print(f"ğŸ” í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ì‹œì‘: {domain} ë„ë©”ì¸")
            print(f"   í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
            print(f"   í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {prompt[:100]}...")
            
            # Evidence ì¶”ì¶œ (í† í¬ë‚˜ì´ì € ì—†ì´)
            print(f"   Evidence ì¶”ì¶œ ì‹œì‘...")
            evidence_indices, evidence_tokens = extract_evidence_tokens(prompt, model_key, domain)
            print(f"   Evidence ì¶”ì¶œ ê²°ê³¼: {len(evidence_indices)}ê°œ ì¸ë±ìŠ¤, {len(evidence_tokens)}ê°œ í† í°")
            
            # Evidence ì¶”ì¶œ ê²°ê³¼ í™•ì¸
            if not evidence_tokens:
                print(f"   âš ï¸ No evidence tokens extracted for prompt: {prompt[:50]}...")
                if attempt < max_retries:
                    print(f"   ğŸ”„ ì¬ì‹œë„ ì¤‘... (ì ì‹œ ëŒ€ê¸°)")
                    time.sleep(1)  # 1ì´ˆ ëŒ€ê¸°
                    continue
                return None
            
            # response í•„ë“œ ì œê±°í•˜ê³  í•„ìš”í•œ í•„ë“œë§Œ í¬í•¨
            cleaned_data = {
                "prompt": prompt_data["prompt"],
                "domain": prompt_data.get("domain", domain),
                "model": model_key,
                "index": prompt_data.get("index", 0),
                "evidence_indices": evidence_indices,
                "evidence_tokens": evidence_tokens,
                "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S")
            }
            
            print(f"   âœ… í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ì™„ë£Œ: {len(evidence_tokens)}ê°œ evidence í† í°")
            return cleaned_data
            
        except Exception as e:
            print(f"   âŒ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries + 1}): {str(e)}")
            print(f"   Prompt: {prompt_data.get('prompt', '')[:50]}...")
            print(f"   Domain: {domain}")
            print(f"   Model: {model_key}")
            
            if attempt < max_retries:
                print(f"   ğŸ”„ ì¬ì‹œë„ ì¤‘... (ì ì‹œ ëŒ€ê¸°)")
                time.sleep(2)  # 2ì´ˆ ëŒ€ê¸°
                continue
            else:
                print(f"   âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
                return None
    
    return None

def save_domain_data(domain: str, domain_data: List[Dict[str, Any]], model_key: str, timestamp: str) -> Tuple[Path, int]:
    """ë„ë©”ì¸ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        print(f"ğŸ’¾ ì €ì¥ ì‹œì‘: {domain} ë„ë©”ì¸, {len(domain_data)}ê°œ ë°ì´í„°")
        
        # ëª¨ë¸ëª…ì—ì„œ ì½œë¡ ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½ (íŒŒì¼ ì‹œìŠ¤í…œ í˜¸í™˜ì„±)
        safe_model_key = model_key.replace(":", "_")
        output_dir = Path(f"dataset/evidence/{safe_model_key}/{domain.lower()}")
        
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir.mkdir(parents=True, exist_ok=True)
        print(f"âœ… ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ: {output_dir}")
        
        output_path = output_dir / f"{safe_model_key}_{len(domain_data)}prompts_{timestamp}.jsonl"
        print(f"ğŸ“„ ì¶œë ¥ íŒŒì¼ ê²½ë¡œ: {output_path}")
        
        # ë°ì´í„° ê²€ì¦
        print(f"ğŸ” ë°ì´í„° ê²€ì¦:")
        print(f"   - ë°ì´í„° íƒ€ì…: {type(domain_data)}")
        print(f"   - ë°ì´í„° ê°œìˆ˜: {len(domain_data)}")
        
        if len(domain_data) > 0:
            print(f"   - ì²« ë²ˆì§¸ ë°ì´í„° ìƒ˜í”Œ:")
            first_item = domain_data[0]
            print(f"     - Keys: {list(first_item.keys())}")
            print(f"     - Evidence tokens: {first_item.get('evidence_tokens', 'N/A')}")
            print(f"     - Evidence indices: {first_item.get('evidence_indices', 'N/A')}")
        
        # íŒŒì¼ ì €ì¥
        saved_count = 0
        with open(output_path, "w", encoding="utf-8") as f:
            for i, item in enumerate(domain_data):
                try:
                    json_line = json.dumps(item, ensure_ascii=False)
                    f.write(json_line + "\n")
                    saved_count += 1
                    
                    # ì²˜ìŒ 3ê°œì™€ ë§ˆì§€ë§‰ 3ê°œë§Œ ë¡œê·¸
                    if i < 3 or i >= len(domain_data) - 3:
                        print(f"   âœ… ì €ì¥ë¨ ({i+1}/{len(domain_data)}): {len(item.get('evidence_tokens', []))}ê°œ evidence")
                    
                except Exception as item_error:
                    print(f"   âŒ í•­ëª© {i+1} ì €ì¥ ì‹¤íŒ¨: {str(item_error)}")
                    print(f"   í•­ëª© ë‚´ìš©: {item}")
        
        print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {saved_count}/{len(domain_data)}ê°œ í•­ëª© ì €ì¥ë¨")
        print(f"ğŸ“„ íŒŒì¼ í¬ê¸°: {output_path.stat().st_size if output_path.exists() else 0} bytes")
        
        return output_path, saved_count
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ({domain}): {str(e)}")
        print(f"   - ë„ë©”ì¸: {domain}")
        print(f"   - ë°ì´í„° ê°œìˆ˜: {len(domain_data)}")
        print(f"   - ëª¨ë¸: {model_key}")
        print(f"   - íƒ€ì„ìŠ¤íƒ¬í”„: {timestamp}")
        return None, 0

def show():
    st.title("ğŸ” Evidence Extractor")
    st.markdown("ë„ë©”ì¸ë³„ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì—ì„œ evidence í† í°ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.")
    
    # ê°•ì œ ìºì‹œ ë¬´íš¨í™”
    if st.sidebar.button("ğŸ”„ ê°•ì œ ìƒˆë¡œê³ ì¹¨", key="force_refresh_evidence"):
        get_available_models.clear()
        st.success("ìºì‹œê°€ ìƒˆë¡œê³ ì¹¨ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ===== ì„¹ì…˜ 1: ëª¨ë¸ ì„¤ì • =====
    st.markdown("---")
    st.markdown("## ğŸ¤– Model Configuration")
    
    # ì‹¤í—˜ ëª¨ë“œ ì„ íƒ
    experiment_mode = st.radio(
        "Evidence ì¶”ì¶œ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”",
        ["ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ", "ë‹¤ì¤‘ ëª¨ë¸ ì¶”ì¶œ"],
        key="evidence_mode_selector"
    )
    
    # ëª¨ë¸ ì„ íƒ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        available_models = get_available_models()
        if not available_models:
            st.error("âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return
        
        if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
            model_key = st.selectbox(
                "ëª¨ë¸ ì„ íƒ",
                available_models,
                index=0 if available_models else None,
                help="Evidence ì¶”ì¶œì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”."
            )
            selected_models = [model_key]
        else:
            st.markdown("**ğŸ”§ ì¶”ì¶œí•  ëª¨ë¸ë“¤ì„ ì„ íƒí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)**")
            selected_models = st.multiselect(
                "ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤",
                available_models,
                default=[available_models[0]] if available_models else [],
                help="ì—¬ëŸ¬ ëª¨ë¸ì„ ì„ íƒí•˜ë©´ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤."
            )
            model_key = selected_models[0] if selected_models else None
    
    with col2:
        if st.button("ğŸ”„ ëª¨ë¸ ëª©ë¡ ìƒˆë¡œê³ ì¹¨", key="refresh_models_evidence"):
            get_available_models.clear()
            st.success("ëª¨ë¸ ëª©ë¡ì´ ìƒˆë¡œê³ ì¹¨ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
    
    # ëª¨ë¸ ì‹¤í–‰ ìƒíƒœ í™•ì¸
    st.markdown("### ğŸ” Model Status Check")
    
    # ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ëª©ë¡ í‘œì‹œ
    running_models = get_running_models()
    col_status1, col_status2 = st.columns([1, 2])
    
    with col_status1:
        if st.button("ğŸ”„ ìƒíƒœ ìƒˆë¡œê³ ì¹¨", key="refresh_status"):
            st.rerun()
    
    with col_status2:
        if running_models:
            st.success(f"ğŸŸ¢ ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸: {', '.join(running_models)}")
        else:
            st.warning("âšª ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì„ íƒëœ ëª¨ë¸ë“¤ ìƒíƒœ í™•ì¸
    if selected_models:
        st.markdown("**ğŸ“Š ì„ íƒëœ ëª¨ë¸ ìƒíƒœ í™•ì¸**")
        
        for model in selected_models:
            is_running = model in running_models
            is_available = check_model_status(model)
            
            col_status3, col_status4 = st.columns(2)
            
            with col_status3:
                if is_running:
                    st.success(f"âœ… {model} - ì‹¤í–‰ ì¤‘")
                elif is_available:
                    st.info(f"â„¹ï¸ {model} - ì‚¬ìš© ê°€ëŠ¥ (ë¡œë“œ í•„ìš”)")
                else:
                    st.error(f"âŒ {model} - ì‚¬ìš© ë¶ˆê°€")
            
            with col_status4:
                # ëª¨ë¸ ìƒíƒœ í™•ì¸ (í† í¬ë‚˜ì´ì € ë¶ˆí•„ìš”)
                st.success(f"ğŸ”§ {model} - ì¤€ë¹„ ì™„ë£Œ")
        
        # ëª¨ë“  ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
        all_available = all(check_model_status(model) for model in selected_models)
        if not all_available:
            st.warning("âš ï¸ ì¼ë¶€ ëª¨ë¸ì„ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")
            st.markdown("""
            **í•´ê²° ë°©ë²•:**
            1. Model Loader íƒ­ìœ¼ë¡œ ì´ë™
            2. ëª¨ë¸ì„ ì„ íƒí•˜ê³  "ğŸš€ Start Model" í´ë¦­
            3. ë˜ëŠ” í„°ë¯¸ë„ì—ì„œ: `ollama run {model_key}`
            """)
            return
        
        st.success(f"âœ… {len(selected_models)}ê°œ ëª¨ë¸ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        st.warning("âš ï¸ ìµœì†Œ í•˜ë‚˜ì˜ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return
    
    # ===== ì„¹ì…˜ 2: ë„ë©”ì¸ ë° íŒŒì¼ ì„ íƒ =====
    st.markdown("---")
    st.markdown("## ğŸ“ Domain & File Selection")
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ë„ë©”ì¸ í™•ì¸
    origin_dir = Path("dataset/origin")
    if not origin_dir.exists():
        st.error("âŒ `dataset/origin` ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € ë„ë©”ì¸ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return
    
    # ëª¨ë¸ë³„ ë„ë©”ì¸ í™•ì¸
    if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ" and model_key:
        # ë‹¨ì¼ ëª¨ë¸ì˜ ê²½ìš° í•´ë‹¹ ëª¨ë¸ì˜ ë„ë©”ì¸ë§Œ í™•ì¸
        model_origin_dir = Path(f"dataset/origin/{model_key.replace(':', '_')}")
        if not model_origin_dir.exists():
            # ì½œë¡ ì´ ê·¸ëŒ€ë¡œì¸ ê²½ìš°ë„ ì‹œë„
            model_origin_dir = Path(f"dataset/origin/{model_key}")
        
        if model_origin_dir.exists():
            available_domains = [d.name for d in model_origin_dir.iterdir() if d.is_dir()]
        else:
            # ëª¨ë¸ë³„ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
            available_domains = [d.name for d in origin_dir.iterdir() if d.is_dir()]
    else:
        # ë‹¤ì¤‘ ëª¨ë¸ì˜ ê²½ìš° ëª¨ë“  ëª¨ë¸ì˜ ë„ë©”ì¸ì„ í•©ì³ì„œ í™•ì¸
        all_domains = set()
        for model in selected_models:
            model_origin_dir = Path(f"dataset/origin/{model.replace(':', '_')}")
            if not model_origin_dir.exists():
                # ì½œë¡ ì´ ê·¸ëŒ€ë¡œì¸ ê²½ìš°ë„ ì‹œë„
                model_origin_dir = Path(f"dataset/origin/{model}")
            
            if model_origin_dir.exists():
                model_domains = [d.name for d in model_origin_dir.iterdir() if d.is_dir()]
                all_domains.update(model_domains)
        
        # ëª¨ë¸ë³„ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        if not all_domains:
            available_domains = [d.name for d in origin_dir.iterdir() if d.is_dir()]
        else:
            available_domains = list(all_domains)
    
    if not available_domains:
        st.error("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ë„ë©”ì¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë„ë©”ì¸ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return
    
    # ë„ë©”ì¸ ì„ íƒ
    col3, col4 = st.columns([2, 1])
    
    with col3:
        selected_domains = st.multiselect(
            "ë„ë©”ì¸ ì„ íƒ",
            available_domains,
            default=available_domains[:2] if len(available_domains) >= 2 else available_domains,
            help="Evidenceë¥¼ ì¶”ì¶œí•  ë„ë©”ì¸ì„ ì„ íƒí•˜ì„¸ìš”. ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        )
    
    with col4:
        show_info = st.button("ğŸ“Š ë„ë©”ì¸ ì •ë³´ ë³´ê¸°", key="show_domain_info")
    
    # ë„ë©”ì¸ ì •ë³´ í‘œì‹œ
    if show_info:
        st.markdown("---")
        st.subheader("ğŸ“Š Domain Information")
        
        for domain in available_domains:
            # ëª¨ë¸ë³„ ë„ë©”ì¸ ì •ë³´ í‘œì‹œ
            if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ" and model_key:
                prompts = load_origin_prompts(domain, model_key)
                col5, col6 = st.columns([3, 1])
                with col5:
                    st.write(f"ğŸ“„ **{domain}** ë„ë©”ì¸ ({model_key})")
                with col6:
                    st.write(f"ğŸ“ {len(prompts)}ê°œ í”„ë¡¬í”„íŠ¸")
            else:
                # ë‹¤ì¤‘ ëª¨ë¸ ë˜ëŠ” ëª¨ë¸ ë¯¸ì„ íƒ ì‹œ ëª¨ë“  ëª¨ë¸ ì •ë³´ í‘œì‹œ
                total_prompts = 0
                for model in selected_models:
                    prompts = load_origin_prompts(domain, model)
                    total_prompts += len(prompts)
                
                col5, col6 = st.columns([3, 1])
                with col5:
                    st.write(f"ğŸ“„ **{domain}** ë„ë©”ì¸")
                with col6:
                    st.write(f"ğŸ“ {total_prompts}ê°œ í”„ë¡¬í”„íŠ¸ (ì „ì²´ ëª¨ë¸)")
        
        st.info("ğŸ’¡ ë„ë©”ì¸ ì •ë³´ë¥¼ ë‹¤ì‹œ ë³´ë ¤ë©´ 'ğŸ“Š ë„ë©”ì¸ ì •ë³´ ë³´ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
    
    # íŒŒì¼ ì„ íƒ ê¸°ëŠ¥ ì¶”ê°€
    if selected_domains:
        st.markdown("---")
        st.markdown("### ğŸ“„ File Selection")
        
        # íŒŒì¼ ì„ íƒ ëª¨ë“œ ì„ íƒ
        file_selection_mode = st.radio(
            "íŒŒì¼ ì„ íƒ ëª¨ë“œ",
            ["ëª¨ë“  íŒŒì¼ ì‚¬ìš©", "íŠ¹ì • íŒŒì¼ ì„ íƒ"],
            help="ëª¨ë“  íŒŒì¼ì„ ì‚¬ìš©í• ì§€, íŠ¹ì • íŒŒì¼ë§Œ ì„ íƒí• ì§€ ê²°ì •í•©ë‹ˆë‹¤."
        )
        
        if file_selection_mode == "íŠ¹ì • íŒŒì¼ ì„ íƒ":
            st.info("ğŸ’¡ ê° ëª¨ë¸ë³„, ë„ë©”ì¸ë³„ë¡œ ì‚¬ìš©í•  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.")
            
            # ëª¨ë¸ë³„ ë„ë©”ì¸ íŒŒì¼ ì„ íƒ
            model_domain_file_selections = {}
            
            for model in selected_models:
                st.markdown(f"### ğŸ¤– {model} ëª¨ë¸")
                
                for domain in selected_domains:
                    st.markdown(f"#### ğŸ“ {domain} ë„ë©”ì¸ íŒŒì¼ ì„ íƒ")
                    
                    available_files = get_available_files(domain, model)
                    if not available_files:
                        st.warning(f"âš ï¸ {model} ëª¨ë¸ì˜ {domain} ë„ë©”ì¸ì— ì‚¬ìš© ê°€ëŠ¥í•œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                        continue
                    
                    # íŒŒì¼ ì •ë³´ í‘œì‹œ
                    file_options = []
                    for file_info in available_files:
                        file_size_mb = file_info["size"] / (1024 * 1024)
                        file_options.append(f"{file_info['name']} ({file_info['prompt_count']}ê°œ í”„ë¡¬í”„íŠ¸, {file_size_mb:.1f}MB)")
                    
                    selected_files = st.multiselect(
                        f"{model} - {domain} ë„ë©”ì¸ íŒŒì¼ ì„ íƒ",
                        options=[f["name"] for f in available_files],
                        default=[f["name"] for f in available_files[:2]] if len(available_files) >= 2 else [f["name"] for f in available_files],
                        format_func=lambda x: next((opt for opt in file_options if x in opt), x),
                        help=f"{model} ëª¨ë¸ì˜ {domain} ë„ë©”ì¸ì—ì„œ ì‚¬ìš©í•  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”."
                    )
                    
                    if model not in model_domain_file_selections:
                        model_domain_file_selections[model] = {}
                    model_domain_file_selections[model][domain] = selected_files
                    
                    # ì„ íƒëœ íŒŒì¼ ì •ë³´ í‘œì‹œ
                    if selected_files:
                        total_prompts = sum(
                            f["prompt_count"] for f in available_files 
                            if f["name"] in selected_files
                        )
                        st.success(f"âœ… {model} - {domain} ë„ë©”ì¸: {len(selected_files)}ê°œ íŒŒì¼, {total_prompts}ê°œ í”„ë¡¬í”„íŠ¸ ì„ íƒë¨")
                    else:
                        st.warning(f"âš ï¸ {model} - {domain} ë„ë©”ì¸: íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•ŠìŒ")
        
        else:
            # ëª¨ë“  íŒŒì¼ ì‚¬ìš© ëª¨ë“œ
            st.success("âœ… ëª¨ë“  íŒŒì¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            domain_file_selections = None
    
    # ===== ì„¹ì…˜ 3: ë¯¸ë¦¬ë³´ê¸° ê¸°ëŠ¥ =====
    st.markdown("---")
    st.markdown("## ğŸ‘€ Preview Evidence Extraction")
    
    preview_enabled = st.checkbox("ë¯¸ë¦¬ë³´ê¸° í™œì„±í™”", value=True, help="ì‹¤ì œ ì¶”ì¶œ ì „ì— ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    if preview_enabled and selected_domains:
        preview_domain = st.selectbox("ë¯¸ë¦¬ë³´ê¸°í•  ë„ë©”ì¸ ì„ íƒ", selected_domains)
        
        # ì„ íƒëœ íŒŒì¼ì´ ìˆìœ¼ë©´ í•´ë‹¹ íŒŒì¼ì—ì„œë§Œ ë¡œë“œ
        if 'model_domain_file_selections' in locals() and model_domain_file_selections:
            # ì²« ë²ˆì§¸ ëª¨ë¸ì˜ íŒŒì¼ ì„ íƒ ì‚¬ìš© (ë¯¸ë¦¬ë³´ê¸°ìš©)
            first_model = selected_models[0] if selected_models else None
            if first_model and first_model in model_domain_file_selections and preview_domain in model_domain_file_selections[first_model]:
                selected_files = model_domain_file_selections[first_model][preview_domain]
                if selected_files:
                    preview_prompts = load_selected_files(preview_domain, selected_files, first_model)
                else:
                    preview_prompts = []
            else:
                preview_prompts = load_origin_prompts(preview_domain, first_model)
        else:
            # ê¸°ì¡´ ë°©ì‹ (ëª¨ë“  íŒŒì¼ ì‚¬ìš©)
            first_model = selected_models[0] if selected_models else None
            preview_prompts = load_origin_prompts(preview_domain, first_model)
        
        if preview_prompts:
            preview_index = st.slider("ë¯¸ë¦¬ë³´ê¸°í•  í”„ë¡¬í”„íŠ¸ ì¸ë±ìŠ¤", 0, min(len(preview_prompts)-1, 10), 0)
            
            if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
                # ë‹¨ì¼ ëª¨ë¸ ë¯¸ë¦¬ë³´ê¸°
                if st.button("ğŸ” ë¯¸ë¦¬ë³´ê¸° ì‹¤í–‰", key="preview_evidence"):
                    with st.spinner("ë¯¸ë¦¬ë³´ê¸° ì¤‘..."):
                        preview_prompt_data = preview_prompts[preview_index]
                        preview_prompt = preview_prompt_data["prompt"]
                        
                        # í”„ë¡¬í”„íŠ¸ ë¶„ì„ (í† í¬ë‚˜ì´ì € ì—†ì´)
                        prompt_words = preview_prompt.split()
                        print(f"í”„ë¡¬í”„íŠ¸ ë¶„ì„: {len(prompt_words)}ê°œ ë‹¨ì–´")
                        
                        # Evidence ì¶”ì¶œ
                        evidence_indices, evidence_tokens = extract_evidence_tokens(
                            preview_prompt, model_key, preview_domain
                        )
            else:
                # ë‹¤ì¤‘ ëª¨ë¸ ë¯¸ë¦¬ë³´ê¸°
                preview_models = st.multiselect(
                    "ë¯¸ë¦¬ë³´ê¸°í•  ëª¨ë¸ ì„ íƒ",
                    selected_models,
                    default=selected_models[:2] if len(selected_models) >= 2 else selected_models,
                    help="ë¯¸ë¦¬ë³´ê¸°í•  ëª¨ë¸ë“¤ì„ ì„ íƒí•˜ì„¸ìš”."
                )
                
                if st.button("ğŸ” ë‹¤ì¤‘ ëª¨ë¸ ë¯¸ë¦¬ë³´ê¸° ì‹¤í–‰", key="preview_evidence_multi"):
                    with st.spinner("ë‹¤ì¤‘ ëª¨ë¸ ë¯¸ë¦¬ë³´ê¸° ì¤‘..."):
                        preview_prompt_data = preview_prompts[preview_index]
                        preview_prompt = preview_prompt_data["prompt"]
                        
                        # ë‹¤ì¤‘ ëª¨ë¸ë¡œ ì²˜ë¦¬
                        processed_items = process_single_prompt_multi_models(
                            preview_prompt_data, preview_models, preview_domain
                        )
                        
                        if processed_items:
                            st.markdown("### ğŸ“‹ Multi-Model Preview Results")
                            
                            for item in processed_items:
                                model_name = item['model']
                                evidence_tokens = item['evidence_tokens']
                                evidence_indices = item['evidence_indices']
                                
                                st.markdown(f"**ğŸ”§ {model_name} ëª¨ë¸ ê²°ê³¼:**")
                                
                                col7, col8 = st.columns(2)
                                with col7:
                                    st.write(f"**ì¶”ì¶œëœ Evidence í† í° ({len(evidence_tokens)}ê°œ):**")
                                    st.text_area("", str(evidence_tokens), height=100, key=f"preview_evidence_tokens_{model_name}")
                                
                                with col8:
                                    st.write(f"**Evidence í† í° ìœ„ì¹˜ ({len(evidence_indices)}ê°œ):**")
                                    st.text_area("", str(evidence_indices), height=100, key=f"preview_evidence_indices_{model_name}")
                                
                                st.markdown("---")
                        
                        # ì›ë³¸ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
                        st.markdown("### ğŸ“„ Original Prompt")
                        st.text_area("", preview_prompt, height=100, key="preview_prompt_multi")
                        
                        # í”„ë¡¬í”„íŠ¸ ë¶„ì„ (í† í¬ë‚˜ì´ì € ì—†ì´)
                        if preview_models:
                            first_model = preview_models[0]
                            prompt_words = preview_prompt.split()
                            st.write(f"**í”„ë¡¬í”„íŠ¸ ë¶„ì„ (ì°¸ê³ ìš©, {first_model} ê¸°ì¤€):**")
                            st.write(f"ì´ {len(prompt_words)}ê°œ ë‹¨ì–´")
                            st.text_area("", str(prompt_words[:20]) + "..." if len(prompt_words) > 20 else str(prompt_words), height=100, key="preview_words_multi")
        
        # ë‹¨ì¼ ëª¨ë¸ ë¯¸ë¦¬ë³´ê¸° ê²°ê³¼ í‘œì‹œ
        if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ" and 'preview_prompt' in locals():
            # ê²°ê³¼ í‘œì‹œ
            st.markdown("### ğŸ“‹ Preview Results")
            
            col7, col8 = st.columns(2)
            with col7:
                st.write("**ì›ë³¸ í”„ë¡¬í”„íŠ¸:**")
                st.text_area("", preview_prompt, height=100, key="preview_prompt")
                
                st.write("**í”„ë¡¬í”„íŠ¸ ë¶„ì„ (ì°¸ê³ ìš©):**")
                prompt_words = preview_prompt.split()
                st.write(f"ì´ {len(prompt_words)}ê°œ ë‹¨ì–´")
                st.text_area("", str(prompt_words[:20]) + "..." if len(prompt_words) > 20 else str(prompt_words), height=100, key="preview_words")
            
            with col8:
                st.write("**ì¶”ì¶œëœ Evidence í† í°:**")
                st.write(f"ì´ {len(evidence_tokens)}ê°œ í† í°")
                st.text_area("", str(evidence_tokens), height=100, key="preview_evidence_tokens")
                
                st.write("**Evidence í† í° ìœ„ì¹˜ (ì›ë³¸ í”„ë¡¬í”„íŠ¸ ê¸°ì¤€):**")
                st.write(f"ì´ {len(evidence_indices)}ê°œ ìœ„ì¹˜")
                st.text_area("", str(evidence_indices), height=100, key="preview_evidence_indices")
                
                # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
                st.markdown("### ğŸ” Debug Information")
                
                # LLM ì‘ë‹µ í™•ì¸
                domain_instruction = DOMAIN_PROMPTS.get(preview_domain.lower(), "Find important tokens related to the domain.")
                debug_prompt = f"""
You are an English-only evidence extraction system. Your task is to extract English tokens from the given prompt.

DOMAIN: {preview_domain}
INSTRUCTION: {domain_instruction}

INPUT PROMPT: "{preview_prompt}"

CRITICAL RULES:
1. You MUST respond ONLY in English
2. You MUST extract ONLY English words that exist in the input prompt
3. You MUST return ONLY a JSON array format
4. You MUST NOT translate words
5. You MUST NOT add words that are not in the prompt
6. You MUST NOT respond in Korean or any other language
7. You MUST focus on domain-specific medical/technical terms

EXAMPLES:
- For medical domain: ["clinical", "findings", "diagnosis", "viral", "encephalitis", "adults"]
- For legal domain: ["legal", "contract", "liability", "jurisdiction"]
- For technical domain: ["algorithm", "implementation", "optimization"]

RESPONSE FORMAT (JSON array only):
["word1", "word2", "word3"]
"""
                
                debug_response = call_ollama_api(model_key, debug_prompt)
                
                col9, col10 = st.columns(2)
                with col9:
                    st.write("**LLM ì‘ë‹µ (ì›ë³¸):**")
                    st.text_area("", debug_response or "No response", height=150, key="debug_response")
                    
                    st.write("**ì¶”ì¶œëœ í† í° (íŒŒì‹± í›„):**")
                    parsed_tokens = extract_tokens_from_response(debug_response) if debug_response else []
                    st.text_area("", str(parsed_tokens), height=100, key="debug_parsed_tokens")
                
                with col10:
                    st.write("**í† í° ë§¤ì¹­ ê²°ê³¼:**")
                    prompt_lower = preview_prompt.lower()
                    matching_info = []
                    for token in parsed_tokens or []:
                        token_lower = token.lower().strip()
                        is_in_prompt = token_lower in prompt_lower
                        import re
                        pattern = r'\b' + re.escape(token_lower) + r'\b'
                        is_word_boundary = bool(re.search(pattern, prompt_lower))
                        matching_info.append(f"'{token}': in_prompt={is_in_prompt}, word_boundary={is_word_boundary}")
                    
                    st.text_area("", "\n".join(matching_info), height=150, key="debug_matching")
                
                # ì¸ë±ìŠ¤ ê³„ì‚° ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
                st.markdown("### ğŸ” Index Calculation Debug")
                
                col11, col12 = st.columns(2)
                with col11:
                    st.write("**ì›ë³¸ í”„ë¡¬í”„íŠ¸ ë¶„ì„:**")
                    prompt_analysis = f"í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(preview_prompt)} ë¬¸ì\n"
                    prompt_analysis += f"ë‹¨ì–´ ìˆ˜: {len(preview_prompt.split())}ê°œ\n"
                    prompt_analysis += f"ë¬¸ìë³„ ë¶„ì„:\n"
                    for i, char in enumerate(preview_prompt[:100]):  # ì²˜ìŒ 100ìë§Œ
                        if i % 20 == 0:
                            prompt_analysis += f"\n{i:3d}: "
                        prompt_analysis += char
                    st.text_area("", prompt_analysis, height=200, key="prompt_analysis")
                
                with col12:
                    st.write("**Evidence í† í° ìœ„ì¹˜ í™•ì¸ (í† í° ë‹¨ìœ„):**")
                    position_info = []
                    
                    # ì›ë³¸ evidence í† í°ê³¼ ì¸ë±ìŠ¤ ë§¤ì¹­
                    original_tokens = extract_tokens_from_response(debug_response) if debug_response else []
                    english_tokens = []
                    for token in original_tokens or []:
                        token_clean = token.lower().strip()
                        if token_clean and all(c.isascii() and c.isalnum() or c.isspace() for c in token_clean):
                            english_tokens.append(token_clean)
                    
                    # ê° í† í°ì— ëŒ€í•œ ì¸ë±ìŠ¤ ì°¾ê¸° (ì›ë³¸ í”„ë¡¬í”„íŠ¸ì—ì„œ ë‹¨ìˆœ ë§¤ì¹­)
                    position_info = []
                    for token in english_tokens:
                        index = preview_prompt.lower().find(token.lower())
                        if index != -1:
                            position_info.append(f"'{token}' at char pos {index}: '{preview_prompt[index:index+len(token)]}' âœ…")
                        else:
                            position_info.append(f"'{token}': not found in prompt âŒ")
                    
                    st.text_area("", "\n".join(position_info), height=200, key="position_info")
                
                # ìµœì¢… ë°ì´í„°ì…‹ í•­ëª© ë¯¸ë¦¬ë³´ê¸°
                st.markdown("### ğŸ“Š Final Dataset Item Preview")
                final_item = {
                    "prompt": preview_prompt_data["prompt"],
                    "domain": preview_prompt_data.get("domain", preview_domain),
                    "model": model_key,
                    "index": preview_prompt_data.get("index", preview_index),
                    "evidence_indices": evidence_indices,
                    "evidence_tokens": evidence_tokens,
                    "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S")
                }
                st.json(final_item)
        else:
            st.warning(f"âš ï¸ {preview_domain} ë„ë©”ì¸ì— í”„ë¡¬í”„íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ===== ì„¹ì…˜ 4: Evidence ì¶”ì¶œ ì‹¤í–‰ =====
    st.markdown("---")
    st.markdown("## âš™ï¸ Extraction Settings")
    
    # Evidence ì¶”ì¶œ ì„¤ì •
    col9, col10 = st.columns([1, 2])
    
    with col9:
        batch_size = st.number_input(
            "ë°°ì¹˜ í¬ê¸°",
            min_value=1,
            max_value=50,
            value=10,
            help="í•œ ë²ˆì— ì²˜ë¦¬í•  í”„ë¡¬í”„íŠ¸ ê°œìˆ˜ì…ë‹ˆë‹¤."
        )
        
        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì˜µì…˜ ì¶”ê°€
        test_mode = st.checkbox(
            "í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì²˜ìŒ 5ê°œë§Œ ì²˜ë¦¬)",
            value=False,
            help="ì²˜ìŒ 5ê°œì˜ í”„ë¡¬í”„íŠ¸ë§Œ ì²˜ë¦¬í•˜ì—¬ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
        )
    
    with col10:
        st.info("âœ… ì„ íƒëœ ë„ë©”ì¸ì˜ ëª¨ë“  í”„ë¡¬í”„íŠ¸ì—ì„œ evidence í† í°ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.")
    
    # Evidence ì¶”ì¶œ ë²„íŠ¼
    col11, col12 = st.columns([2, 1])
    
    with col11:
        extract_button = st.button("ğŸ” Extract Evidence", type="primary", key="extract_evidence")
    
    with col12:
        if st.button("ğŸ—‘ï¸ ìºì‹œ ì´ˆê¸°í™”", key="clear_cache_evidence"):
            get_available_models.clear()
            st.success("ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ===== Evidence ì¶”ì¶œ ì‹¤í–‰ =====
    if extract_button and selected_domains:
        try:
            # ì‚¬ì „ ì²´í¬
            st.markdown("### ğŸ” Pre-Extraction Check")
            
            # 1. ëª¨ë¸ ìƒíƒœ í™•ì¸
            if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
                # ë‹¨ì¼ ëª¨ë¸ ì²´í¬
                is_model_running = model_key in get_running_models()
                if is_model_running:
                    st.success(f"âœ… ëª¨ë¸ {model_key} ì‹¤í–‰ ì¤‘")
                else:
                    st.error(f"âŒ ëª¨ë¸ {model_key} ì‹¤í–‰ë˜ì§€ ì•ŠìŒ")
                    st.warning("ğŸ’¡ Model Loader íƒ­ì—ì„œ ëª¨ë¸ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                    return
                
                # ëª¨ë¸ ìƒíƒœë§Œ í™•ì¸ (í† í¬ë‚˜ì´ì € ë¶ˆí•„ìš”)
                st.success(f"âœ… ëª¨ë¸ {model_key} ì¤€ë¹„ ì™„ë£Œ")
            else:
                # ë‹¤ì¤‘ ëª¨ë¸ ì²´í¬
                for model in selected_models:
                    is_model_running = model in get_running_models()
                    if is_model_running:
                        st.success(f"âœ… ëª¨ë¸ {model} ì‹¤í–‰ ì¤‘")
                    else:
                        st.warning(f"âš ï¸ ëª¨ë¸ {model} ì‹¤í–‰ë˜ì§€ ì•ŠìŒ (ìë™ ë¡œë“œ ì‹œë„)")
                    
                    # ëª¨ë¸ ìƒíƒœë§Œ í™•ì¸ (í† í¬ë‚˜ì´ì € ë¶ˆí•„ìš”)
                    st.success(f"âœ… {model} ì¤€ë¹„ ì™„ë£Œ")
            
            # 2. ë„ë©”ì¸ë³„ í”„ë¡¬í”„íŠ¸ í™•ì¸
            for domain in selected_domains:
                for model in selected_models:
                    # ì„ íƒëœ íŒŒì¼ì´ ìˆìœ¼ë©´ í•´ë‹¹ íŒŒì¼ì—ì„œë§Œ ë¡œë“œ
                    if 'model_domain_file_selections' in locals() and model_domain_file_selections and model in model_domain_file_selections and domain in model_domain_file_selections[model]:
                        selected_files = model_domain_file_selections[model][domain]
                        if selected_files:
                            prompts = load_selected_files(domain, selected_files, model)
                            st.success(f"âœ… {model} - {domain} ë„ë©”ì¸: {len(prompts)}ê°œ í”„ë¡¬í”„íŠ¸ (ì„ íƒëœ íŒŒì¼: {len(selected_files)}ê°œ)")
                        else:
                            st.error(f"âŒ {model} - {domain} ë„ë©”ì¸: ì„ íƒëœ íŒŒì¼ì´ ì—†ìŒ")
                            return
                    else:
                        prompts = load_origin_prompts(domain, model)
                        if prompts:
                            st.success(f"âœ… {model} - {domain} ë„ë©”ì¸: {len(prompts)}ê°œ í”„ë¡¬í”„íŠ¸ (ëª¨ë“  íŒŒì¼)")
                        else:
                            st.error(f"âŒ {model} - {domain} ë„ë©”ì¸: í”„ë¡¬í”„íŠ¸ ì—†ìŒ")
                            return
            
            st.success("âœ… ëª¨ë“  ì‚¬ì „ ì²´í¬ í†µê³¼! Evidence ì¶”ì¶œì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            st.markdown("---")
            
            # ì „ì²´ ì‹œì‘ ì‹œê°„ ê¸°ë¡
            total_start_time = time.time()
            
            # ì§„í–‰ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ ì»¨í…Œì´ë„ˆë“¤
            progress_text = st.empty()
            progress_counter = st.empty()
            time_info = st.empty()
            
            # ìµœì¢… ë°ì´í„°ì…‹ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
            final_datasets = []
            
            # ì „ì²´ ì‘ì—…ëŸ‰ ê³„ì‚°
            total_tasks = len(selected_domains) * len(selected_models)
            completed_tasks = 0
            
            for domain_idx, domain in enumerate(selected_domains, 1):
                for model_idx, model in enumerate(selected_models, 1):
                    # ëª¨ë¸ë³„ ë„ë©”ì¸ë³„ ì‹œì‘ ì‹œê°„ ê¸°ë¡
                    model_domain_start_time = time.time()
                    
                    # ëª¨ë¸ë³„ ë„ë©”ì¸ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
                    if 'model_domain_file_selections' in locals() and model_domain_file_selections and model in model_domain_file_selections and domain in model_domain_file_selections[model]:
                        selected_files = model_domain_file_selections[model][domain]
                        if selected_files:
                            prompts = load_selected_files(domain, selected_files, model)
                        else:
                            st.warning(f"âš ï¸ {model} - {domain} ë„ë©”ì¸ì— ì„ íƒëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                            continue
                    else:
                        prompts = load_origin_prompts(domain, model)
                    
                    if not prompts:
                        st.warning(f"âš ï¸ {model} - {domain} ë„ë©”ì¸ì— í”„ë¡¬í”„íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        continue
                
                    # í…ŒìŠ¤íŠ¸ ëª¨ë“œì¸ ê²½ìš° ì²˜ìŒ 5ê°œë§Œ ì²˜ë¦¬
                    if test_mode:
                        prompts = prompts[:5]
                        st.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {model} - {domain} ë„ë©”ì¸ì—ì„œ ì²˜ìŒ 5ê°œ í”„ë¡¬í”„íŠ¸ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                
                if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
                    # ë‹¨ì¼ ëª¨ë¸ ì²˜ë¦¬
                    progress_text.text(f"Extracting evidence from {domain} domain prompts using {model}...")
                    
                    with st.spinner(f"Extracting evidence from {len(prompts)} prompts in {domain} domain using {model} ({domain_idx}/{len(selected_domains)})..."):
                        for i, prompt_data in enumerate(prompts):
                            # ì§„í–‰ìƒí™© ì¹´ìš´í„° ì—…ë°ì´íŠ¸
                            progress_counter.text(f"{model} - {domain} domain: {i+1}/{len(prompts)}")
                            
                            # ì‹œê°„ ì •ë³´ ì—…ë°ì´íŠ¸
                            current_time = time.time()
                            elapsed_time = current_time - total_start_time
                            
                            # ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
                            def get_domain_prompt_count(d, m):
                                if 'model_domain_file_selections' in locals() and model_domain_file_selections and m in model_domain_file_selections and d in model_domain_file_selections[m]:
                                    selected_files = model_domain_file_selections[m][d]
                                    if selected_files:
                                        return len(load_selected_files(d, selected_files, m))
                                return len(load_origin_prompts(d, m))
                            
                            total_prompts_to_process = sum(get_domain_prompt_count(d, model) for d in selected_domains)
                            completed_prompts = sum(get_domain_prompt_count(d, model) for d in selected_domains[:domain_idx-1]) + i
                            if completed_prompts > 0:
                                avg_time_per_prompt = elapsed_time / completed_prompts
                                remaining_prompts = total_prompts_to_process - completed_prompts
                                estimated_remaining_time = avg_time_per_prompt * remaining_prompts
                                estimated_total_time = elapsed_time + estimated_remaining_time
                                
                                time_info.text(f"ì†Œìš”ì‹œê°„: {elapsed_time:.1f}ì´ˆ | ì˜ˆìƒì™„ë£Œ: {estimated_total_time:.1f}ì´ˆ | ë‚¨ì€ì‹œê°„: {estimated_remaining_time:.1f}ì´ˆ")
                            else:
                                time_info.text(f"ì†Œìš”ì‹œê°„: {elapsed_time:.1f}ì´ˆ | ì˜ˆìƒì™„ë£Œ: ê³„ì‚° ì¤‘...")
                            
                            # ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ (ë°°ì¹˜ í¬ê¸° ì œí•œ)
                            batch_size = 50  # 50ê°œì”© ì²˜ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬ ë¶€í•˜ ê°ì†Œ
                            
                            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
                            if i % batch_size == 0:
                                print(f"ğŸ“¦ ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {i+1}-{min(i+batch_size, len(prompts))}/{len(prompts)}")
                                # ë°°ì¹˜ ê°„ ì ì‹œ ëŒ€ê¸° (ë©”ëª¨ë¦¬ ì •ë¦¬)
                                if i > 0:
                                    time.sleep(0.5)
                            
                            processed_item = process_single_prompt(prompt_data, model, domain)
                            if processed_item:
                                final_datasets.append(processed_item)
                                # ë””ë²„ê¹…: ì„±ê³µí•œ ê²½ìš° ë¡œê·¸
                                if (i + 1) % 10 == 0:
                                    print(f"âœ… Processed {i+1}/{len(prompts)} prompts in {model} - {domain} domain - Evidence tokens: {len(processed_item.get('evidence_tokens', []))}")
                            else:
                                # ë””ë²„ê¹…: ì‹¤íŒ¨í•œ ê²½ìš° ìƒì„¸ ë¡œê·¸
                                print(f"âŒ Failed to process prompt {i+1} in {model} - {domain} domain")
                                if i < 3:  # ì²˜ìŒ 3ê°œë§Œ ìƒì„¸ ë¡œê·¸
                                    print(f"   Prompt: {prompt_data.get('prompt', '')[:100]}...")
                                    print(f"   Domain: {domain}")
                                    print(f"   Model: {model}")
                                    print(f"   Evidence extraction failed")
                                if (i + 1) % 10 == 0:
                                    print(f"âŒ Failed {i+1}/{len(prompts)} prompts in {model} - {domain} domain")
                        
                        # ëª¨ë¸ë³„ ë„ë©”ì¸ë³„ ì™„ë£Œ ì‹œê°„ ê³„ì‚°
                        model_domain_end_time = time.time()
                        model_domain_duration = model_domain_end_time - model_domain_start_time
                        print(f"{model} - {domain} domain evidence extraction completed in {model_domain_duration:.2f} seconds")
                        
                        # ì‘ì—… ì™„ë£Œ ì¹´ìš´í„° ì¦ê°€
                        completed_tasks += 1
                
                else:
                    # ë‹¤ì¤‘ ëª¨ë¸ ì²˜ë¦¬ - í˜„ì¬ ëª¨ë¸ë§Œ ì²˜ë¦¬
                    progress_text.text(f"Extracting evidence from {domain} domain prompts using {model}...")
                    
                    with st.spinner(f"Extracting evidence from {len(prompts)} prompts in {domain} domain using {model} ({domain_idx}/{len(selected_domains)})..."):
                        for i, prompt_data in enumerate(prompts):
                            # ì§„í–‰ìƒí™© ì¹´ìš´í„° ì—…ë°ì´íŠ¸
                            progress_counter.text(f"{model} - {domain} domain: {i+1}/{len(prompts)}")
                            
                            # ì‹œê°„ ì •ë³´ ì—…ë°ì´íŠ¸
                            current_time = time.time()
                            elapsed_time = current_time - total_start_time
                            
                            # ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
                            def get_domain_prompt_count(d, m):
                                if 'model_domain_file_selections' in locals() and model_domain_file_selections and m in model_domain_file_selections and d in model_domain_file_selections[m]:
                                    selected_files = model_domain_file_selections[m][d]
                                    if selected_files:
                                        return len(load_selected_files(d, selected_files, m))
                                return len(load_origin_prompts(d, m))
                            
                            total_prompts_to_process = sum(get_domain_prompt_count(d, m) for d in selected_domains for m in selected_models)
                            completed_prompts = sum(get_domain_prompt_count(d, m) for d in selected_domains[:domain_idx-1] for m in selected_models) + sum(get_domain_prompt_count(domain, m) for m in selected_models[:model_idx-1]) + i
                            if completed_prompts > 0:
                                avg_time_per_prompt = elapsed_time / completed_prompts
                                remaining_prompts = total_prompts_to_process - completed_prompts
                                estimated_remaining_time = avg_time_per_prompt * remaining_prompts
                                estimated_total_time = elapsed_time + estimated_remaining_time
                                
                                time_info.text(f"ì†Œìš”ì‹œê°„: {elapsed_time:.1f}ì´ˆ | ì˜ˆìƒì™„ë£Œ: {estimated_total_time:.1f}ì´ˆ | ë‚¨ì€ì‹œê°„: {estimated_remaining_time:.1f}ì´ˆ")
                            else:
                                time_info.text(f"ì†Œìš”ì‹œê°„: {elapsed_time:.1f}ì´ˆ | ì˜ˆìƒì™„ë£Œ: ê³„ì‚° ì¤‘...")
                            
                            # ë‹¨ì¼ ëª¨ë¸ë¡œ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
                            print(f"ğŸ”§ Processing prompt {i+1}/{len(prompts)} in {model} - {domain} domain")
                            
                            processed_item = process_single_prompt(prompt_data, model, domain)
                            if processed_item:
                                final_datasets.append(processed_item)
                                # ë””ë²„ê¹…: ì„±ê³µí•œ ê²½ìš° ë¡œê·¸
                                if (i + 1) % 10 == 0:
                                    print(f"âœ… Processed {i+1}/{len(prompts)} prompts in {model} - {domain} domain - Evidence tokens: {len(processed_item.get('evidence_tokens', []))}")
                            else:
                                # ë””ë²„ê¹…: ì‹¤íŒ¨í•œ ê²½ìš° ìƒì„¸ ë¡œê·¸
                                print(f"âŒ Failed to process prompt {i+1} in {model} - {domain} domain")
                                if i < 3:  # ì²˜ìŒ 3ê°œë§Œ ìƒì„¸ ë¡œê·¸
                                    print(f"   Prompt: {prompt_data.get('prompt', '')[:100]}...")
                                    print(f"   Domain: {domain}")
                                    print(f"   Model: {model}")
                                    print(f"   Evidence extraction failed")
                                if (i + 1) % 10 == 0:
                                    print(f"âŒ Failed {i+1}/{len(prompts)} prompts in {model} - {domain} domain")
                        
                        # ëª¨ë¸ë³„ ë„ë©”ì¸ë³„ ì™„ë£Œ ì‹œê°„ ê³„ì‚°
                        model_domain_end_time = time.time()
                        model_domain_duration = model_domain_end_time - model_domain_start_time
                        print(f"{model} - {domain} domain evidence extraction completed in {model_domain_duration:.2f} seconds")
            
            # ì „ì²´ ì™„ë£Œ ì‹œê°„ ê³„ì‚°
            total_end_time = time.time()
            total_duration = total_end_time - total_start_time
            
            # ì§„í–‰ìƒí™© í‘œì‹œ ì •ë¦¬
            progress_text.empty()
            progress_counter.empty()
            time_info.empty()
            
            # ===== ìµœì¢… ë°ì´í„°ì…‹ ì €ì¥ =====
            st.markdown("---")
            st.subheader("ğŸ’¾ Saving Final Dataset")
            
            # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
            st.info(f"ğŸ“Š ì´ ì²˜ë¦¬ëœ ë°ì´í„°: {len(final_datasets)}ê°œ")
            st.info(f"ğŸ¯ ì„ íƒëœ ë„ë©”ì¸: {', '.join(selected_domains)}")
            
            # final_datasets ìƒì„¸ ë¶„ì„
            print(f"ğŸ” Final datasets ë¶„ì„:")
            print(f"   - ì´ ë°ì´í„° ê°œìˆ˜: {len(final_datasets)}")
            
            if len(final_datasets) > 0:
                print(f"   - ì²« ë²ˆì§¸ ë°ì´í„° ìƒ˜í”Œ:")
                first_data = final_datasets[0]
                print(f"     - Keys: {list(first_data.keys())}")
                print(f"     - Domain: {first_data.get('domain', 'N/A')}")
                print(f"     - Model: {first_data.get('model', 'N/A')}")
                print(f"     - Evidence tokens: {first_data.get('evidence_tokens', [])}")
                print(f"     - Evidence indices: {first_data.get('evidence_indices', [])}")
                
                # ëª¨ë“  ë°ì´í„°ì˜ ëª¨ë¸ ì •ë³´ í™•ì¸
                print(f"   - ëª¨ë“  ë°ì´í„°ì˜ ëª¨ë¸ ì •ë³´:")
                model_info = {}
                for i, data in enumerate(final_datasets):
                    model = data.get('model', 'N/A')
                    domain = data.get('domain', 'N/A')
                    if model not in model_info:
                        model_info[model] = {'count': 0, 'domains': set()}
                    model_info[model]['count'] += 1
                    model_info[model]['domains'].add(domain)
                    
                    # ì²˜ìŒ 5ê°œë§Œ ìƒì„¸ ì¶œë ¥
                    if i < 5:
                        print(f"     [{i}] Model: {model}, Domain: {domain}, Evidence tokens: {len(data.get('evidence_tokens', []))}")
                
                print(f"   - ëª¨ë¸ë³„ ìš”ì•½:")
                for model, info in model_info.items():
                    domains_str = ', '.join(sorted(info['domains']))
                    print(f"     {model}: {info['count']}ê°œ ({domains_str})")
            else:
                print(f"   - final_datasetsì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
                print(f"   - ì„ íƒëœ ëª¨ë¸ë“¤: {selected_models}")
                print(f"   - ì„ íƒëœ ë„ë©”ì¸ë“¤: {selected_domains}")
            
            # ë„ë©”ì¸ë³„ ë° ëª¨ë¸ë³„ ë°ì´í„° ë¶„í¬ í™•ì¸
            domain_distribution = {}
            model_distribution = {}
            for item in final_datasets:
                domain = item.get('domain', 'unknown')
                model = item.get('model', 'unknown')
                domain_distribution[domain] = domain_distribution.get(domain, 0) + 1
                model_distribution[model] = model_distribution.get(model, 0) + 1
            
            print(f"   - ë„ë©”ì¸ë³„ ë¶„í¬: {domain_distribution}")
            print(f"   - ëª¨ë¸ë³„ ë¶„í¬: {model_distribution}")
            
            # ê° ë„ë©”ì¸ë³„ ì²˜ë¦¬ ê²°ê³¼ í‘œì‹œ
            for domain in selected_domains:
                # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ë§¤ì¹­
                domain_data = [item for item in final_datasets if item["domain"].lower() == domain.lower()]
                if domain_data:
                    st.success(f"âœ… {domain} ë„ë©”ì¸: {len(domain_data)}ê°œ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ")
                    print(f"âœ… {domain} ë„ë©”ì¸: {len(domain_data)}ê°œ ë°ì´í„° í™•ì¸ë¨")
                else:
                    st.error(f"âŒ {domain} ë„ë©”ì¸: ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨")
                    print(f"âŒ {domain} ë„ë©”ì¸: ë°ì´í„° ì—†ìŒ")
                    # ì‹¤íŒ¨ ì›ì¸ ë¶„ì„
                    prompts = load_origin_prompts(domain)
                    if prompts:
                        st.warning(f"   - ì›ë³¸ í”„ë¡¬í”„íŠ¸: {len(prompts)}ê°œ ì¡´ì¬")
                        if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
                            st.warning(f"   - ëª¨ë¸ ìƒíƒœ: {'ì‹¤í–‰ ì¤‘' if model_key in get_running_models() else 'ì‹¤í–‰ë˜ì§€ ì•ŠìŒ'}")
                            st.warning(f"   - í† í¬ë‚˜ì´ì €: {MODEL_TOKENIZER_MAP.get(model_key, 'ì—†ìŒ')}")
                        else:
                            st.warning(f"   - ì„ íƒëœ ëª¨ë¸ë“¤: {', '.join(selected_models)}")
            
            # ë‹¤ì¤‘ ëª¨ë¸ì¸ ê²½ìš° ëª¨ë¸ë³„ ì²˜ë¦¬ ê²°ê³¼ë„ í‘œì‹œ
            if experiment_mode == "ë‹¤ì¤‘ ëª¨ë¸ ì¶”ì¶œ":
                st.markdown("**ğŸ“Š ëª¨ë¸ë³„ ì²˜ë¦¬ ê²°ê³¼**")
                for model in selected_models:
                    model_data = [item for item in final_datasets if item["model"] == model]
                    if model_data:
                        st.success(f"âœ… {model}: {len(model_data)}ê°œ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ")
                        print(f"âœ… {model}: {len(model_data)}ê°œ ë°ì´í„° í™•ì¸ë¨")
                    else:
                        st.error(f"âŒ {model}: ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨")
                        print(f"âŒ {model}: ë°ì´í„° ì—†ìŒ")
            
            # ë„ë©”ì¸ë³„ë¡œ íŒŒì¼ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            saved_files = []
            
            print(f"ğŸ’¾ ì €ì¥ ì‹œì‘ - íƒ€ì„ìŠ¤íƒ¬í”„: {timestamp}")
            
            if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
                # ë‹¨ì¼ ëª¨ë¸ ì €ì¥
                for domain in selected_domains:
                    # ë„ë©”ì¸ë³„ ë°ì´í„° í•„í„°ë§ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
                    domain_data = [item for item in final_datasets if item["domain"].lower() == domain.lower()]
                    
                    st.info(f"ğŸ“‹ {domain} ë„ë©”ì¸ ë°ì´í„°: {len(domain_data)}ê°œ")
                    print(f"ğŸ“‹ {domain} ë„ë©”ì¸ ì €ì¥ ì¤€ë¹„: {len(domain_data)}ê°œ ë°ì´í„°")
                    
                    if domain_data:
                        output_path, count = save_domain_data(domain, domain_data, model_key, timestamp)
                        if output_path:
                            saved_files.append((domain, output_path, count))
                            st.success(f"âœ… {domain} ë„ë©”ì¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
                            print(f"âœ… {domain} ë„ë©”ì¸ ì €ì¥ ì„±ê³µ: {output_path} ({count}ê°œ)")
                        else:
                            st.error(f"âŒ {domain} ë„ë©”ì¸ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")
                            print(f"âŒ {domain} ë„ë©”ì¸ ì €ì¥ ì‹¤íŒ¨")
                    else:
                        st.warning(f"âš ï¸ {domain} ë„ë©”ì¸ì— ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        print(f"âš ï¸ {domain} ë„ë©”ì¸: ì €ì¥í•  ë°ì´í„° ì—†ìŒ")
                        st.info(f"ğŸ’¡ ì›ì¸: evidence ì¶”ì¶œ ê³¼ì •ì—ì„œ ëª¨ë“  í”„ë¡¬í”„íŠ¸ê°€ ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        st.info(f"ğŸ’¡ í•´ê²°: ë¯¸ë¦¬ë³´ê¸° ê¸°ëŠ¥ìœ¼ë¡œ ê°œë³„ í”„ë¡¬í”„íŠ¸ë¥¼ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”.")
            else:
                # ë‹¤ì¤‘ ëª¨ë¸ ì €ì¥ - ëª¨ë¸ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ì €ì¥
                for model in selected_models:
                    st.markdown(f"**ğŸ“Š {model} ëª¨ë¸ ê²°ê³¼ ì €ì¥**")
                    
                    for domain in selected_domains:
                        # ëª¨ë¸ê³¼ ë„ë©”ì¸ë³„ ë°ì´í„° í•„í„°ë§
                        domain_data = [item for item in final_datasets 
                                     if item["domain"].lower() == domain.lower() and item["model"] == model]
                        
                        st.info(f"ğŸ“‹ {domain} ë„ë©”ì¸ ({model}): {len(domain_data)}ê°œ")
                        print(f"ğŸ“‹ {domain} ë„ë©”ì¸ ({model}) ì €ì¥ ì¤€ë¹„: {len(domain_data)}ê°œ ë°ì´í„°")
                        
                        if domain_data:
                            output_path, count = save_domain_data(domain, domain_data, model, timestamp)
                            if output_path:
                                saved_files.append((f"{domain} ({model})", output_path, count))
                                st.success(f"âœ… {domain} ë„ë©”ì¸ ({model}) íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
                                print(f"âœ… {domain} ë„ë©”ì¸ ({model}) ì €ì¥ ì„±ê³µ: {output_path} ({count}ê°œ)")
                            else:
                                st.error(f"âŒ {domain} ë„ë©”ì¸ ({model}) íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")
                                print(f"âŒ {domain} ë„ë©”ì¸ ({model}) ì €ì¥ ì‹¤íŒ¨")
                        else:
                            st.warning(f"âš ï¸ {domain} ë„ë©”ì¸ ({model})ì— ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            print(f"âš ï¸ {domain} ë„ë©”ì¸ ({model}): ì €ì¥í•  ë°ì´í„° ì—†ìŒ")
            
            # ===== ìµœì¢… ê²°ê³¼ í‘œì‹œ =====
            st.markdown("---")
            st.subheader("âœ… Evidence Extraction Complete!")
            
            # ê²°ê³¼ ìš”ì•½ì„ ì»¬ëŸ¼ìœ¼ë¡œ ë°°ì¹˜
            col13, col14, col15 = st.columns(3)
            
            with col13:
                st.metric("ì´ ì†Œìš” ì‹œê°„", f"{total_duration:.1f}ì´ˆ")
            
            with col14:
                if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
                    st.metric("ì²˜ë¦¬ëœ ë„ë©”ì¸", f"{len(selected_domains)}ê°œ")
                else:
                    st.metric("ì²˜ë¦¬ëœ ë„ë©”ì¸", f"{len(selected_domains)}ê°œ")
            
            with col15:
                total_generated = len(final_datasets)
                if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
                    st.metric("ìƒì„±ëœ ë°ì´í„°ì…‹", f"{total_generated}ê°œ")
                else:
                    st.metric("ìƒì„±ëœ ë°ì´í„°ì…‹", f"{total_generated}ê°œ")
            
            # ë‹¤ì¤‘ ëª¨ë¸ ê²°ê³¼ ìš”ì•½
            if experiment_mode == "ë‹¤ì¤‘ ëª¨ë¸ ì¶”ì¶œ":
                st.markdown("**ğŸ“Š ëª¨ë¸ë³„ ê²°ê³¼ ìš”ì•½**")
                
                model_summary = {}
                for item in final_datasets:
                    model_name = item['model']
                    if model_name not in model_summary:
                        model_summary[model_name] = {'count': 0, 'domains': set()}
                    model_summary[model_name]['count'] += 1
                    model_summary[model_name]['domains'].add(item['domain'])
                
                for model_name, summary in model_summary.items():
                    domains_str = ', '.join(sorted(summary['domains']))
                    st.info(f"**{model_name}**: {summary['count']}ê°œ ê²°ê³¼ ({domains_str} ë„ë©”ì¸)")
            
            # ìƒì„±ëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ
            st.markdown("---")
            st.subheader("ğŸ“‹ Generated Files")
            
            if saved_files:
                for domain, file_path, count in saved_files:
                    with st.container():
                        col16, col17 = st.columns([3, 1])
                        with col16:
                            # íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                            if file_path.exists():
                                st.write(f"ğŸ“„ **{domain}** ë„ë©”ì¸: `{file_path.name}` ({count}ê°œ í•­ëª©) âœ…")
                            else:
                                st.write(f"ğŸ“„ **{domain}** ë„ë©”ì¸: `{file_path.name}` ({count}ê°œ í•­ëª©) âŒ íŒŒì¼ ì—†ìŒ")
                        with col17:
                            st.write(f"ğŸ“ `{file_path.parent}`")
                
                # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì •ë³´
                if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
                    safe_model_key = model_key.replace(":", "_")
                    st.info(f"ğŸ“ ëª¨ë“  íŒŒì¼ì´ `dataset/evidence/{safe_model_key}/` ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.info(f"ğŸ“ ê° ëª¨ë¸ë³„ë¡œ `dataset/evidence/[ëª¨ë¸ëª…]/` ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    for model in selected_models:
                        safe_model_key = model.replace(":", "_")
                        st.info(f"   - {model}: `dataset/evidence/{safe_model_key}/`")
                
                # íŒŒì¼ í¬ê¸° ì •ë³´ í‘œì‹œ
                st.markdown("---")
                st.subheader("ğŸ“ File Information")
                for domain, file_path, count in saved_files:
                    if file_path.exists():
                        file_size = file_path.stat().st_size
                        st.write(f"ğŸ“„ {domain}: {file_size:,} bytes ({file_size/1024:.1f} KB)")
            else:
                st.warning("âš ï¸ ì €ì¥ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                st.info("ğŸ’¡ Evidence ì¶”ì¶œì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            st.session_state.evidence_extraction_error = str(e)
            print(f"Evidence extraction error: {str(e)}")
    
    # Evidence ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì²˜ë¦¬
    if extract_button and not selected_domains:
        st.error("âŒ ë„ë©”ì¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”!")
    
    # Evidence ì¶”ì¶œ ì¤‘ ì—ëŸ¬ ì²˜ë¦¬
    if 'evidence_extraction_error' in st.session_state:
        st.markdown("---")
        st.subheader("âŒ Evidence Extraction Failed")
        
        # ì—ëŸ¬ ì •ë³´ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë°°ì¹˜
        col18, col19 = st.columns([2, 1])
        
        with col18:
            st.error(f"Evidence ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:")
            st.code(st.session_state.evidence_extraction_error)
        
        with col19:
            st.warning("ğŸ’¡ í•´ê²° ë°©ë²•:")
            st.write("1. í† í¬ë‚˜ì´ì €ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
            st.write("2. ëª¨ë¸ì´ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸")
            st.write("3. í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸")
        
        # ì—ëŸ¬ ìƒíƒœ ì •ë¦¬
        del st.session_state.evidence_extraction_error 