import streamlit as st
import json
import time
from datetime import datetime
from pathlib import Path
import requests
from transformers import AutoTokenizer
import re
import ast
from typing import List, Tuple, Optional, Dict, Any

# ìƒìˆ˜ ì •ì˜
OLLAMA_API_BASE = "http://localhost:11434"
TIMEOUT = 30

# ëª¨ë¸ë³„ í† í¬ë‚˜ì´ì € ë§¤í•‘
MODEL_TOKENIZER_MAP = {
    "gemma:7b": "google/gemma-7b",
    "mistral:7b": "mistralai/Mistral-7B-v0.1",
    "qwen:7b": "Qwen/Qwen-7B",
    "llama2:7b": "meta-llama/Llama-2-7b-hf",
    "llama2:13b": "meta-llama/Llama-2-13b-hf",
    "llama2:70b": "meta-llama/Llama-2-70b-hf",
    "deepseek-r1:7b": "deepseek-ai/deepseek-llm-7b-base",
    "deepseek-r1-distill-llama:8b": "deepseek-ai/DeepSeek-R1-Distill-Llama-8B"
}

# ë„ë©”ì¸ë³„ evidence ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
DOMAIN_PROMPTS = {
    "economy": "Find tokens related to economy, finance, market, investment, currency, and trade.",
    "legal": "Find tokens related to law, regulations, contracts, rights, and obligations.",
    "medical": "Find tokens related to medicine, health, disease, treatment, and drugs.",
    "technical": "Find tokens related to technology, science, engineering, computers, and systems."
}

@st.cache_data(ttl=300)
def get_available_models() -> List[str]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ Ollama ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        response = requests.get(f"{OLLAMA_API_BASE}/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get("models", [])
            return [model["name"] for model in models]
        return []
    except Exception as e:
        print(f"Error fetching models: {e}")
        return []

def check_model_status(model_key: str) -> bool:
    """íŠ¹ì • ëª¨ë¸ì˜ ì‹¤í–‰ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    try:
        # ë¨¼ì € ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ëª©ë¡ í™•ì¸
        response = requests.get(f"{OLLAMA_API_BASE}/api/ps", timeout=5)
        if response.status_code == 200:
            running_models = response.json().get("models", [])
            model_names = [model["name"] for model in running_models]
            if model_key in model_names:
                return True
        
        # ì‹¤í–‰ ì¤‘ì´ ì•„ë‹ˆë¼ë©´ ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í…ŒìŠ¤íŠ¸
        response = requests.post(
            f"{OLLAMA_API_BASE}/api/generate",
            json={
                "model": model_key,
                "prompt": "test",
                "stream": False,
                "options": {
                    "num_predict": 1
                }
            },
            timeout=10
        )
        
        if response.status_code == 200:
            # ì‘ë‹µì´ ì„±ê³µí•˜ë©´ ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•¨
            return True
        elif response.status_code == 404:
            # ëª¨ë¸ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ
            return False
        else:
            # ê¸°íƒ€ ì˜¤ë¥˜
            return False
            
    except Exception as e:
        print(f"ëª¨ë¸ ìƒíƒœ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return False

def get_running_models() -> List[str]:
    """ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        response = requests.get(f"{OLLAMA_API_BASE}/api/ps", timeout=5)
        if response.status_code == 200:
            running_models = response.json().get("models", [])
            return [model["name"] for model in running_models]
        return []
    except Exception as e:
        print(f"ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return []

def load_file_data(file_path: Path) -> List[Dict[str, Any]]:
    """íŒŒì¼ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            if file_path.suffix == ".json":
                data = json.load(f)
                return data if isinstance(data, list) else [data]
            elif file_path.suffix == ".jsonl":
                return [json.loads(line) for line in f if line.strip()]
    except Exception as e:
        print(f"Error loading {file_path}: {e}")
    return []

def load_origin_prompts(domain: str) -> List[Dict[str, Any]]:
    """ë„ë©”ì¸ë³„ origin í”„ë¡¬í”„íŠ¸ íŒŒì¼ë“¤ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    origin_dir = Path(f"dataset/origin/{domain.lower()}")
    if not origin_dir.exists():
        return []
    
    all_prompts = []
    
    # ëª¨ë“  JSON ë° JSONL íŒŒì¼ ì²˜ë¦¬
    for file_path in origin_dir.glob("*.json*"):
        file_data = load_file_data(file_path)
        all_prompts.extend(file_data)
    
    return all_prompts

def find_token_positions(prompt: str, tokens: List[str], tokenizer) -> List[int]:
    """í”„ë¡¬í”„íŠ¸ì—ì„œ í† í°ë“¤ì˜ ìœ„ì¹˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤ (í† í° ë‹¨ìœ„ ì¸ë±ìŠ¤)."""
    try:
        # í”„ë¡¬í”„íŠ¸ë¥¼ í† í°í™”
        tokenized = tokenizer.tokenize(prompt)
        token_indices = []
        
        # ê° evidence í† í°ì— ëŒ€í•´ í† í° ì¸ë±ìŠ¤ ì°¾ê¸°
        for evidence_token in tokens:
            evidence_token_lower = evidence_token.lower()
            found_index = -1  # ê¸°ë³¸ê°’ -1 (ì°¾ì§€ ëª»í•¨)
            
            # í† í°í™”ëœ ë¦¬ìŠ¤íŠ¸ì—ì„œ ë§¤ì¹­ë˜ëŠ” í† í° ì°¾ê¸°
            for i, token in enumerate(tokenized):
                # Ä  ë¬¸ì ì œê±°í•˜ê³  í† í°ì„ ë””ì½”ë”©í•˜ì—¬ ì›ë³¸ í…ìŠ¤íŠ¸ì™€ ë¹„êµ
                clean_token = token.replace('Ä ', '')
                decoded_token = tokenizer.convert_tokens_to_string([token]).strip()
                
                # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ ì¶”ê°€
                print(f"   ë§¤ì¹­ ì‹œë„: evidence='{evidence_token_lower}' vs clean_token='{clean_token.lower()}' vs decoded='{decoded_token.lower()}'")
                
                # ì„¸ ê°€ì§€ ë°©ë²• ëª¨ë‘ ì‹œë„
                if (clean_token.lower() == evidence_token_lower or 
                    decoded_token.lower() == evidence_token_lower or
                    token.lower() == evidence_token_lower):
                    found_index = i
                    print(f"   âœ… ë§¤ì¹­ ì„±ê³µ: {evidence_token_lower} -> ì¸ë±ìŠ¤ {i}")
                    break  # ì²« ë²ˆì§¸ ë§¤ì¹­ë§Œ ì°¾ê¸°
            
            token_indices.append(found_index)
        
        return token_indices
        
    except Exception as e:
        print(f"í† í° ìœ„ì¹˜ ì°¾ê¸° ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return [-1] * len(tokens)  # ëª¨ë“  í† í°ì— ëŒ€í•´ -1 ë°˜í™˜

def extract_tokens_from_response(response_text: str) -> Optional[List[str]]:
    """ëª¨ë¸ ì‘ë‹µì—ì„œ í† í° ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        print(f"   ğŸ” í† í° ì¶”ì¶œ ì‹œì‘: {len(response_text)} ë¬¸ì ì‘ë‹µ")
        
        # JSON í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
        import re
        import ast
        
        # JSON ë°°ì—´ íŒ¨í„´ ì°¾ê¸°
        list_match = re.search(r'\[[^\]]+\]', response_text)
        if list_match:
            print(f"   JSON ë°°ì—´ íŒ¨í„´ ë°œê²¬: {list_match.group()}")
            try:
                evidence_tokens = ast.literal_eval(list_match.group())
                if isinstance(evidence_tokens, list):
                    # ë¬¸ìì—´ë§Œ í•„í„°ë§
                    result = [str(token).strip() for token in evidence_tokens if token]
                    print(f"   âœ… JSON ë°°ì—´ì—ì„œ ì¶”ì¶œ: {len(result)}ê°œ í† í°")
                    return result
            except Exception as json_error:
                print(f"   âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {str(json_error)}")
                pass
        
        # ë”°ì˜´í‘œë¡œ ë‘˜ëŸ¬ì‹¸ì¸ í† í°ë“¤ ì¶”ì¶œ
        print(f"   ë”°ì˜´í‘œ íŒ¨í„´ìœ¼ë¡œ ì¶”ì¶œ ì‹œë„...")
        quoted_tokens = re.findall(r'["\']([^"\']+)["\']', response_text)
        if quoted_tokens:
            result = [token.strip() for token in quoted_tokens if token.strip()]
            print(f"   âœ… ë”°ì˜´í‘œ íŒ¨í„´ì—ì„œ ì¶”ì¶œ: {len(result)}ê°œ í† í°")
            return result
        
        # ê³µë°±ìœ¼ë¡œ êµ¬ë¶„ëœ ë‹¨ì–´ë“¤ ì¶”ì¶œ (ë§ˆì§€ë§‰ ìˆ˜ë‹¨)
        print(f"   ë‹¨ì–´ íŒ¨í„´ìœ¼ë¡œ ì¶”ì¶œ ì‹œë„...")
        words = re.findall(r'\b\w+\b', response_text)
        if words:
            result = [word.strip() for word in words if word.strip()]
            print(f"   âœ… ë‹¨ì–´ íŒ¨í„´ì—ì„œ ì¶”ì¶œ: {len(result)}ê°œ í† í°")
            return result
        
        print(f"   âŒ ëª¨ë“  ì¶”ì¶œ ë°©ë²• ì‹¤íŒ¨")
        return None
        
    except Exception as e:
        print(f"âŒ í† í° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        print(f"   ì‘ë‹µ í…ìŠ¤íŠ¸: {response_text[:100]}...")
        return None

def call_ollama_api(model_key: str, prompt: str) -> Optional[str]:
    """Ollama APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤."""
    try:
        print(f"   ğŸ“¡ Ollama API í˜¸ì¶œ: {model_key}")
        print(f"   í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        
        response = requests.post(
            f"{OLLAMA_API_BASE}/api/generate",
            json={
                "model": model_key,
                "prompt": prompt,
                "stream": False,
                "options": {
                    "temperature": 0.0,  # ë” ë‚®ì€ temperatureë¡œ ì¼ê´€ëœ ì‘ë‹µ
                    "top_p": 0.1,        # ë” ë‚®ì€ top_pë¡œ í™•ì‹¤í•œ ì‘ë‹µ
                    "num_predict": 50,    # ì§§ì€ ì‘ë‹µìœ¼ë¡œ ì œí•œ
                    "repeat_penalty": 1.1, # ë°˜ë³µ ë°©ì§€
                    "top_k": 1           # ê°€ì¥ í™•ì‹¤í•œ í† í°ë§Œ ì„ íƒ
                }
            },
            timeout=TIMEOUT
        )
        
        print(f"   API ì‘ë‹µ ìƒíƒœ ì½”ë“œ: {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            response_text = result.get("response", "").strip()
            
            # deepseek ëª¨ë¸ì˜ <think> íƒœê·¸ ì œê±°
            if "deepseek" in model_key.lower():
                import re
                # <think>...</think> íƒœê·¸ì™€ ë‚´ìš© ì œê±°
                response_text = re.sub(r'<think>.*?</think>', '', response_text, flags=re.DOTALL)
                # <think> íƒœê·¸ë§Œ ìˆëŠ” ê²½ìš° ì œê±°
                response_text = re.sub(r'<think>\s*</think>', '', response_text)
                response_text = response_text.strip()
                print(f"   âœ… API í˜¸ì¶œ ì„±ê³µ (deepseek íƒœê·¸ ì œê±°): {len(response_text)} ë¬¸ì ì‘ë‹µ")
            else:
                print(f"   âœ… API í˜¸ì¶œ ì„±ê³µ: {len(response_text)} ë¬¸ì ì‘ë‹µ")
            
            return response_text
        else:
            print(f"âŒ Ollama API ì˜¤ë¥˜: {response.status_code}")
            print(f"   ì‘ë‹µ ë‚´ìš©: {response.text[:200]}...")
            return None
    except Exception as e:
        print(f"âŒ API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        print(f"   ëª¨ë¸: {model_key}")
        print(f"   í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)}")
        return None

def extract_evidence_tokens(prompt: str, model_key: str, domain: str) -> Tuple[List[int], List[str]]:
    """
    ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì—ì„œ evidence í† í°ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        prompt (str): ì›ë³¸ í”„ë¡¬í”„íŠ¸
        model_key (str): ì‚¬ìš©í•  ëª¨ë¸ ì´ë¦„
        domain (str): ë„ë©”ì¸ ì´ë¦„
    
    Returns:
        tuple: (evidence_indices, evidence_tokens)
    """
    try:
        print(f"ğŸ” Evidence ì¶”ì¶œ ì‹œì‘: {domain} ë„ë©”ì¸")
        print(f"   í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        
        domain_instruction = DOMAIN_PROMPTS.get(domain.lower(), "Find important tokens related to the domain.")
        print(f"   ë„ë©”ì¸ ì§€ì‹œì‚¬í•­: {domain_instruction}")
        
        # Evidence ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ê°•ë ¥í•œ ì˜ì–´ ì‘ë‹µ ê°•ì œ)
        evidence_prompt = f"""
You are an English-only evidence extraction system. Your task is to extract English tokens from the given prompt.

DOMAIN: {domain}
INSTRUCTION: {domain_instruction}

INPUT PROMPT: "{prompt}"

CRITICAL RULES:
1. You MUST respond ONLY in English
2. You MUST extract ONLY English words that exist in the input prompt
3. You MUST return ONLY a JSON array format
4. You MUST NOT translate words
5. You MUST NOT add words that are not in the prompt
6. You MUST NOT respond in Korean or any other language
7. You MUST focus on domain-specific medical/technical terms

EXAMPLES:
- For medical domain: ["clinical", "findings", "diagnosis", "viral", "encephalitis", "adults"]
- For legal domain: ["legal", "contract", "liability", "jurisdiction"]
- For technical domain: ["algorithm", "implementation", "optimization"]

RESPONSE FORMAT (JSON array only):
["word1", "word2", "word3"]
"""
        
        print(f"   Ollama API í˜¸ì¶œ ì‹œì‘...")
        # Ollama API í˜¸ì¶œ
        response_text = call_ollama_api(model_key, evidence_prompt)
        if not response_text:
            print(f"âŒ No response from Ollama API for model {model_key}")
            return [], []
        
        print(f"   Ollama API ì‘ë‹µ ë°›ìŒ: {len(response_text)} ë¬¸ì")
        print(f"   ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response_text[:200]}...")
        
        # ì‘ë‹µì—ì„œ í† í° ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ
        print(f"   í† í° ì¶”ì¶œ ì‹œì‘...")
        evidence_tokens = extract_tokens_from_response(response_text)
        if not evidence_tokens:
            print(f"âŒ Failed to extract tokens from response: {response_text[:100]}...")
            return [], []
        
        print(f"ğŸ” Extracted {len(evidence_tokens)} tokens from response: {evidence_tokens}")
        
        # ì˜ì–´ í† í°ë§Œ í•„í„°ë§
        print(f"   ì˜ì–´ í† í° í•„í„°ë§ ì‹œì‘...")
        english_tokens = []
        for token in evidence_tokens:
            token_clean = token.lower().strip()
            # ì˜ì–´ ë‹¨ì–´ë§Œ í—ˆìš© (í•œêµ­ì–´, íŠ¹ìˆ˜ë¬¸ì ì œì™¸)
            if token_clean and all(c.isascii() and c.isalnum() or c.isspace() for c in token_clean):
                english_tokens.append(token_clean)
        
        print(f"   ì˜ì–´ í† í° í•„í„°ë§ ê²°ê³¼: {len(english_tokens)}ê°œ")
        
        if not english_tokens:
            print(f"âŒ No valid English tokens found after filtering")
            return [], []
        
        print(f"ğŸ” Found {len(english_tokens)} valid English tokens: {english_tokens}")
        
        # í”„ë¡¬í”„íŠ¸ë¥¼ ì†Œë¬¸ìë¡œ ë³€í™˜í•˜ì—¬ ë§¤ì¹­
        print(f"   í”„ë¡¬í”„íŠ¸ ë§¤ì¹­ ì‹œì‘...")
        prompt_lower = prompt.lower()
        valid_tokens = []
        
        for token in english_tokens:
            # í”„ë¡¬í”„íŠ¸ì— ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ (ë‹¨ì–´ ê²½ê³„ ê³ ë ¤)
            if token in prompt_lower:
                # ì›ë³¸ í”„ë¡¬í”„íŠ¸ì—ì„œ ì •í™•í•œ í† í° ì°¾ê¸°
                import re
                pattern = r'\b' + re.escape(token) + r'\b'
                if re.search(pattern, prompt_lower):
                    valid_tokens.append(token)
        
        print(f"   í”„ë¡¬í”„íŠ¸ ë§¤ì¹­ ê²°ê³¼: {len(valid_tokens)}ê°œ")
        
        if not valid_tokens:
            print(f"âŒ No tokens matched in prompt after word boundary check")
            return [], []
        
        print(f"ğŸ” Found {len(valid_tokens)} tokens that match in prompt: {valid_tokens}")
        
        # í† í¬ë‚˜ì´ì € ë¡œë“œ (ì„ íƒì )
        print(f"   í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹œì‘...")
        tokenizer_name = MODEL_TOKENIZER_MAP.get(model_key)
        print(f"{model_key} : {tokenizer_name}")
        
        if tokenizer_name:
            try:
                tokenizer = load_tokenizer_cached(tokenizer_name)
                print(f"   í† í¬ë‚˜ì´ì € ë¡œë“œ ì™„ë£Œ: {tokenizer_name}")
                
                # í† í° ìœ„ì¹˜ ì°¾ê¸° (í† í° ë‹¨ìœ„ ì¸ë±ìŠ¤)
                print(f"   í† í° ìœ„ì¹˜ ì°¾ê¸° ì‹œì‘...")
                indices = find_token_positions(prompt, valid_tokens, tokenizer)
                print(f"   í† í° ìœ„ì¹˜ ì°¾ê¸° ê²°ê³¼: {indices}")
                
                # ìœ íš¨í•œ ì¸ë±ìŠ¤ë§Œ í•„í„°ë§ (-1ì´ ì•„ë‹Œ ê²ƒë“¤)
                valid_indices = [idx for idx in indices if idx != -1]
                valid_tokens_with_indices = [token for i, token in enumerate(valid_tokens) if indices[i] != -1]
                
                print(f"ğŸ” Final result: {len(valid_indices)} indices, {len(valid_tokens_with_indices)} tokens")
                print(f"   ìµœì¢… evidence í† í°: {valid_tokens_with_indices}")
                print(f"   ìµœì¢… evidence ì¸ë±ìŠ¤: {valid_indices}")
                
                return valid_indices, valid_tokens_with_indices
                
            except Exception as e:
                print(f"   âš ï¸ í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹¤íŒ¨, ë”ë¯¸ ì¸ë±ìŠ¤ ì‚¬ìš©: {str(e)}")
                # í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ì¸ë±ìŠ¤ ì‚¬ìš©
                dummy_indices = list(range(len(valid_tokens)))
                print(f"   ğŸ” Using dummy indices: {dummy_indices}")
                return dummy_indices, valid_tokens
        else:
            print(f"   âš ï¸ Tokenizer not found for model {model_key}")
            
            # í† í¬ë‚˜ì´ì €ê°€ ì—†ëŠ” ëª¨ë¸ì˜ ê²½ìš° ë”ë¯¸ ì¸ë±ìŠ¤ ì‚¬ìš©
            dummy_indices = list(range(len(valid_tokens)))
            print(f"   ğŸ” Using dummy indices: {dummy_indices}")
            return dummy_indices, valid_tokens
        
    except Exception as e:
        print(f"âŒ Evidence ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        print(f"   í”„ë¡¬í”„íŠ¸: {prompt[:100]}...")
        print(f"   ëª¨ë¸: {model_key}")
        print(f"   ë„ë©”ì¸: {domain}")
        return [], []

@st.cache_resource
def load_tokenizer_cached(tokenizer_name: str):
    """í† í¬ë‚˜ì´ì €ë¥¼ ìºì‹œí•˜ì—¬ ë¡œë“œí•©ë‹ˆë‹¤."""
    try:
        print(f"   ğŸ”§ í† í¬ë‚˜ì´ì € ë¡œë“œ: {tokenizer_name}")
        return AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=True)
    except Exception as e:
        print(f"   âŒ í† í¬ë‚˜ì´ì € ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        # trust_remote_code ì—†ì´ ë‹¤ì‹œ ì‹œë„
        try:
            print(f"   ğŸ”§ trust_remote_code=Falseë¡œ ì¬ì‹œë„")
            return AutoTokenizer.from_pretrained(tokenizer_name, trust_remote_code=False)
        except Exception as e2:
            print(f"   âŒ í† í¬ë‚˜ì´ì € ë¡œë“œ ìµœì¢… ì‹¤íŒ¨: {str(e2)}")
            raise e2

def process_single_prompt_multi_models(prompt_data: Dict[str, Any], model_keys: List[str], domain: str) -> List[Dict[str, Any]]:
    """ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ë¥¼ ì—¬ëŸ¬ ëª¨ë¸ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    results = []
    
    for model_key in model_keys:
        try:
            print(f"ğŸ” í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ì‹œì‘: {domain} ë„ë©”ì¸, {model_key} ëª¨ë¸")
            print(f"   í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt_data['prompt'])} ë¬¸ì")
            print(f"   í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {prompt_data['prompt'][:100]}...")
            
            # í† í¬ë‚˜ì´ì € ì´ë¦„ í™•ì¸
            tokenizer_name = MODEL_TOKENIZER_MAP.get(model_key)
            if not tokenizer_name:
                print(f"   âš ï¸ Tokenizer not found for model {model_key}")
                continue
            
            # í† í¬ë‚˜ì´ì € ë¡œë“œ
            tokenizer = load_tokenizer_cached(tokenizer_name)
            tokens = tokenizer.tokenize(prompt_data["prompt"])
            print(f"   í† í¬ë‚˜ì´ì§• ì™„ë£Œ: {len(tokens)}ê°œ í† í°")
            
            # Evidence ì¶”ì¶œ
            print(f"   Evidence ì¶”ì¶œ ì‹œì‘...")
            evidence_indices, evidence_tokens = extract_evidence_tokens(prompt_data["prompt"], model_key, domain)
            print(f"   Evidence ì¶”ì¶œ ê²°ê³¼: {len(evidence_indices)}ê°œ ì¸ë±ìŠ¤, {len(evidence_tokens)}ê°œ í† í°")
            
            # Evidence ì¶”ì¶œ ê²°ê³¼ í™•ì¸
            if not evidence_tokens:
                print(f"   âš ï¸ No evidence tokens extracted for prompt: {prompt_data['prompt'][:50]}...")
                continue
            
            # response í•„ë“œ ì œê±°í•˜ê³  í•„ìš”í•œ í•„ë“œë§Œ í¬í•¨
            cleaned_data = {
                "prompt": prompt_data["prompt"],
                "domain": prompt_data.get("domain", domain),
                "model": model_key,
                "index": prompt_data.get("index", 0),
                "evidence_indices": evidence_indices,
                "evidence_tokens": evidence_tokens,
                "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S")
            }
            
            results.append(cleaned_data)
            print(f"   âœ… í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ì™„ë£Œ: {domain} ë„ë©”ì¸, {model_key} ëª¨ë¸, {len(evidence_tokens)}ê°œ evidence í† í°")
            
        except Exception as e:
            print(f"   âŒ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ({model_key}): {str(e)}")
            print(f"   Prompt: {prompt_data.get('prompt', '')[:50]}...")
            print(f"   Domain: {domain}")
            print(f"   Model: {model_key}")
            continue
    
    return results

def process_single_prompt(prompt_data: Dict[str, Any], model_key: str, domain: str, tokenizer_name: str) -> Dict[str, Any]:
    """ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤. (ë‹¨ì¼ ëª¨ë¸ìš© - í˜¸í™˜ì„± ìœ ì§€)"""
    try:
        prompt = prompt_data["prompt"]
        print(f"ğŸ” í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ì‹œì‘: {domain} ë„ë©”ì¸")
        print(f"   í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        print(f"   í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {prompt[:100]}...")
        
        # í† í¬ë‚˜ì´ì € ë¡œë“œ
        tokenizer = load_tokenizer_cached(tokenizer_name)
        tokens = tokenizer.tokenize(prompt)
        print(f"   í† í¬ë‚˜ì´ì§• ì™„ë£Œ: {len(tokens)}ê°œ í† í°")
        
        # Evidence ì¶”ì¶œ
        print(f"   Evidence ì¶”ì¶œ ì‹œì‘...")
        evidence_indices, evidence_tokens = extract_evidence_tokens(prompt, model_key, domain)
        print(f"   Evidence ì¶”ì¶œ ê²°ê³¼: {len(evidence_indices)}ê°œ ì¸ë±ìŠ¤, {len(evidence_tokens)}ê°œ í† í°")
        
        # Evidence ì¶”ì¶œ ê²°ê³¼ í™•ì¸
        if not evidence_tokens:
            print(f"   âš ï¸ No evidence tokens extracted for prompt: {prompt[:50]}...")
            return None
        
        # response í•„ë“œ ì œê±°í•˜ê³  í•„ìš”í•œ í•„ë“œë§Œ í¬í•¨
        cleaned_data = {
            "prompt": prompt_data["prompt"],
            "domain": prompt_data.get("domain", domain),
            "model": model_key,
            "index": prompt_data.get("index", 0),
            "evidence_indices": evidence_indices,
            "evidence_tokens": evidence_tokens,
            "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S")
        }
        
        print(f"   âœ… í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ì™„ë£Œ: {len(evidence_tokens)}ê°œ evidence í† í°")
        return cleaned_data
        
    except Exception as e:
        print(f"   âŒ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        print(f"   Prompt: {prompt_data.get('prompt', '')[:50]}...")
        print(f"   Domain: {domain}")
        print(f"   Model: {model_key}")
        print(f"   Tokenizer: {tokenizer_name}")
        return None

def save_domain_data(domain: str, domain_data: List[Dict[str, Any]], model_key: str, timestamp: str) -> Tuple[Path, int]:
    """ë„ë©”ì¸ ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
    try:
        print(f"ğŸ’¾ ì €ì¥ ì‹œì‘: {domain} ë„ë©”ì¸, {len(domain_data)}ê°œ ë°ì´í„°")
        
        # ëª¨ë¸ëª…ì—ì„œ ì½œë¡ ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€ê²½ (íŒŒì¼ ì‹œìŠ¤í…œ í˜¸í™˜ì„±)
        safe_model_key = model_key.replace(":", "_")
        output_dir = Path(f"dataset/{safe_model_key}/{domain.lower()}")
        
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        output_dir.mkdir(parents=True, exist_ok=True)
        print(f"âœ… ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ: {output_dir}")
        
        output_path = output_dir / f"{safe_model_key}_{len(domain_data)}prompts_{timestamp}.jsonl"
        print(f"ğŸ“„ ì¶œë ¥ íŒŒì¼ ê²½ë¡œ: {output_path}")
        
        # ë°ì´í„° ê²€ì¦
        print(f"ğŸ” ë°ì´í„° ê²€ì¦:")
        print(f"   - ë°ì´í„° íƒ€ì…: {type(domain_data)}")
        print(f"   - ë°ì´í„° ê°œìˆ˜: {len(domain_data)}")
        
        if len(domain_data) > 0:
            print(f"   - ì²« ë²ˆì§¸ ë°ì´í„° ìƒ˜í”Œ:")
            first_item = domain_data[0]
            print(f"     - Keys: {list(first_item.keys())}")
            print(f"     - Evidence tokens: {first_item.get('evidence_tokens', 'N/A')}")
            print(f"     - Evidence indices: {first_item.get('evidence_indices', 'N/A')}")
        
        # íŒŒì¼ ì €ì¥
        saved_count = 0
        with open(output_path, "w", encoding="utf-8") as f:
            for i, item in enumerate(domain_data):
                try:
                    json_line = json.dumps(item, ensure_ascii=False)
                    f.write(json_line + "\n")
                    saved_count += 1
                    
                    # ì²˜ìŒ 3ê°œì™€ ë§ˆì§€ë§‰ 3ê°œë§Œ ë¡œê·¸
                    if i < 3 or i >= len(domain_data) - 3:
                        print(f"   âœ… ì €ì¥ë¨ ({i+1}/{len(domain_data)}): {len(item.get('evidence_tokens', []))}ê°œ evidence")
                    
                except Exception as item_error:
                    print(f"   âŒ í•­ëª© {i+1} ì €ì¥ ì‹¤íŒ¨: {str(item_error)}")
                    print(f"   í•­ëª© ë‚´ìš©: {item}")
        
        print(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {saved_count}/{len(domain_data)}ê°œ í•­ëª© ì €ì¥ë¨")
        print(f"ğŸ“„ íŒŒì¼ í¬ê¸°: {output_path.stat().st_size if output_path.exists() else 0} bytes")
        
        return output_path, saved_count
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ({domain}): {str(e)}")
        print(f"   - ë„ë©”ì¸: {domain}")
        print(f"   - ë°ì´í„° ê°œìˆ˜: {len(domain_data)}")
        print(f"   - ëª¨ë¸: {model_key}")
        print(f"   - íƒ€ì„ìŠ¤íƒ¬í”„: {timestamp}")
        return None, 0

def show():
    st.title("ğŸ” Evidence Extractor")
    st.markdown("ë„ë©”ì¸ë³„ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì—ì„œ evidence í† í°ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.")
    
    # ê°•ì œ ìºì‹œ ë¬´íš¨í™”
    if st.sidebar.button("ğŸ”„ ê°•ì œ ìƒˆë¡œê³ ì¹¨", key="force_refresh_evidence"):
        get_available_models.clear()
        st.success("ìºì‹œê°€ ìƒˆë¡œê³ ì¹¨ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ===== ì„¹ì…˜ 1: ëª¨ë¸ ì„¤ì • =====
    st.markdown("---")
    st.markdown("## ğŸ¤– Model Configuration")
    
    # ì‹¤í—˜ ëª¨ë“œ ì„ íƒ
    experiment_mode = st.radio(
        "Evidence ì¶”ì¶œ ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”",
        ["ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ", "ë‹¤ì¤‘ ëª¨ë¸ ì¶”ì¶œ"],
        key="evidence_mode_selector"
    )
    
    # ëª¨ë¸ ì„ íƒ
    col1, col2 = st.columns([2, 1])
    
    with col1:
        available_models = get_available_models()
        if not available_models:
            st.error("âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Ollamaê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            return
        
        if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
            model_key = st.selectbox(
                "ëª¨ë¸ ì„ íƒ",
                available_models,
                index=0 if available_models else None,
                help="Evidence ì¶”ì¶œì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”."
            )
            selected_models = [model_key]
        else:
            st.markdown("**ğŸ”§ ì¶”ì¶œí•  ëª¨ë¸ë“¤ì„ ì„ íƒí•˜ì„¸ìš” (ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥)**")
            selected_models = st.multiselect(
                "ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤",
                available_models,
                default=[available_models[0]] if available_models else [],
                help="ì—¬ëŸ¬ ëª¨ë¸ì„ ì„ íƒí•˜ë©´ ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤."
            )
            model_key = selected_models[0] if selected_models else None
    
    with col2:
        if st.button("ğŸ”„ ëª¨ë¸ ëª©ë¡ ìƒˆë¡œê³ ì¹¨", key="refresh_models_evidence"):
            get_available_models.clear()
            st.success("ëª¨ë¸ ëª©ë¡ì´ ìƒˆë¡œê³ ì¹¨ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
    
    # ëª¨ë¸ ì‹¤í–‰ ìƒíƒœ í™•ì¸
    st.markdown("### ğŸ” Model Status Check")
    
    # ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ëª©ë¡ í‘œì‹œ
    running_models = get_running_models()
    col_status1, col_status2 = st.columns([1, 2])
    
    with col_status1:
        if st.button("ğŸ”„ ìƒíƒœ ìƒˆë¡œê³ ì¹¨", key="refresh_status"):
            st.rerun()
    
    with col_status2:
        if running_models:
            st.success(f"ğŸŸ¢ ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸: {', '.join(running_models)}")
        else:
            st.warning("âšª ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì„ íƒëœ ëª¨ë¸ë“¤ ìƒíƒœ í™•ì¸
    if selected_models:
        st.markdown("**ğŸ“Š ì„ íƒëœ ëª¨ë¸ ìƒíƒœ í™•ì¸**")
        
        for model in selected_models:
            is_running = model in running_models
            is_available = check_model_status(model)
            
            col_status3, col_status4 = st.columns(2)
            
            with col_status3:
                if is_running:
                    st.success(f"âœ… {model} - ì‹¤í–‰ ì¤‘")
                elif is_available:
                    st.info(f"â„¹ï¸ {model} - ì‚¬ìš© ê°€ëŠ¥ (ë¡œë“œ í•„ìš”)")
                else:
                    st.error(f"âŒ {model} - ì‚¬ìš© ë¶ˆê°€")
            
            with col_status4:
                # í† í¬ë‚˜ì´ì € ì´ë¦„ í™•ì¸
                tokenizer_name = MODEL_TOKENIZER_MAP.get(model)
                if tokenizer_name:
                    st.success(f"ğŸ”§ {model} - í† í¬ë‚˜ì´ì € ì§€ì›")
                else:
                    st.warning(f"âš ï¸ {model} - í† í¬ë‚˜ì´ì € ì—†ìŒ")
        
        # ëª¨ë“  ëª¨ë¸ì´ ì‚¬ìš© ê°€ëŠ¥í•œì§€ í™•ì¸
        all_available = all(check_model_status(model) for model in selected_models)
        if not all_available:
            st.warning("âš ï¸ ì¼ë¶€ ëª¨ë¸ì„ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.")
            st.markdown("""
            **í•´ê²° ë°©ë²•:**
            1. Model Loader íƒ­ìœ¼ë¡œ ì´ë™
            2. ëª¨ë¸ì„ ì„ íƒí•˜ê³  "ğŸš€ Start Model" í´ë¦­
            3. ë˜ëŠ” í„°ë¯¸ë„ì—ì„œ: `ollama run {model_key}`
            """)
            return
        
        st.success(f"âœ… {len(selected_models)}ê°œ ëª¨ë¸ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    else:
        st.warning("âš ï¸ ìµœì†Œ í•˜ë‚˜ì˜ ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        return
    
    # ===== ì„¹ì…˜ 2: ë„ë©”ì¸ ì„ íƒ =====
    st.markdown("---")
    st.markdown("## ğŸ“ Domain Selection")
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ë„ë©”ì¸ í™•ì¸
    origin_dir = Path("dataset/origin")
    if not origin_dir.exists():
        st.error("âŒ `dataset/origin` ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € ë„ë©”ì¸ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return
    
    available_domains = [d.name for d in origin_dir.iterdir() if d.is_dir()]
    if not available_domains:
        st.error("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ë„ë©”ì¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë„ë©”ì¸ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")
        return
    
    # ë„ë©”ì¸ ì„ íƒ
    col3, col4 = st.columns([2, 1])
    
    with col3:
        selected_domains = st.multiselect(
            "ë„ë©”ì¸ ì„ íƒ",
            available_domains,
            default=available_domains[:2] if len(available_domains) >= 2 else available_domains,
            help="Evidenceë¥¼ ì¶”ì¶œí•  ë„ë©”ì¸ì„ ì„ íƒí•˜ì„¸ìš”. ì—¬ëŸ¬ ê°œ ì„ íƒ ê°€ëŠ¥í•©ë‹ˆë‹¤."
        )
    
    with col4:
        show_info = st.button("ğŸ“Š ë„ë©”ì¸ ì •ë³´ ë³´ê¸°", key="show_domain_info")
    
    # ë„ë©”ì¸ ì •ë³´ í‘œì‹œ
    if show_info:
        st.markdown("---")
        st.subheader("ğŸ“Š Domain Information")
        
        for domain in available_domains:
            prompts = load_origin_prompts(domain)
            col5, col6 = st.columns([3, 1])
            with col5:
                st.write(f"ğŸ“„ **{domain}** ë„ë©”ì¸")
            with col6:
                st.write(f"ğŸ“ {len(prompts)}ê°œ í”„ë¡¬í”„íŠ¸")
        
        st.info("ğŸ’¡ ë„ë©”ì¸ ì •ë³´ë¥¼ ë‹¤ì‹œ ë³´ë ¤ë©´ 'ğŸ“Š ë„ë©”ì¸ ì •ë³´ ë³´ê¸°' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.")
    
    # ===== ì„¹ì…˜ 3: ë¯¸ë¦¬ë³´ê¸° ê¸°ëŠ¥ =====
    st.markdown("---")
    st.markdown("## ğŸ‘€ Preview Evidence Extraction")
    
    preview_enabled = st.checkbox("ë¯¸ë¦¬ë³´ê¸° í™œì„±í™”", value=True, help="ì‹¤ì œ ì¶”ì¶œ ì „ì— ìƒ˜í”Œë¡œ í…ŒìŠ¤íŠ¸í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    if preview_enabled and selected_domains:
        preview_domain = st.selectbox("ë¯¸ë¦¬ë³´ê¸°í•  ë„ë©”ì¸ ì„ íƒ", selected_domains)
        preview_prompts = load_origin_prompts(preview_domain)
        
        if preview_prompts:
            preview_index = st.slider("ë¯¸ë¦¬ë³´ê¸°í•  í”„ë¡¬í”„íŠ¸ ì¸ë±ìŠ¤", 0, min(len(preview_prompts)-1, 10), 0)
            
            if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
                # ë‹¨ì¼ ëª¨ë¸ ë¯¸ë¦¬ë³´ê¸°
                if st.button("ğŸ” ë¯¸ë¦¬ë³´ê¸° ì‹¤í–‰", key="preview_evidence"):
                    with st.spinner("ë¯¸ë¦¬ë³´ê¸° ì¤‘..."):
                        preview_prompt_data = preview_prompts[preview_index]
                        preview_prompt = preview_prompt_data["prompt"]
                        
                        # í† í¬ë‚˜ì´ì§•
                        tokenizer = load_tokenizer_cached(tokenizer_name)
                        tokens = tokenizer.tokenize(preview_prompt)
                        
                        # Evidence ì¶”ì¶œ
                        evidence_indices, evidence_tokens = extract_evidence_tokens(
                            preview_prompt, model_key, preview_domain
                        )
            else:
                # ë‹¤ì¤‘ ëª¨ë¸ ë¯¸ë¦¬ë³´ê¸°
                preview_models = st.multiselect(
                    "ë¯¸ë¦¬ë³´ê¸°í•  ëª¨ë¸ ì„ íƒ",
                    selected_models,
                    default=selected_models[:2] if len(selected_models) >= 2 else selected_models,
                    help="ë¯¸ë¦¬ë³´ê¸°í•  ëª¨ë¸ë“¤ì„ ì„ íƒí•˜ì„¸ìš”."
                )
                
                if st.button("ğŸ” ë‹¤ì¤‘ ëª¨ë¸ ë¯¸ë¦¬ë³´ê¸° ì‹¤í–‰", key="preview_evidence_multi"):
                    with st.spinner("ë‹¤ì¤‘ ëª¨ë¸ ë¯¸ë¦¬ë³´ê¸° ì¤‘..."):
                        preview_prompt_data = preview_prompts[preview_index]
                        preview_prompt = preview_prompt_data["prompt"]
                        
                        # ë‹¤ì¤‘ ëª¨ë¸ë¡œ ì²˜ë¦¬
                        processed_items = process_single_prompt_multi_models(
                            preview_prompt_data, preview_models, preview_domain
                        )
                        
                        if processed_items:
                            st.markdown("### ğŸ“‹ Multi-Model Preview Results")
                            
                            for item in processed_items:
                                model_name = item['model']
                                evidence_tokens = item['evidence_tokens']
                                evidence_indices = item['evidence_indices']
                                
                                st.markdown(f"**ğŸ”§ {model_name} ëª¨ë¸ ê²°ê³¼:**")
                                
                                col7, col8 = st.columns(2)
                                with col7:
                                    st.write(f"**ì¶”ì¶œëœ Evidence í† í° ({len(evidence_tokens)}ê°œ):**")
                                    st.text_area("", str(evidence_tokens), height=100, key=f"preview_evidence_tokens_{model_name}")
                                
                                with col8:
                                    st.write(f"**Evidence í† í° ìœ„ì¹˜ ({len(evidence_indices)}ê°œ):**")
                                    st.text_area("", str(evidence_indices), height=100, key=f"preview_evidence_indices_{model_name}")
                                
                                st.markdown("---")
                        
                        # ì›ë³¸ í”„ë¡¬í”„íŠ¸ í‘œì‹œ
                        st.markdown("### ğŸ“„ Original Prompt")
                        st.text_area("", preview_prompt, height=100, key="preview_prompt_multi")
                        
                        # í† í¬ë‚˜ì´ì§• ê²°ê³¼ (ì²« ë²ˆì§¸ ëª¨ë¸ ê¸°ì¤€)
                        if preview_models:
                            first_model = preview_models[0]
                            tokenizer_name = MODEL_TOKENIZER_MAP.get(first_model)
                            if tokenizer_name:
                                tokenizer = load_tokenizer_cached(tokenizer_name)
                                tokens = tokenizer.tokenize(preview_prompt)
                                st.write(f"**í† í¬ë‚˜ì´ì§• ê²°ê³¼ (ì°¸ê³ ìš©, {first_model} ê¸°ì¤€):**")
                                st.write(f"ì´ {len(tokens)}ê°œ í† í°")
                                st.text_area("", str(tokens[:20]) + "..." if len(tokens) > 20 else str(tokens), height=100, key="preview_tokens_multi")
        
        # ë‹¨ì¼ ëª¨ë¸ ë¯¸ë¦¬ë³´ê¸° ê²°ê³¼ í‘œì‹œ
        if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ" and 'preview_prompt' in locals():
            # ê²°ê³¼ í‘œì‹œ
            st.markdown("### ğŸ“‹ Preview Results")
            
            col7, col8 = st.columns(2)
            with col7:
                st.write("**ì›ë³¸ í”„ë¡¬í”„íŠ¸:**")
                st.text_area("", preview_prompt, height=100, key="preview_prompt")
                
                st.write("**í† í¬ë‚˜ì´ì§• ê²°ê³¼ (ì°¸ê³ ìš©):**")
                st.write(f"ì´ {len(tokens)}ê°œ í† í°")
                st.text_area("", str(tokens[:20]) + "..." if len(tokens) > 20 else str(tokens), height=100, key="preview_tokens")
            
            with col8:
                st.write("**ì¶”ì¶œëœ Evidence í† í°:**")
                st.write(f"ì´ {len(evidence_tokens)}ê°œ í† í°")
                st.text_area("", str(evidence_tokens), height=100, key="preview_evidence_tokens")
                
                st.write("**Evidence í† í° ìœ„ì¹˜ (ì›ë³¸ í”„ë¡¬í”„íŠ¸ ê¸°ì¤€):**")
                st.write(f"ì´ {len(evidence_indices)}ê°œ ìœ„ì¹˜")
                st.text_area("", str(evidence_indices), height=100, key="preview_evidence_indices")
                
                # ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
                st.markdown("### ğŸ” Debug Information")
                
                # LLM ì‘ë‹µ í™•ì¸
                domain_instruction = DOMAIN_PROMPTS.get(preview_domain.lower(), "Find important tokens related to the domain.")
                debug_prompt = f"""
You are an English-only evidence extraction system. Your task is to extract English tokens from the given prompt.

DOMAIN: {preview_domain}
INSTRUCTION: {domain_instruction}

INPUT PROMPT: "{preview_prompt}"

CRITICAL RULES:
1. You MUST respond ONLY in English
2. You MUST extract ONLY English words that exist in the input prompt
3. You MUST return ONLY a JSON array format
4. You MUST NOT translate words
5. You MUST NOT add words that are not in the prompt
6. You MUST NOT respond in Korean or any other language
7. You MUST focus on domain-specific medical/technical terms

EXAMPLES:
- For medical domain: ["clinical", "findings", "diagnosis", "viral", "encephalitis", "adults"]
- For legal domain: ["legal", "contract", "liability", "jurisdiction"]
- For technical domain: ["algorithm", "implementation", "optimization"]

RESPONSE FORMAT (JSON array only):
["word1", "word2", "word3"]
"""
                
                debug_response = call_ollama_api(model_key, debug_prompt)
                
                col9, col10 = st.columns(2)
                with col9:
                    st.write("**LLM ì‘ë‹µ (ì›ë³¸):**")
                    st.text_area("", debug_response or "No response", height=150, key="debug_response")
                    
                    st.write("**ì¶”ì¶œëœ í† í° (íŒŒì‹± í›„):**")
                    parsed_tokens = extract_tokens_from_response(debug_response) if debug_response else []
                    st.text_area("", str(parsed_tokens), height=100, key="debug_parsed_tokens")
                
                with col10:
                    st.write("**í† í° ë§¤ì¹­ ê²°ê³¼:**")
                    prompt_lower = preview_prompt.lower()
                    matching_info = []
                    for token in parsed_tokens or []:
                        token_lower = token.lower().strip()
                        is_in_prompt = token_lower in prompt_lower
                        import re
                        pattern = r'\b' + re.escape(token_lower) + r'\b'
                        is_word_boundary = bool(re.search(pattern, prompt_lower))
                        matching_info.append(f"'{token}': in_prompt={is_in_prompt}, word_boundary={is_word_boundary}")
                    
                    st.text_area("", "\n".join(matching_info), height=150, key="debug_matching")
                
                # ì¸ë±ìŠ¤ ê³„ì‚° ë””ë²„ê¹… ì •ë³´ ì¶”ê°€
                st.markdown("### ğŸ” Index Calculation Debug")
                
                col11, col12 = st.columns(2)
                with col11:
                    st.write("**í† í°í™” ê²°ê³¼ (ì¸ë±ìŠ¤ í‘œì‹œ):**")
                    tokenized = tokenizer.tokenize(preview_prompt)
                    indexed_tokens = ""
                    for i, token in enumerate(tokenized):
                        if i % 5 == 0:
                            indexed_tokens += f"\n{i:3d}: "
                        indexed_tokens += f"{token} "
                    st.text_area("", indexed_tokens, height=200, key="indexed_tokens")
                
                with col12:
                    st.write("**Evidence í† í° ìœ„ì¹˜ í™•ì¸ (í† í° ë‹¨ìœ„):**")
                    position_info = []
                    
                    # ì›ë³¸ evidence í† í°ê³¼ ì¸ë±ìŠ¤ ë§¤ì¹­
                    original_tokens = extract_tokens_from_response(debug_response) if debug_response else []
                    english_tokens = []
                    for token in original_tokens or []:
                        token_clean = token.lower().strip()
                        if token_clean and all(c.isascii() and c.isalnum() or c.isspace() for c in token_clean):
                            english_tokens.append(token_clean)
                    
                    # ê° í† í°ì— ëŒ€í•œ ì¸ë±ìŠ¤ ì°¾ê¸°
                    all_indices = find_token_positions(preview_prompt, english_tokens, tokenizer)
                    
                    for i, (token, idx) in enumerate(zip(english_tokens, all_indices)):
                        if idx != -1 and idx < len(tokenized):
                            actual_token = tokenized[idx]
                            # Ä  ë¬¸ì ì œê±°í•˜ì—¬ í‘œì‹œ
                            clean_actual_token = actual_token.replace('Ä ', '')
                            position_info.append(f"'{token}' at token pos {idx}: '{clean_actual_token}' âœ…")
                        elif idx == -1:
                            position_info.append(f"'{token}': not found in tokens âŒ")
                        else:
                            position_info.append(f"'{token}' at token pos {idx}: index out of range âŒ")
                    
                    st.text_area("", "\n".join(position_info), height=200, key="position_info")
                
                # ìµœì¢… ë°ì´í„°ì…‹ í•­ëª© ë¯¸ë¦¬ë³´ê¸°
                st.markdown("### ğŸ“Š Final Dataset Item Preview")
                final_item = {
                    "prompt": preview_prompt_data["prompt"],
                    "domain": preview_prompt_data.get("domain", preview_domain),
                    "model": model_key,
                    "index": preview_prompt_data.get("index", preview_index),
                    "evidence_indices": evidence_indices,
                    "evidence_tokens": evidence_tokens,
                    "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S")
                }
                st.json(final_item)
        else:
            st.warning(f"âš ï¸ {preview_domain} ë„ë©”ì¸ì— í”„ë¡¬í”„íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ===== ì„¹ì…˜ 4: Evidence ì¶”ì¶œ ì‹¤í–‰ =====
    st.markdown("---")
    st.markdown("## âš™ï¸ Extraction Settings")
    
    # Evidence ì¶”ì¶œ ì„¤ì •
    col9, col10 = st.columns([1, 2])
    
    with col9:
        batch_size = st.number_input(
            "ë°°ì¹˜ í¬ê¸°",
            min_value=1,
            max_value=50,
            value=10,
            help="í•œ ë²ˆì— ì²˜ë¦¬í•  í”„ë¡¬í”„íŠ¸ ê°œìˆ˜ì…ë‹ˆë‹¤."
        )
        
        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì˜µì…˜ ì¶”ê°€
        test_mode = st.checkbox(
            "í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì²˜ìŒ 5ê°œë§Œ ì²˜ë¦¬)",
            value=False,
            help="ì²˜ìŒ 5ê°œì˜ í”„ë¡¬í”„íŠ¸ë§Œ ì²˜ë¦¬í•˜ì—¬ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
        )
    
    with col10:
        st.info("âœ… ì„ íƒëœ ë„ë©”ì¸ì˜ ëª¨ë“  í”„ë¡¬í”„íŠ¸ì—ì„œ evidence í† í°ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.")
    
    # Evidence ì¶”ì¶œ ë²„íŠ¼
    col11, col12 = st.columns([2, 1])
    
    with col11:
        extract_button = st.button("ğŸ” Extract Evidence", type="primary", key="extract_evidence")
    
    with col12:
        if st.button("ğŸ—‘ï¸ ìºì‹œ ì´ˆê¸°í™”", key="clear_cache_evidence"):
            get_available_models.clear()
            load_tokenizer_cached.clear()  # í† í¬ë‚˜ì´ì € ìºì‹œë„ ì´ˆê¸°í™”
            keys_to_remove = [key for key in st.session_state.keys() if key.startswith('tokenizer_')]
            for key in keys_to_remove:
                del st.session_state[key]
            st.success("ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
    
    # ===== Evidence ì¶”ì¶œ ì‹¤í–‰ =====
    if extract_button and selected_domains:
        try:
            # ì‚¬ì „ ì²´í¬
            st.markdown("### ğŸ” Pre-Extraction Check")
            
            # 1. ëª¨ë¸ ìƒíƒœ í™•ì¸
            if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
                # ë‹¨ì¼ ëª¨ë¸ ì²´í¬
                is_model_running = model_key in get_running_models()
                if is_model_running:
                    st.success(f"âœ… ëª¨ë¸ {model_key} ì‹¤í–‰ ì¤‘")
                else:
                    st.error(f"âŒ ëª¨ë¸ {model_key} ì‹¤í–‰ë˜ì§€ ì•ŠìŒ")
                    st.warning("ğŸ’¡ Model Loader íƒ­ì—ì„œ ëª¨ë¸ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
                    return
                
                # í† í¬ë‚˜ì´ì € í™•ì¸
                tokenizer_name = MODEL_TOKENIZER_MAP.get(model_key)
                if tokenizer_name:
                    st.success(f"âœ… í† í¬ë‚˜ì´ì €: {tokenizer_name}")
                else:
                    st.error(f"âŒ í† í¬ë‚˜ì´ì €ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {model_key}")
                    return
            else:
                # ë‹¤ì¤‘ ëª¨ë¸ ì²´í¬
                for model in selected_models:
                    is_model_running = model in get_running_models()
                    if is_model_running:
                        st.success(f"âœ… ëª¨ë¸ {model} ì‹¤í–‰ ì¤‘")
                    else:
                        st.warning(f"âš ï¸ ëª¨ë¸ {model} ì‹¤í–‰ë˜ì§€ ì•ŠìŒ (ìë™ ë¡œë“œ ì‹œë„)")
                    
                    # í† í¬ë‚˜ì´ì € í™•ì¸
                    tokenizer_name = MODEL_TOKENIZER_MAP.get(model)
                    if tokenizer_name:
                        st.success(f"âœ… {model} í† í¬ë‚˜ì´ì €: {tokenizer_name}")
                    else:
                        st.warning(f"âš ï¸ {model} í† í¬ë‚˜ì´ì € ì—†ìŒ")
            
            # 2. ë„ë©”ì¸ë³„ í”„ë¡¬í”„íŠ¸ í™•ì¸
            for domain in selected_domains:
                prompts = load_origin_prompts(domain)
                if prompts:
                    st.success(f"âœ… {domain} ë„ë©”ì¸: {len(prompts)}ê°œ í”„ë¡¬í”„íŠ¸")
                else:
                    st.error(f"âŒ {domain} ë„ë©”ì¸: í”„ë¡¬í”„íŠ¸ ì—†ìŒ")
                    return
            
            st.success("âœ… ëª¨ë“  ì‚¬ì „ ì²´í¬ í†µê³¼! Evidence ì¶”ì¶œì„ ì‹œì‘í•©ë‹ˆë‹¤.")
            st.markdown("---")
            
            # ì „ì²´ ì‹œì‘ ì‹œê°„ ê¸°ë¡
            total_start_time = time.time()
            
            # ì§„í–‰ìƒí™© í‘œì‹œë¥¼ ìœ„í•œ ì»¨í…Œì´ë„ˆë“¤
            progress_text = st.empty()
            progress_counter = st.empty()
            time_info = st.empty()
            
            # ìµœì¢… ë°ì´í„°ì…‹ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
            final_datasets = []
            
            # ì „ì²´ ì‘ì—…ëŸ‰ ê³„ì‚°
            total_tasks = len(selected_domains) * len(selected_models)
            completed_tasks = 0
            
            for domain_idx, domain in enumerate(selected_domains, 1):
                # ë„ë©”ì¸ë³„ ì‹œì‘ ì‹œê°„ ê¸°ë¡
                domain_start_time = time.time()
                
                # ë„ë©”ì¸ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
                prompts = load_origin_prompts(domain)
                if not prompts:
                    st.warning(f"âš ï¸ {domain} ë„ë©”ì¸ì— í”„ë¡¬í”„íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                
                # í…ŒìŠ¤íŠ¸ ëª¨ë“œì¸ ê²½ìš° ì²˜ìŒ 5ê°œë§Œ ì²˜ë¦¬
                if test_mode:
                    prompts = prompts[:5]
                    st.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {domain} ë„ë©”ì¸ì—ì„œ ì²˜ìŒ 5ê°œ í”„ë¡¬í”„íŠ¸ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                
                if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
                    # ë‹¨ì¼ ëª¨ë¸ ì²˜ë¦¬
                    progress_text.text(f"Extracting evidence from {domain} domain prompts using {model_key}...")
                    
                    with st.spinner(f"Extracting evidence from {len(prompts)} prompts in {domain} domain using {model_key} ({domain_idx}/{len(selected_domains)})..."):
                        for i, prompt_data in enumerate(prompts):
                            # ì§„í–‰ìƒí™© ì¹´ìš´í„° ì—…ë°ì´íŠ¸
                            progress_counter.text(f"{domain} domain: {i+1}/{len(prompts)}")
                            
                            # ì‹œê°„ ì •ë³´ ì—…ë°ì´íŠ¸
                            current_time = time.time()
                            elapsed_time = current_time - total_start_time
                            
                            # ì˜ˆìƒ ì‹œê°„ ê³„ì‚°
                            total_prompts_to_process = sum(len(load_origin_prompts(d)) for d in selected_domains)
                            completed_prompts = sum(len(load_origin_prompts(d)) for d in selected_domains[:domain_idx-1]) + i
                            if completed_prompts > 0:
                                avg_time_per_prompt = elapsed_time / completed_prompts
                                remaining_prompts = total_prompts_to_process - completed_prompts
                                estimated_remaining_time = avg_time_per_prompt * remaining_prompts
                                estimated_total_time = elapsed_time + estimated_remaining_time
                                
                                time_info.text(f"ì†Œìš”ì‹œê°„: {elapsed_time:.1f}ì´ˆ | ì˜ˆìƒì™„ë£Œ: {estimated_total_time:.1f}ì´ˆ | ë‚¨ì€ì‹œê°„: {estimated_remaining_time:.1f}ì´ˆ")
                            else:
                                time_info.text(f"ì†Œìš”ì‹œê°„: {elapsed_time:.1f}ì´ˆ | ì˜ˆìƒì™„ë£Œ: ê³„ì‚° ì¤‘...")
                            
                            # ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
                            processed_item = process_single_prompt(prompt_data, model_key, domain, tokenizer_name)
                            if processed_item:
                                final_datasets.append(processed_item)
                                # ë””ë²„ê¹…: ì„±ê³µí•œ ê²½ìš° ë¡œê·¸
                                if (i + 1) % 10 == 0:
                                    print(f"âœ… Processed {i+1}/{len(prompts)} prompts in {domain} domain - Evidence tokens: {len(processed_item.get('evidence_tokens', []))}")
                            else:
                                # ë””ë²„ê¹…: ì‹¤íŒ¨í•œ ê²½ìš° ìƒì„¸ ë¡œê·¸
                                print(f"âŒ Failed to process prompt {i+1} in {domain} domain")
                                if i < 3:  # ì²˜ìŒ 3ê°œë§Œ ìƒì„¸ ë¡œê·¸
                                    print(f"   Prompt: {prompt_data.get('prompt', '')[:100]}...")
                                    print(f"   Domain: {domain}")
                                    print(f"   Model: {model_key}")
                                    print(f"   Tokenizer: {tokenizer_name}")
                                if (i + 1) % 10 == 0:
                                    print(f"âŒ Failed {i+1}/{len(prompts)} prompts in {domain} domain")
                        
                        # ë„ë©”ì¸ë³„ ì™„ë£Œ ì‹œê°„ ê³„ì‚°
                        domain_end_time = time.time()
                        domain_duration = domain_end_time - domain_start_time
                        print(f"{domain} domain evidence extraction completed in {domain_duration:.2f} seconds")
                
                else:
                    # ë‹¤ì¤‘ ëª¨ë¸ ì²˜ë¦¬
                    progress_text.text(f"Extracting evidence from {domain} domain prompts using {len(selected_models)} models...")
                    
                    with st.spinner(f"Extracting evidence from {len(prompts)} prompts in {domain} domain using {len(selected_models)} models ({domain_idx}/{len(selected_domains)})..."):
                        for i, prompt_data in enumerate(prompts):
                            # ì§„í–‰ìƒí™© ì¹´ìš´í„° ì—…ë°ì´íŠ¸
                            progress_counter.text(f"{domain} domain: {i+1}/{len(prompts)} (ëª¨ë¸: {len(selected_models)}ê°œ)")
                            
                            # ì‹œê°„ ì •ë³´ ì—…ë°ì´íŠ¸
                            current_time = time.time()
                            elapsed_time = current_time - total_start_time
                            
                            # ì˜ˆìƒ ì‹œê°„ ê³„ì‚° (ëª¨ë¸ ìˆ˜ë¥¼ ê³ ë ¤)
                            total_prompts_to_process = sum(len(load_origin_prompts(d)) for d in selected_domains) * len(selected_models)
                            completed_prompts = (sum(len(load_origin_prompts(d)) for d in selected_domains[:domain_idx-1]) + i) * len(selected_models)
                            if completed_prompts > 0:
                                avg_time_per_prompt = elapsed_time / completed_prompts
                                remaining_prompts = total_prompts_to_process - completed_prompts
                                estimated_remaining_time = avg_time_per_prompt * remaining_prompts
                                estimated_total_time = elapsed_time + estimated_remaining_time
                                
                                time_info.text(f"ì†Œìš”ì‹œê°„: {elapsed_time:.1f}ì´ˆ | ì˜ˆìƒì™„ë£Œ: {estimated_total_time:.1f}ì´ˆ | ë‚¨ì€ì‹œê°„: {estimated_remaining_time:.1f}ì´ˆ")
                            else:
                                time_info.text(f"ì†Œìš”ì‹œê°„: {elapsed_time:.1f}ì´ˆ | ì˜ˆìƒì™„ë£Œ: ê³„ì‚° ì¤‘...")
                            
                            # ë‹¤ì¤‘ ëª¨ë¸ë¡œ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
                            processed_items = process_single_prompt_multi_models(prompt_data, selected_models, domain)
                            if processed_items:
                                final_datasets.extend(processed_items)
                                # ë””ë²„ê¹…: ì„±ê³µí•œ ê²½ìš° ë¡œê·¸
                                if (i + 1) % 10 == 0:
                                    total_evidence = sum(len(item.get('evidence_tokens', [])) for item in processed_items)
                                    print(f"âœ… Processed {i+1}/{len(prompts)} prompts in {domain} domain with {len(selected_models)} models - Total evidence tokens: {total_evidence}")
                            else:
                                # ë””ë²„ê¹…: ì‹¤íŒ¨í•œ ê²½ìš° ìƒì„¸ ë¡œê·¸
                                print(f"âŒ Failed to process prompt {i+1} in {domain} domain with all models")
                                if i < 3:  # ì²˜ìŒ 3ê°œë§Œ ìƒì„¸ ë¡œê·¸
                                    print(f"   Prompt: {prompt_data.get('prompt', '')[:100]}...")
                                    print(f"   Domain: {domain}")
                                    print(f"   Models: {selected_models}")
                                if (i + 1) % 10 == 0:
                                    print(f"âŒ Failed {i+1}/{len(prompts)} prompts in {domain} domain")
                        
                        # ë„ë©”ì¸ë³„ ì™„ë£Œ ì‹œê°„ ê³„ì‚°
                        domain_end_time = time.time()
                        domain_duration = domain_end_time - domain_start_time
                        print(f"{domain} domain evidence extraction completed in {domain_duration:.2f} seconds")
            
            # ì „ì²´ ì™„ë£Œ ì‹œê°„ ê³„ì‚°
            total_end_time = time.time()
            total_duration = total_end_time - total_start_time
            
            # ì§„í–‰ìƒí™© í‘œì‹œ ì •ë¦¬
            progress_text.empty()
            progress_counter.empty()
            time_info.empty()
            
            # ===== ìµœì¢… ë°ì´í„°ì…‹ ì €ì¥ =====
            st.markdown("---")
            st.subheader("ğŸ’¾ Saving Final Dataset")
            
            # ë””ë²„ê¹… ì •ë³´ í‘œì‹œ
            st.info(f"ğŸ“Š ì´ ì²˜ë¦¬ëœ ë°ì´í„°: {len(final_datasets)}ê°œ")
            st.info(f"ğŸ¯ ì„ íƒëœ ë„ë©”ì¸: {', '.join(selected_domains)}")
            
            # final_datasets ìƒì„¸ ë¶„ì„
            print(f"ğŸ” Final datasets ë¶„ì„:")
            print(f"   - ì´ ë°ì´í„° ê°œìˆ˜: {len(final_datasets)}")
            
            if len(final_datasets) > 0:
                print(f"   - ì²« ë²ˆì§¸ ë°ì´í„° ìƒ˜í”Œ:")
                first_data = final_datasets[0]
                print(f"     - Keys: {list(first_data.keys())}")
                print(f"     - Domain: {first_data.get('domain', 'N/A')}")
                print(f"     - Model: {first_data.get('model', 'N/A')}")
                print(f"     - Evidence tokens: {first_data.get('evidence_tokens', [])}")
                print(f"     - Evidence indices: {first_data.get('evidence_indices', [])}")
            
            # ë„ë©”ì¸ë³„ ë°ì´í„° ë¶„í¬ í™•ì¸
            domain_distribution = {}
            for item in final_datasets:
                domain = item.get('domain', 'unknown')
                domain_distribution[domain] = domain_distribution.get(domain, 0) + 1
            
            print(f"   - ë„ë©”ì¸ë³„ ë¶„í¬: {domain_distribution}")
            
            # ê° ë„ë©”ì¸ë³„ ì²˜ë¦¬ ê²°ê³¼ í‘œì‹œ
            for domain in selected_domains:
                # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ë§¤ì¹­
                domain_data = [item for item in final_datasets if item["domain"].lower() == domain.lower()]
                if domain_data:
                    st.success(f"âœ… {domain} ë„ë©”ì¸: {len(domain_data)}ê°œ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ")
                    print(f"âœ… {domain} ë„ë©”ì¸: {len(domain_data)}ê°œ ë°ì´í„° í™•ì¸ë¨")
                else:
                    st.error(f"âŒ {domain} ë„ë©”ì¸: ë°ì´í„° ì²˜ë¦¬ ì‹¤íŒ¨")
                    print(f"âŒ {domain} ë„ë©”ì¸: ë°ì´í„° ì—†ìŒ")
                    # ì‹¤íŒ¨ ì›ì¸ ë¶„ì„
                    prompts = load_origin_prompts(domain)
                    if prompts:
                        st.warning(f"   - ì›ë³¸ í”„ë¡¬í”„íŠ¸: {len(prompts)}ê°œ ì¡´ì¬")
                        st.warning(f"   - ëª¨ë¸ ìƒíƒœ: {'ì‹¤í–‰ ì¤‘' if model_key in get_running_models() else 'ì‹¤í–‰ë˜ì§€ ì•ŠìŒ'}")
                        st.warning(f"   - í† í¬ë‚˜ì´ì €: {MODEL_TOKENIZER_MAP.get(model_key, 'ì—†ìŒ')}")
            
            # ë„ë©”ì¸ë³„ë¡œ íŒŒì¼ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            saved_files = []
            
            print(f"ğŸ’¾ ì €ì¥ ì‹œì‘ - íƒ€ì„ìŠ¤íƒ¬í”„: {timestamp}")
            
            if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
                # ë‹¨ì¼ ëª¨ë¸ ì €ì¥
                for domain in selected_domains:
                    # ë„ë©”ì¸ë³„ ë°ì´í„° í•„í„°ë§ (ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´)
                    domain_data = [item for item in final_datasets if item["domain"].lower() == domain.lower()]
                    
                    st.info(f"ğŸ“‹ {domain} ë„ë©”ì¸ ë°ì´í„°: {len(domain_data)}ê°œ")
                    print(f"ğŸ“‹ {domain} ë„ë©”ì¸ ì €ì¥ ì¤€ë¹„: {len(domain_data)}ê°œ ë°ì´í„°")
                    
                    if domain_data:
                        output_path, count = save_domain_data(domain, domain_data, model_key, timestamp)
                        if output_path:
                            saved_files.append((domain, output_path, count))
                            st.success(f"âœ… {domain} ë„ë©”ì¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
                            print(f"âœ… {domain} ë„ë©”ì¸ ì €ì¥ ì„±ê³µ: {output_path} ({count}ê°œ)")
                        else:
                            st.error(f"âŒ {domain} ë„ë©”ì¸ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")
                            print(f"âŒ {domain} ë„ë©”ì¸ ì €ì¥ ì‹¤íŒ¨")
                    else:
                        st.warning(f"âš ï¸ {domain} ë„ë©”ì¸ì— ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        print(f"âš ï¸ {domain} ë„ë©”ì¸: ì €ì¥í•  ë°ì´í„° ì—†ìŒ")
                        st.info(f"ğŸ’¡ ì›ì¸: evidence ì¶”ì¶œ ê³¼ì •ì—ì„œ ëª¨ë“  í”„ë¡¬í”„íŠ¸ê°€ ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        st.info(f"ğŸ’¡ í•´ê²°: ë¯¸ë¦¬ë³´ê¸° ê¸°ëŠ¥ìœ¼ë¡œ ê°œë³„ í”„ë¡¬í”„íŠ¸ë¥¼ í…ŒìŠ¤íŠ¸í•´ë³´ì„¸ìš”.")
            else:
                # ë‹¤ì¤‘ ëª¨ë¸ ì €ì¥ - ëª¨ë¸ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ì €ì¥
                for model in selected_models:
                    st.markdown(f"**ğŸ“Š {model} ëª¨ë¸ ê²°ê³¼ ì €ì¥**")
                    
                    for domain in selected_domains:
                        # ëª¨ë¸ê³¼ ë„ë©”ì¸ë³„ ë°ì´í„° í•„í„°ë§
                        domain_data = [item for item in final_datasets 
                                     if item["domain"].lower() == domain.lower() and item["model"] == model]
                        
                        st.info(f"ğŸ“‹ {domain} ë„ë©”ì¸ ({model}): {len(domain_data)}ê°œ")
                        print(f"ğŸ“‹ {domain} ë„ë©”ì¸ ({model}) ì €ì¥ ì¤€ë¹„: {len(domain_data)}ê°œ ë°ì´í„°")
                        
                        if domain_data:
                            output_path, count = save_domain_data(domain, domain_data, model, timestamp)
                            if output_path:
                                saved_files.append((f"{domain} ({model})", output_path, count))
                                st.success(f"âœ… {domain} ë„ë©”ì¸ ({model}) íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_path}")
                                print(f"âœ… {domain} ë„ë©”ì¸ ({model}) ì €ì¥ ì„±ê³µ: {output_path} ({count}ê°œ)")
                            else:
                                st.error(f"âŒ {domain} ë„ë©”ì¸ ({model}) íŒŒì¼ ì €ì¥ ì‹¤íŒ¨")
                                print(f"âŒ {domain} ë„ë©”ì¸ ({model}) ì €ì¥ ì‹¤íŒ¨")
                        else:
                            st.warning(f"âš ï¸ {domain} ë„ë©”ì¸ ({model})ì— ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                            print(f"âš ï¸ {domain} ë„ë©”ì¸ ({model}): ì €ì¥í•  ë°ì´í„° ì—†ìŒ")
            
            # ===== ìµœì¢… ê²°ê³¼ í‘œì‹œ =====
            st.markdown("---")
            st.subheader("âœ… Evidence Extraction Complete!")
            
            # ê²°ê³¼ ìš”ì•½ì„ ì»¬ëŸ¼ìœ¼ë¡œ ë°°ì¹˜
            col13, col14, col15 = st.columns(3)
            
            with col13:
                st.metric("ì´ ì†Œìš” ì‹œê°„", f"{total_duration:.1f}ì´ˆ")
            
            with col14:
                if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
                    st.metric("ì²˜ë¦¬ëœ ë„ë©”ì¸", f"{len(selected_domains)}ê°œ")
                else:
                    st.metric("ì²˜ë¦¬ëœ ë„ë©”ì¸", f"{len(selected_domains)}ê°œ")
            
            with col15:
                total_generated = len(final_datasets)
                if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
                    st.metric("ìƒì„±ëœ ë°ì´í„°ì…‹", f"{total_generated}ê°œ")
                else:
                    st.metric("ìƒì„±ëœ ë°ì´í„°ì…‹", f"{total_generated}ê°œ")
            
            # ë‹¤ì¤‘ ëª¨ë¸ ê²°ê³¼ ìš”ì•½
            if experiment_mode == "ë‹¤ì¤‘ ëª¨ë¸ ì¶”ì¶œ":
                st.markdown("**ğŸ“Š ëª¨ë¸ë³„ ê²°ê³¼ ìš”ì•½**")
                
                model_summary = {}
                for item in final_datasets:
                    model_name = item['model']
                    if model_name not in model_summary:
                        model_summary[model_name] = {'count': 0, 'domains': set()}
                    model_summary[model_name]['count'] += 1
                    model_summary[model_name]['domains'].add(item['domain'])
                
                for model_name, summary in model_summary.items():
                    domains_str = ', '.join(sorted(summary['domains']))
                    st.info(f"**{model_name}**: {summary['count']}ê°œ ê²°ê³¼ ({domains_str} ë„ë©”ì¸)")
            
            # ìƒì„±ëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ
            st.markdown("---")
            st.subheader("ğŸ“‹ Generated Files")
            
            if saved_files:
                for domain, file_path, count in saved_files:
                    with st.container():
                        col16, col17 = st.columns([3, 1])
                        with col16:
                            # íŒŒì¼ì´ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
                            if file_path.exists():
                                st.write(f"ğŸ“„ **{domain}** ë„ë©”ì¸: `{file_path.name}` ({count}ê°œ í•­ëª©) âœ…")
                            else:
                                st.write(f"ğŸ“„ **{domain}** ë„ë©”ì¸: `{file_path.name}` ({count}ê°œ í•­ëª©) âŒ íŒŒì¼ ì—†ìŒ")
                        with col17:
                            st.write(f"ğŸ“ `{file_path.parent}`")
                
                # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì •ë³´
                if experiment_mode == "ë‹¨ì¼ ëª¨ë¸ ì¶”ì¶œ":
                    safe_model_key = model_key.replace(":", "_")
                    st.info(f"ğŸ“ ëª¨ë“  íŒŒì¼ì´ `dataset/{safe_model_key}/` ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                else:
                    st.info(f"ğŸ“ ê° ëª¨ë¸ë³„ë¡œ `dataset/[ëª¨ë¸ëª…]/` ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                    for model in selected_models:
                        safe_model_key = model.replace(":", "_")
                        st.info(f"   - {model}: `dataset/{safe_model_key}/`")
                
                # íŒŒì¼ í¬ê¸° ì •ë³´ í‘œì‹œ
                st.markdown("---")
                st.subheader("ğŸ“ File Information")
                for domain, file_path, count in saved_files:
                    if file_path.exists():
                        file_size = file_path.stat().st_size
                        st.write(f"ğŸ“„ {domain}: {file_size:,} bytes ({file_size/1024:.1f} KB)")
            else:
                st.warning("âš ï¸ ì €ì¥ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                st.info("ğŸ’¡ Evidence ì¶”ì¶œì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
        except Exception as e:
            st.session_state.evidence_extraction_error = str(e)
            print(f"Evidence extraction error: {str(e)}")
    
    # Evidence ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ ì²˜ë¦¬
    if extract_button and not selected_domains:
        st.error("âŒ ë„ë©”ì¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”!")
    
    # Evidence ì¶”ì¶œ ì¤‘ ì—ëŸ¬ ì²˜ë¦¬
    if 'evidence_extraction_error' in st.session_state:
        st.markdown("---")
        st.subheader("âŒ Evidence Extraction Failed")
        
        # ì—ëŸ¬ ì •ë³´ë¥¼ ì»¬ëŸ¼ìœ¼ë¡œ ë°°ì¹˜
        col18, col19 = st.columns([2, 1])
        
        with col18:
            st.error(f"Evidence ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:")
            st.code(st.session_state.evidence_extraction_error)
        
        with col19:
            st.warning("ğŸ’¡ í•´ê²° ë°©ë²•:")
            st.write("1. í† í¬ë‚˜ì´ì €ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
            st.write("2. ëª¨ë¸ì´ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸")
            st.write("3. í”„ë¡¬í”„íŠ¸ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸")
        
        # ì—ëŸ¬ ìƒíƒœ ì •ë¦¬
        del st.session_state.evidence_extraction_error 