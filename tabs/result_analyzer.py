import streamlit as st
import json
import os
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from .experiment import get_model_experiment_path, list_model_experiment_results, load_model_experiment_result, analyze_head_attention_pattern

def show():
    st.title("ğŸ” ì‹¤í—˜ ê²°ê³¼ ë¶„ì„")
    st.markdown("ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¡œë“œí•˜ê³  íŠ¹ì • í—¤ë“œì˜ attention íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    # ëª¨ë¸ ì„ íƒ
    st.subheader("ğŸ“Š ì‹¤í—˜ ê²°ê³¼ ì„ íƒ")
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤ ì°¾ê¸°
    experiment_root = "experiment_results"
    if not os.path.exists(experiment_root):
        st.error("ì‹¤í—˜ ê²°ê³¼ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì‹¤í—˜ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return
    
    available_models = []
    for model_dir in os.listdir(experiment_root):
        model_path = os.path.join(experiment_root, model_dir)
        if os.path.isdir(model_path):
            # ë””ë ‰í† ë¦¬ëª…ì„ ëª¨ë¸ëª…ìœ¼ë¡œ ë³€í™˜
            model_name = model_dir.replace('_', '/').replace('_', ':')
            files = [f for f in os.listdir(model_path) if f.endswith(".json") and not f.endswith("_errors.json")]
            if files:
                available_models.append(model_name)
    
    if not available_models:
        st.error("ë¶„ì„í•  ì‹¤í—˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì‹¤í—˜ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return
    
    selected_model = st.selectbox(
        "ë¶„ì„í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”",
        available_models,
        key="analyzer_model_selector"
    )
    
    # ì‹¤í—˜ ê²°ê³¼ íŒŒì¼ ì„ íƒ
    experiment_results = list_model_experiment_results(selected_model)
    
    if not experiment_results:
        st.error("ì„ íƒí•œ ëª¨ë¸ì˜ ì‹¤í—˜ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    selected_result = st.selectbox(
        "ë¶„ì„í•  ì‹¤í—˜ ê²°ê³¼ë¥¼ ì„ íƒí•˜ì„¸ìš”",
        experiment_results,
        key="analyzer_result_selector"
    )
    
    # ì‹¤í—˜ ê²°ê³¼ ë¡œë“œ
    if st.button("ğŸ“ˆ ê²°ê³¼ ë¡œë“œ", type="primary"):
        with st.spinner("ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¡œë“œí•˜ëŠ” ì¤‘..."):
            result_data = load_model_experiment_result(selected_model, selected_result)
            
            if not result_data:
                st.error("ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            st.session_state.analyzer_result_data = result_data
            st.session_state.analyzer_model_name = selected_model
            st.success(f"âœ… {len(result_data)}ê°œ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ!")
    
    # ê²°ê³¼ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë¶„ì„ ì‹œì‘
    if 'analyzer_result_data' in st.session_state and st.session_state.analyzer_result_data:
        result_data = st.session_state.analyzer_result_data
        
        st.subheader("ğŸ“Š ê²°ê³¼ ìš”ì•½")
        
        # ë„ë©”ì¸ë³„ í†µê³„
        domain_stats = {}
        head_stats = {}
        
        for result in result_data:
            domain = result.get("domain", "unknown")
            max_head = result.get("max_head", -1)
            # ìƒˆë¡œìš´ ë³€ìˆ˜ëª…ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ì¡´ ë³€ìˆ˜ëª… ì‚¬ìš©
            attention_score = result.get("avg_evidence_attention_whole", result.get("avg_evidence_attention", 0.0))
            
            if domain not in domain_stats:
                domain_stats[domain] = {"count": 0, "total_attention": 0.0, "heads": []}
            domain_stats[domain]["count"] += 1
            domain_stats[domain]["total_attention"] += attention_score
            domain_stats[domain]["heads"].append(max_head)
            
            if max_head not in head_stats:
                head_stats[max_head] = {"count": 0, "total_attention": 0.0, "domains": []}
            head_stats[max_head]["count"] += 1
            head_stats[max_head]["total_attention"] += attention_score
            head_stats[max_head]["domains"].append(domain)
        
        # ë„ë©”ì¸ë³„ í†µê³„ í‘œì‹œ
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**ë„ë©”ì¸ë³„ í†µê³„**")
            for domain, stats in domain_stats.items():
                avg_attention = stats["total_attention"] / stats["count"]
                most_common_head = max(set(stats["heads"]), key=stats["heads"].count)
                st.write(f"**{domain}**: {stats['count']}ê°œ ê²°ê³¼, í‰ê·  ì–´í…ì…˜: {avg_attention:.4f}, ê°€ì¥ ë§ì´ ì„ íƒëœ í—¤ë“œ: {most_common_head}")
        
        with col2:
            st.markdown("**í—¤ë“œë³„ í†µê³„**")
            # ìƒìœ„ 10ê°œ í—¤ë“œë§Œ í‘œì‹œ
            sorted_heads = sorted(head_stats.items(), key=lambda x: x[1]["count"], reverse=True)[:10]
            for head, stats in sorted_heads:
                avg_attention = stats["total_attention"] / stats["count"]
                st.write(f"**Head {head}**: {stats['count']}íšŒ ì„ íƒ, í‰ê·  ì–´í…ì…˜: {avg_attention:.4f}")
        
        # íŠ¹ì • í—¤ë“œ ë¶„ì„
        st.subheader("ğŸ” íŠ¹ì • í—¤ë“œ ë¶„ì„")
        
        # ë¶„ì„í•  í—¤ë“œ ì„ íƒ
        target_head = st.number_input(
            "ë¶„ì„í•  í—¤ë“œ ë²ˆí˜¸",
            min_value=0,
            max_value=63,  # ì¼ë°˜ì ì¸ transformer ëª¨ë¸ì˜ í—¤ë“œ ìˆ˜
            value=27,
            help="ë¶„ì„í•˜ê³  ì‹¶ì€ íŠ¹ì • í—¤ë“œì˜ ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
        
        if st.button("ğŸ”¬ í—¤ë“œ ë¶„ì„", type="primary"):
            # í•´ë‹¹ í—¤ë“œê°€ ì„ íƒëœ ê²°ê³¼ë“¤ ì°¾ê¸°
            head_results = [r for r in result_data if r.get("max_head") == target_head]
            
            if not head_results:
                st.warning(f"Head {target_head}ì´ ì„ íƒëœ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            st.success(f"Head {target_head}ì´ ì„ íƒëœ {len(head_results)}ê°œ ê²°ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
            
            # ì²« ë²ˆì§¸ ê²°ê³¼ë¡œ attention íŒ¨í„´ ë¶„ì„
            sample_result = head_results[0]
            
            # ëª¨ë¸ì´ ë¡œë“œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ë” ìì„¸í•œ ë””ë²„ê¹…)
            st.info(f"ì„¸ì…˜ ìƒíƒœ í™•ì¸: model={'model' in st.session_state}, tokenizer={'tokenizer' in st.session_state}")
            
            if 'model' in st.session_state and 'tokenizer' in st.session_state:
                model = st.session_state['model']
                tokenizer = st.session_state['tokenizer']
                
                st.info(f"ëª¨ë¸ íƒ€ì…: {type(model)}, í† í¬ë‚˜ì´ì € íƒ€ì…: {type(tokenizer)}")
                
                if model is None or tokenizer is None:
                    st.error("ëª¨ë¸ ë˜ëŠ” í† í¬ë‚˜ì´ì €ê°€ Noneì…ë‹ˆë‹¤. ëª¨ë¸ ë¡œë“œ íƒ­ì—ì„œ ëª¨ë¸ì„ ë‹¤ì‹œ ë¡œë“œí•´ì£¼ì„¸ìš”.")
                    return
                
                st.success("âœ… ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                
                # attention ì¶”ì¶œ
                prompt = sample_result.get("prompt", "")
                evidence_indices = sample_result.get("evidence_indices", [])
                
                if not prompt:
                    st.error("í”„ë¡¬í”„íŠ¸ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return
                
                with st.spinner("Attention íŒ¨í„´ì„ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                    try:
                        import torch
                        inputs = tokenizer(prompt, return_tensors="pt")
                        inputs = {k: v.to(model.device) for k, v in inputs.items()}
                        
                        with torch.no_grad():
                            outputs = model(**inputs, output_attentions=True)
                            attentions = tuple(attn.cpu().numpy() for attn in outputs.attentions)
                        
                        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])
                        last_attn = attentions[-1][0]  # (head, from_token, to_token)
                        
                        # Head 27ì˜ attention íŒ¨í„´ ë¶„ì„
                        fig, stats, head_attention = analyze_head_attention_pattern(
                            last_attn, tokens, evidence_indices, target_head
                        )
                        
                        if fig is not None:
                            st.pyplot(fig)
                            
                            # í†µê³„ ì •ë³´ í‘œì‹œ
                            st.subheader("ğŸ“ˆ ë¶„ì„ ê²°ê³¼")
                            
                            col1, col2, col3 = st.columns(3)
                            with col1:
                                st.metric("Evidence í† í° í‰ê·  ì–´í…ì…˜", f"{stats['evidence_mean']:.4f}")
                            with col2:
                                st.metric("Non-Evidence í† í° í‰ê·  ì–´í…ì…˜", f"{stats['non_evidence_mean']:.4f}")
                            with col3:
                                st.metric("ì–´í…ì…˜ ë¹„ìœ¨", f"{stats['attention_ratio']:.2f}")
                            
                            # í•´ì„
                            st.subheader("ğŸ’¡ í•´ì„")
                            if stats['attention_ratio'] > 1.5:
                                st.success(f"âœ… Head {target_head}ì€ evidence í† í°ì— ê°•í•˜ê²Œ ë°˜ì‘í•©ë‹ˆë‹¤! (ë¹„ìœ¨: {stats['attention_ratio']:.2f})")
                            elif stats['attention_ratio'] > 1.1:
                                st.info(f"â„¹ï¸ Head {target_head}ì€ evidence í† í°ì— ì•½ê°„ ë” ë°˜ì‘í•©ë‹ˆë‹¤. (ë¹„ìœ¨: {stats['attention_ratio']:.2f})")
                            else:
                                st.warning(f"âš ï¸ Head {target_head}ì€ evidence í† í°ì— íŠ¹ë³„íˆ ë°˜ì‘í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ë¹„ìœ¨: {stats['attention_ratio']:.2f})")
                            
                            # ìƒì„¸ í†µê³„
                            st.markdown("**ìƒì„¸ í†µê³„**")
                            st.json(stats)
                            
                        else:
                            st.error("Attention íŒ¨í„´ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                            
                    except Exception as e:
                        st.error(f"Attention ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            else:
                st.error("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ëª¨ë¸ ë¡œë“œ íƒ­ì—ì„œ ëª¨ë¸ì„ ë¡œë“œí•´ì£¼ì„¸ìš”.")
                st.info("í˜„ì¬ ì„¸ì…˜ ìƒíƒœ í‚¤ë“¤: " + str(list(st.session_state.keys())))
        
        # ì „ì²´ í—¤ë“œ ë¶„í¬ ì‹œê°í™”
        st.subheader("ğŸ“Š ì „ì²´ í—¤ë“œ ë¶„í¬")
        
        if st.button("ğŸ“ˆ ë¶„í¬ ì‹œê°í™”", type="secondary"):
            # í—¤ë“œë³„ ì„ íƒ íšŸìˆ˜
            head_counts = {head: stats["count"] for head, stats in head_stats.items()}
            
            fig, ax = plt.subplots(figsize=(12, 6))
            heads = list(head_counts.keys())
            counts = list(head_counts.values())
            
            bars = ax.bar(heads, counts, alpha=0.7, color='skyblue')
            ax.set_xlabel('Head Index')
            ax.set_ylabel('Selection Count')
            ax.set_title('Head Selection Distribution')
            ax.set_xticks(heads)
            ax.set_xticklabels(heads, rotation=45)
            
            # ìƒìœ„ 5ê°œ í—¤ë“œ ê°•ì¡°
            sorted_heads = sorted(head_counts.items(), key=lambda x: x[1], reverse=True)[:5]
            for head, count in sorted_heads:
                if head in heads:
                    idx = heads.index(head)
                    bars[idx].set_color('red')
                    ax.text(head, count + 0.1, f'{count}', ha='center', va='bottom', fontweight='bold')
            
            plt.tight_layout()
            st.pyplot(fig)
            
            # ìƒìœ„ í—¤ë“œ ì •ë³´
            st.markdown("**ê°€ì¥ ë§ì´ ì„ íƒëœ í—¤ë“œë“¤**")
            for i, (head, count) in enumerate(sorted_heads, 1):
                avg_attention = head_stats[head]["total_attention"] / count
                st.write(f"{i}. **Head {head}**: {count}íšŒ ì„ íƒ, í‰ê·  ì–´í…ì…˜: {avg_attention:.4f}")
    
    else:
        st.info("ì‹¤í—˜ ê²°ê³¼ë¥¼ ë¡œë“œí•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.") 