import streamlit as st
from pathlib import Path
import json
import requests
from utils import (
    check_ollama_model_status,
    chat_with_model,
    get_available_models,
    fetch_ollama_models
)
import pandas as pd
import time
from datetime import datetime

# Ollama API ìƒìˆ˜
OLLAMA_API_BASE = "http://localhost:11434"

def start_model_via_api(model_name: str) -> tuple[bool, str]:
    """Ollama APIë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì‹œì‘í•©ë‹ˆë‹¤."""
    try:
        # ëª¨ë¸ ì‹¤í–‰ API í˜¸ì¶œ
        response = requests.post(
            f"{OLLAMA_API_BASE}/api/generate",
            json={
                "model": model_name,
                "prompt": "Hello",
                "stream": False
            },
            timeout=30
        )
        
        if response.status_code == 200:
            return True, f"Model {model_name} started successfully."
        else:
            return False, f"Failed to start model {model_name}. Status: {response.status_code}"
            
    except Exception as e:
        return False, f"Error starting model {model_name}: {str(e)}"

def stop_model_via_api(model_name: str) -> tuple[bool, str]:
    """Ollama APIë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì¤‘ì§€í•©ë‹ˆë‹¤."""
    try:
        # ë¨¼ì € ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ëª©ë¡ í™•ì¸
        response = requests.get(f"{OLLAMA_API_BASE}/api/ps", timeout=5)
        
        if response.status_code != 200:
            return False, f"Failed to check model status. Status: {response.status_code}"
        
        running_models = response.json().get("models", [])
        running_model_names = [model["name"] for model in running_models]
        
        if model_name not in running_model_names:
            return True, f"Model {model_name} is not running."
        
        # ëª¨ë¸ì´ ì‹¤í–‰ ì¤‘ì´ë©´ ì¤‘ì§€ ì‹œë„
        try:
            # Ollama APIë¥¼ ì‚¬ìš©í•´ì„œ ëª¨ë¸ ì¤‘ì§€ (ì•ˆì „í•œ ë°©ë²•)
            stop_response = requests.post(
                f"{OLLAMA_API_BASE}/api/generate",
                json={
                    "model": model_name,
                    "prompt": "stop",
                    "stream": False,
                    "options": {
                        "num_predict": 1,
                        "temperature": 0
                    }
                },
                timeout=3
            )
            
            if stop_response.status_code == 200:
                return True, f"Model {model_name} stopped successfully."
            else:
                return False, f"Failed to stop model {model_name}. Status: {stop_response.status_code}"
                
        except Exception as e:
            return False, f"Error stopping model {model_name}: {str(e)}"
            
    except Exception as e:
        return False, f"Error checking model status: {str(e)}"

def get_running_models_via_api() -> list[str]:
    """Ollama APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        response = requests.get(f"{OLLAMA_API_BASE}/api/ps", timeout=5)
        if response.status_code == 200:
            models = response.json().get("models", [])
            return [model["name"] for model in models]
        return []
    except Exception as e:
        print(f"Error fetching running models: {e}")
        return []

def show():
    # í˜ì´ì§€ ì œëª©
    st.header("ğŸ¤– Model Loader")
    st.markdown("Ollama ëª¨ë¸ì„ ê´€ë¦¬í•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'last_refresh_time' not in st.session_state:
        st.session_state.last_refresh_time = 0
    if 'model_choice' not in st.session_state:
        st.session_state.model_choice = ""
    if 'test_response' not in st.session_state:
        st.session_state.test_response = ""
    if 'test_prompt' not in st.session_state:
        st.session_state.test_prompt = ""
    
    # ===== 1. ì„¤ì¹˜ëœ ëª¨ë¸ ì„¹ì…˜ =====
    st.markdown("### ğŸ“¦ Installed Models")
    st.markdown("Currently installed models in the system.")
    
    # ì„¤ì¹˜ëœ ëª¨ë¸ ëª©ë¡ (ìºì‹œë¨)
    installed_models = get_available_models()
    
    # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
    col1, col2 = st.columns([1, 4])
    with col1:
        if st.button("ğŸ”„ Refresh", type="primary", key="refresh_installed"):
            get_available_models.clear()
            st.session_state.last_refresh_time = time.time()
            st.success("Model list refreshed!")
    
    # ë§ˆì§€ë§‰ ìƒˆë¡œê³ ì¹¨ ì‹œê°„ í‘œì‹œ
    if st.session_state.last_refresh_time > 0:
        with col2:
            st.caption(f"Last refresh: {datetime.fromtimestamp(st.session_state.last_refresh_time).strftime('%H:%M:%S')}")
    
    # ì„¤ì¹˜ëœ ëª¨ë¸ ëª©ë¡ í‘œì‹œ
    if installed_models:
        for model in installed_models:
            st.markdown(f"- `{model}`")
    else:
        st.info("No models installed.")
    
    st.markdown("---")
    
    # ===== 2. ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ì„¹ì…˜ =====
    st.markdown("### ğŸš€ Running Models")
    st.markdown("Currently running models.")
    
    # ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ
    running_models = get_running_models_via_api()
    
    col3, col4 = st.columns([1, 4])
    with col3:
        if st.button("ğŸ”„ Check Running", type="secondary", key="refresh_running"):
            st.rerun()
    
    with col4:
        st.caption(f"Found {len(running_models)} running model(s)")
    
    # ì‹¤í–‰ ì¤‘ì¸ ëª¨ë¸ ëª©ë¡ í‘œì‹œ
    if running_models:
        for model in running_models:
            st.markdown(f"- ğŸŸ¢ `{model}` (Running)")
    else:
        st.info("No models are currently running.")
    
    st.markdown("---")
    
    # ===== 3. ëª¨ë¸ ì‹¤í–‰ ì„¹ì…˜ =====
    st.markdown("### ğŸ¯ Model Execution")
    st.markdown("Select and run a model.")
    
    # ëª¨ë¸ ì„ íƒ
    col_select, col_info = st.columns([2, 1])
    
    with col_select:
        # ì„ íƒ ë°©ì‹ ë¼ë””ì˜¤ ë²„íŠ¼
        select_method = st.radio(
            "Selection Method",
            ["From List", "Direct Input"],
            horizontal=True,
            key="select_method"
        )
        
        if select_method == "From List":
            # ì„¤ì¹˜ëœ ëª¨ë¸ê³¼ ê¸°ë³¸ ëª¨ë¸ì„ êµ¬ë¶„í•˜ì—¬ í‘œì‹œ
            default_models = ["llama2:7b", "llama2:13b", "llama2:70b", "gemma:2b", "gemma:7b", "qwen:7b", "qwen:14b"]
            
            # ì„¤ì¹˜ëœ ëª¨ë¸ê³¼ ê¸°ë³¸ ëª¨ë¸ì„ êµ¬ë¶„í•˜ì—¬ ì˜µì…˜ ìƒì„±
            model_options = []
            
            # ì„¤ì¹˜ëœ ëª¨ë¸ ì¶”ê°€
            if installed_models:
                model_options.append({"label": "--- Installed Models ---", "disabled": True})
                for model in sorted(installed_models):
                    status = "ğŸŸ¢ (Running)" if model in running_models else "âšª (Stopped)"
                    model_options.append({"label": f"ğŸ“¦ {model} {status}", "value": model})
            
            # ê¸°ë³¸ ëª¨ë¸ ì¶”ê°€
            model_options.append({"label": "--- Available Models ---", "disabled": True})
            for model in sorted(default_models):
                if model not in installed_models:
                    model_options.append({"label": f"ğŸ’« {model}", "value": model})
            
            model_choice = st.selectbox(
                "Select a model to run",
                options=[opt["value"] for opt in model_options if "value" in opt],
                format_func=lambda x: next((opt["label"] for opt in model_options if "value" in opt and opt["value"] == x), x),
                help="Select a model to run. Uninstalled models will be downloaded automatically.",
                key="model_selectbox"
            )
        else:
            # ì§ì ‘ ì…ë ¥ í•„ë“œ
            model_choice = st.text_input(
                "Enter model name",
                placeholder="e.g., llama2:7b",
                help="Enter model name in format: model:version (e.g., llama2:7b, gemma:2b)",
                key="model_text_input"
            )
        
        # ì„ íƒëœ ëª¨ë¸ì„ ì„¸ì…˜ì— ì €ì¥
        if model_choice:
            st.session_state.model_choice = model_choice
    
    with col_info:
        if select_method == "From List":
            st.markdown("""
            #### Icon Legend
            - ğŸ“¦ : Installed models
            - ğŸ’« : Available models
            - ğŸŸ¢ : Running
            - âšª : Stopped
            """)
        else:
            st.markdown("""
            #### ğŸ’¡ Input Format
            - Format: `model:version`
            - Versions: `7b`, `13b`, `70b`, etc.
            - Examples: `llama2:7b`, `gemma:2b`
            """)
    
    # ì‹¤í–‰/ì¤‘ì§€ ë²„íŠ¼ë“¤
    col5, col6, col7 = st.columns(3)
    
    with col5:
        start_disabled = not st.session_state.model_choice
        if st.button("ğŸš€ Start Model", type="primary", key="start_model", disabled=start_disabled):
            if st.session_state.model_choice in running_models:
                st.warning(f"Model {st.session_state.model_choice} is already running.")
            else:
                with st.spinner(f"Starting {st.session_state.model_choice}..."):
                    success, message = start_model_via_api(st.session_state.model_choice)
                    if success:
                        st.success(message)
                        st.rerun()
                    else:
                        st.error(message)
    
    with col6:
        if st.button("ğŸ›‘ Stop Model", type="secondary", key="stop_model"):
            if st.session_state.model_choice:
                with st.spinner(f"Stopping {st.session_state.model_choice}..."):
                    success, message = stop_model_via_api(st.session_state.model_choice)
                    if success:
                        st.success(message)
                        st.rerun()
                    else:
                        st.warning(message)
            else:
                st.warning("Please select a model first.")
    
    with col7:
        if st.button("ğŸ” Check Status", type="secondary", key="check_status"):
            if st.session_state.model_choice:
                is_running = check_ollama_model_status(st.session_state.model_choice)
                if is_running:
                    st.success(f"âœ… {st.session_state.model_choice} is running.")
                else:
                    st.warning(f"âŒ {st.session_state.model_choice} is not running.")
            else:
                st.warning("Please select a model first.")
    
    st.markdown("---")
    
    # ===== 4. ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì„¹ì…˜ =====
    st.markdown("### ğŸ§ª Model Testing")
    st.markdown("Test the selected model's performance.")
    
    if st.session_state.model_choice:
        st.info(f"Selected model: **{st.session_state.model_choice}**")
        
        test_prompt = st.text_area(
            "Enter test prompt", 
            height=100,
            placeholder="e.g., 'Hello! Let's have a simple conversation.'",
            key="test_prompt_input"
        )
        
        col_test1, col_test2 = st.columns([1, 4])
        with col_test1:
            if st.button("ğŸ’« Run Test", type="primary", key="test_button"):
                if not test_prompt:
                    st.warning("Please enter a prompt.")
                else:
                    # ë¨¼ì € ëª¨ë¸ ìƒíƒœ í™•ì¸
                    if not check_ollama_model_status(st.session_state.model_choice):
                        st.error(f"âŒ {st.session_state.model_choice} is not running. Please start the model first.")
                    else:
                        with st.spinner("Generating model response..."):
                            response = chat_with_model(st.session_state.model_choice, test_prompt)
                            st.session_state.test_response = response
        with col_test2:
            st.caption("ğŸ’¡ The model must be running to test.")
        
        # ì‘ë‹µì´ ìˆìœ¼ë©´ í‘œì‹œ
        if st.session_state.test_response:
            st.markdown("---")
            st.markdown("### ğŸ¤– Model Response:")
            st.markdown(st.session_state.test_response)
    else:
        st.warning("Please select a model first.")
    
    st.markdown("---")
    
    # ===== 5. ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ì„¹ì…˜ =====
    st.markdown("### ğŸ“š Available Models")
    st.markdown("All models available in Ollama.")
    
    if st.button("ğŸ“‹ Show All Models", type="secondary", key="show_all_models"):
        with st.spinner("Fetching available models..."):
            models_list = fetch_ollama_models()
            if models_list is not None and len(models_list) > 0:
                # ë¦¬ìŠ¤íŠ¸ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
                import pandas as pd
                models_df = pd.DataFrame(models_list)
                st.dataframe(models_df, use_container_width=True)
            else:
                st.warning("Failed to fetch models or no models available.")
    
    # ===== 6. ì‹œìŠ¤í…œ ê´€ë¦¬ ì„¹ì…˜ =====
    st.markdown("---")
    st.markdown("### âš™ï¸ System Management")
    st.markdown("Manage system cache and settings.")
    
    # ìºì‹œ ì´ˆê¸°í™” ë²„íŠ¼
    if st.button("ğŸ—‘ï¸ Clear Cache", help="Clear cache while keeping model selection", type="secondary", key="clear_cache"):
        get_available_models.clear()
        keys_to_remove = ['last_refresh_time']
        for key in keys_to_remove:
            if key in st.session_state:
                del st.session_state[key]
        st.success("Cache cleared! (Model selection is preserved)") 