#!/usr/bin/env python3
"""
ì‹¤ì œ Evidence ì¶”ì¶œ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

from transformers import AutoTokenizer
import requests
import json
import re
from typing import List, Dict, Any

# Ollama API ì„¤ì •
OLLAMA_API_BASE = "http://localhost:11434"

def get_model_response(model_name: str, prompt: str) -> str:
    """Ollama ëª¨ë¸ì—ì„œ ì‘ë‹µì„ ë°›ì•„ì˜µë‹ˆë‹¤."""
    try:
        response = requests.post(
            f"{OLLAMA_API_BASE}/api/generate",
            json={
                "model": model_name,
                "prompt": prompt,
                "stream": False
            },
            timeout=30
        )
        if response.status_code == 200:
            return response.json().get("response", "")
        else:
            raise Exception(f"API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}")
    except Exception as e:
        raise Exception(f"ëª¨ë¸ ì‘ë‹µ ì˜¤ë¥˜: {str(e)}")

def create_evidence_query(word_list: List[str], prompt: str, domain: str) -> str:
    """Evidence ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    
    evidence_query = f"""Extract key evidence words from the following {domain} domain question.

Question: "{prompt}"

Provided word list:
{', '.join(word_list)}

Please respond in the following JSON format:
{{
    "evidence_words": ["word1", "word2", "word3"],
    "explanation": "Reason for selecting these words"
}}

Guidelines:
1. Select words that are crucial for understanding the core of the question
2. Prioritize domain-specific technical terms
3. There is no limit on the number of words you can select
4. Only select words from the provided word list"""

    return evidence_query

def extract_json_from_response(response: str) -> Dict[str, Any]:
    """ì‘ë‹µì—ì„œ JSONì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        # JSON ë¸”ë¡ ì°¾ê¸°
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if json_match:
            json_str = json_match.group()
            return json.loads(json_str)
        else:
            # JSONì´ ì—†ìœ¼ë©´ ìˆ˜ë™ìœ¼ë¡œ íŒŒì‹± ì‹œë„
            evidence_words = []
            explanation = ""
            
            # evidence_words ì¶”ì¶œ
            words_match = re.search(r'"evidence_words":\s*\[(.*?)\]', response, re.DOTALL)
            if words_match:
                words_str = words_match.group(1)
                evidence_words = [word.strip().strip('"\'') for word in words_str.split(',') if word.strip()]
            
            # explanation ì¶”ì¶œ
            exp_match = re.search(r'"explanation":\s*"([^"]*)"', response)
            if exp_match:
                explanation = exp_match.group(1)
            
            return {
                "evidence_words": evidence_words,
                "explanation": explanation
            }
    except Exception as e:
        print(f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}")
        return {"evidence_words": [], "explanation": "íŒŒì‹± ì‹¤íŒ¨"}

def validate_evidence(result: Dict[str, Any], words: List[str]) -> Dict[str, Any]:
    """ì¶”ì¶œëœ evidenceë¥¼ ê²€ì¦í•©ë‹ˆë‹¤."""
    evidence_words = result.get("evidence_words", [])
    explanation = result.get("explanation", "")
    
    # ì œê³µëœ ë‹¨ì–´ ëª©ë¡ì— ìˆëŠ”ì§€ í™•ì¸
    valid_words = []
    invalid_words = []
    
    for word in evidence_words:
        if word in words:
            valid_words.append(word)
        else:
            invalid_words.append(word)
    
    return {
        "evidence_words": valid_words,
        "invalid_words": invalid_words,
        "explanation": explanation,
        "is_valid": len(invalid_words) == 0
    }

def extract_evidence_with_deepseek(prompt: str, model_name: str = "deepseek-r1:7b", domain: str = "Medical") -> Dict[str, Any]:
    """DeepSeek ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ evidenceë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    
    print(f"ğŸ§  Evidence ì¶”ì¶œ ì‹œì‘...")
    print(f"ğŸ“ í”„ë¡¬í”„íŠ¸: {prompt}")
    print(f"ğŸ¤– ëª¨ë¸: {model_name}")
    print(f"ğŸ¥ ë„ë©”ì¸: {domain}")
    
    try:
        # í† í¬ë‚˜ì´ì € ë¡œë“œ
        tokenizer = AutoTokenizer.from_pretrained("deepseek-ai/deepseek-llm-7b-base", trust_remote_code=True)
        
        # í…ìŠ¤íŠ¸ë¥¼ ë‹¨ì–´ë¡œ ë¶„ë¦¬
        words = prompt.split()
        print(f"ğŸ“š ë‹¨ì–´ ëª©ë¡ ({len(words)}ê°œ): {words}")
        
        # Evidence ì¶”ì¶œ ì¿¼ë¦¬ ìƒì„±
        evidence_query = create_evidence_query(words, prompt, domain)
        print(f"\nğŸ” Evidence ì¶”ì¶œ ì¿¼ë¦¬:")
        print(evidence_query)
        
        # ëª¨ë¸ì— ì¿¼ë¦¬ ì „ì†¡
        print(f"\nğŸ“¤ ëª¨ë¸ì— ì¿¼ë¦¬ ì „ì†¡ ì¤‘...")
        response = get_model_response(model_name, evidence_query)
        print(f"ğŸ“¥ ëª¨ë¸ ì‘ë‹µ:")
        print(response)
        
        # JSON ì¶”ì¶œ
        result = extract_json_from_response(response)
        print(f"\nğŸ” ì¶”ì¶œëœ JSON: {result}")
        
        # ê²€ì¦
        validated_result = validate_evidence(result, words)
        print(f"\nâœ… ê²€ì¦ ê²°ê³¼: {validated_result}")
        
        return {
            "prompt": prompt,
            "model": model_name,
            "domain": domain,
            "words": words,
            "evidence_words": validated_result["evidence_words"],
            "invalid_words": validated_result["invalid_words"],
            "explanation": validated_result["explanation"],
            "is_valid": validated_result["is_valid"],
            "raw_response": response
        }
        
    except Exception as e:
        print(f"âŒ Evidence ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
        return {
            "error": str(e),
            "prompt": prompt,
            "model": model_name,
            "domain": domain
        }

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    
    print("ğŸš€ DeepSeek Evidence ì¶”ì¶œ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    # í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë“¤
    test_cases = [
        {
            "prompt": "What are the key clinical features associated with a diagnosis of atrial fibrillation in patients presenting with stroke?",
            "domain": "Medical"
        },
        {
            "prompt": "Describe the primary ethical considerations associated with the use of artificial intelligence in patient diagnosis and treatment.",
            "domain": "Medical"
        },
        {
            "prompt": "List the most common side effects associated with long-term use of Metformin for Type 2 Diabetes management.",
            "domain": "Medical"
        }
    ]
    
    results = []
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\n{'='*60}")
        print(f"ğŸ§ª í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {i}")
        print(f"{'='*60}")
        
        result = extract_evidence_with_deepseek(
            prompt=test_case["prompt"],
            domain=test_case["domain"]
        )
        
        results.append(result)
        
        # ê²°ê³¼ ìš”ì•½
        if "error" not in result:
            print(f"\nğŸ“‹ ê²°ê³¼ ìš”ì•½:")
            print(f"  - ì¶”ì¶œëœ evidence ë‹¨ì–´: {result['evidence_words']}")
            print(f"  - ìœ íš¨ì„±: {'âœ… ìœ íš¨' if result['is_valid'] else 'âŒ ë¬´íš¨'}")
            if result['invalid_words']:
                print(f"  - ë¬´íš¨í•œ ë‹¨ì–´: {result['invalid_words']}")
            print(f"  - ì„¤ëª…: {result['explanation']}")
        else:
            print(f"âŒ ì˜¤ë¥˜: {result['error']}")
    
    # ì „ì²´ ê²°ê³¼ ì €ì¥
    with open("evidence_extraction_results.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"ğŸ“ ê²°ê³¼ê°€ 'evidence_extraction_results.json'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ì„±ê³µë¥  ê³„ì‚°
    success_count = sum(1 for r in results if "error" not in r and r.get("is_valid", False))
    total_count = len(results)
    
    print(f"âœ… ì„±ê³µë¥ : {success_count}/{total_count} ({success_count/total_count*100:.1f}%)")

if __name__ == "__main__":
    main() 